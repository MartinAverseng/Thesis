{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./figures/logo-ecole-polytechnique-ve.jpg' style='position:absolute; top:0; right:0;' width='100px' height='' alt='' />\n",
    "\n",
    "<center>**Bachelor of Ecole Polytechnique**</center>\n",
    "<center>Computational Mathematics, year 1, semester 2</center>\n",
    "<center>Author: Aline Lefebvre-Lepot</center>\n",
    "\n",
    "# Rootfinding of equations in one variable\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "<img src=\"./figures/Abstract.png\" alt=\"Roots\" style=\"width: 500px;\"/>\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div markdown=1 class=Abstract>\n",
    "In this chapter, we consider the problem of finding **roots of an equation in one variable**: find $x$ such that $f(x)=0$. We discuss numerical methods to approximate solutions of this kind of problems to an arbitrarily high accuracy. First, we formalize the notion of convergence and order of convergence for **iterative methods**. Then, we focus on three iterative algorithms approximating roots of functions: **bisection method**, **fixed point iterations** and **Newton Raphson method**. These methods are described, analysed and used to solve 3 problems coming from physics, finance and dynamics of population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Iterative methods: errors and convergence](#iterative)\n",
    "- [The bisection method](#bisection)\n",
    "- [Fixed point iterations](#fixedPoint)\n",
    "- [The Newton-Raphson method](#Newton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## loading python libraries\n",
    "\n",
    "# necessary to display plots inline:\n",
    "%matplotlib inline   \n",
    "\n",
    "# load the libraries\n",
    "import matplotlib.pyplot as plt # 2D plotting library\n",
    "import numpy as np              # package for scientific computing  \n",
    "\n",
    "from math import *              # package for mathematics (pi, arctan, sqrt, factorial ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the zeros of a function $f$ or equivalently the roots of equation $f(x)=0$ is a problem that can be encountered in various situations. In lot of these situations, the solution cannot be computed exactly and one has to design numerical algorithms to approximate the solutions. We give below a few examples of such situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 1: State equation of a gaz\n",
    "\n",
    "<img src=\"figures/VanDerWaals.jpg\" alt=\"vanderWaals\" style=\"width: 200px;\"/>\n",
    "  \n",
    ">**Johannes Diderik van der Waals (1837-1923).**\n",
    ">He is a Dutch theoretical physicist. He was primarily known for his thesis work (1873) in which he proposed a state equation for gases to take into account their non-ideality and the existence of intermolecular interactions. His new equation of state revolutionized the study of the behavior of gases. This work was followed by several other researches on molecules that has been fundamental for the development of molecular physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state equation of a gaz relating the pressure $p$, the volume $V$ and the temperature $T$ proposed by van der Waals can be written\n",
    "\n",
    "$$\n",
    "\\left[p + a \\left( \\frac{N}{V}\\right)^2\\right] (V-Nb) = kNT\n",
    "$$\n",
    "\n",
    "where $N$ is the number of molecules of the gaz, $k$ is the Boltzmann-constant and $a$ and $b$ are coefficients depending on the gaz. To determine the volume occupied by a gaz at pressure $p$ and temperature $T$, we need to solve this equation whose root is $V$. \n",
    "\n",
    "Suppose one wants to find the volume occupied by $1000$ molecules of $\\text{CO}_2$ at temperature $T=300\\,K$ and pressure $p=3.5 \\cdot 10^7 \\,Pa$. Then, the previous equation has to be solved for $V$, with the following values of parameters $a$ and $b$ corresponding to carbon dioxide: $a=0.401 \\,Pa\\,m^6$ and $b=42.7 \\cdot 10^{-6}\\, m^3$. The Boltzmann constant is $k=1.3806503 \\cdot 10^{-23} \\,J\\,K^{-1}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 2: Investment found\n",
    "\n",
    "Suppose someone wants to have a saving account valued at $S=30\\,000$ euros upon retirement in 10 years. He can deposit $d=30$ euros each month on its account. The rate of interest is $i$ and $S_n$ the capital after $n$ months. If the intersest is computed monthly, we have:\n",
    "\n",
    "$$\n",
    "S_n =  \\sum_{k=0}^{n-1} d(1+i)^{k} = d \\frac{(1+i)^n-1}{i}\n",
    "$$\n",
    "\n",
    "If this person wants to know the minimal rate interest needed to achieve his goal, he has to solve the following equation for $i$:\n",
    "$$\n",
    "S =  d \\frac{(1+i)^{n_{end}}-1}{i} \\quad \\text{ where } \\quad n_{end} = 120\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 3: A first population model\n",
    "\n",
    "<img src=\"figures/Malthus.jpg\" alt=\"Malthus\" style=\"width: 300px;\"/>\n",
    "  \n",
    ">**Thomas Robert Malthus (1766-1834).**\n",
    ">He is a British economist. He is mainly known for his works about the links between a population dynamics and its productions. He published  anonymously in 1798 an *Essay on the principle of populations*. It is based on the idea that the growth of a population is essentially geometric while the growth of the production is arithmetic. This leads to the so-called Malthusianism doctrine suggesting that the population size has to be controlled to avoid a catastrophe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population dynamics is a branch of mathematical biology that gave rise to a great amount of research and is still very active nowadays. The objective is to study the evolution of the size and composition of populations and how the environment drives them. The first model that can be derived is a natural exponential growth model. It depends on two parameters: $\\beta$ and $\\delta$, the average numbers of births and deaths per individual and unit of time. If we suppose that these parameters are the same for all individuals and do not depend on the size of the population, we can denote the growth rate of the population by $\\lambda = \\beta - \\delta$  and write:\n",
    "\n",
    "$$\n",
    "\\frac{dN}{dt} = \\lambda \\, N\n",
    "$$\n",
    "\n",
    "where $N$ is the population size. This model leads to exponentially increasing ($\\lambda>0)$ or decreasing populations ($\\lambda<0$). Of course, this model can be enriched to derive more realistic models such as the logistic population growth model where the growth rate $\\lambda$ depends on the size of the population as follows : $\\lambda(N) = \\lambda_* - cN$. This way, too large populations have a negative growth rate, leading to population regulation. When the population is not isolated, one has to take into account immigration or emigration. If we denote by $r$ the average number of individuals joining the community per unit of time, a new model can be written as\n",
    "\n",
    "$$\n",
    "\\frac{dN}{dt} = \\lambda \\, N + r,\n",
    "$$\n",
    "\n",
    "whose solution is (if $\\lambda\\neq 0$)\n",
    "\n",
    "$$\n",
    "N(t) = N(0)\\exp(\\lambda t) + \\frac{r}{\\lambda}(\\exp(\\lambda t)-1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants to estimate the natural growth rate $\\lambda$ in France, one can use the following (evaluated) data:\n",
    "\n",
    "| Population 01/01/2016 | Population 01/01/2017   | migratory balance in 2016 |\n",
    "|-----------------------|-------------------------|---------------------------|\n",
    "|  66 695 000          | 66 954 000              |   67 000                     |\n",
    "\n",
    "and solve the corresponding equation for $\\lambda$ (unit of time = year)\n",
    "\n",
    "$$\n",
    "N(2017) = N(2016)\\exp(\\lambda) + \\frac{r}{\\lambda}(\\exp(\\lambda)-1).\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"iterative\"></a>\n",
    "## Iterative methods: errors and convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the previous problems have the same characteristic: the exact solution cannot be computed through an explicit formula and they have to be approximated through numerical methods.\n",
    "\n",
    "Let us write these problems under the following generic rootfinding problem:\n",
    "\n",
    "$$\n",
    "\\text{given }\\quad f: [a,b] \\to \\mathbb{R},\\quad \\text{find}\\quad x^*\\in[a,b] \\quad\\text{such that}\\quad f(x^*)=0.\n",
    "$$\n",
    "\n",
    "Methods for approximating the root $x^*$ of $f$ are often iterative: algorithms generate sequences $(x_k)_{k\\in\\mathbb{N}}$ that are supposed to converge to $x^*$. Given such a sequence, the two questions one has to answer are:\n",
    "- Does the sequence converge to $x^*$ ?\n",
    "- if it converges, how fast does it converge to $x^*$ ?\n",
    "\n",
    "Before going further, we formalize below the notions of convergence and convergence speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Def\">\n",
    "**Convergence**. Suppose that a sequence $(x_k)_k$ is generated to approximate $x^*$. The error at step $k$ is defined as\n",
    "\n",
    "$$\n",
    "e_k= |\\,x_k\\,-\\,x^*\\,|\n",
    "$$\n",
    "\n",
    "where $|\\,\\cdot\\,|$ denotes the absolute value. The sequence $(x_k)_k$ is said to *converge to $x^*$* if\n",
    "\n",
    "$$\n",
    "e_k \\longrightarrow 0 \\quad \\text{when}\\quad k\\to \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, several sequences can be generated and converge to $x$. One has to choose which one will be used by comparing their properties such as the computational time or the speed of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"Ex\">\n",
    "Let us consider the three following sequences converging to $x^*=0$:\n",
    "\n",
    "$$\n",
    "x_k=\\left(\\frac{1}{2}\\right)^k, \\quad \\bar x_k=\\left(\\frac{1}{7}\\right)^k, \\quad \\text{and}\\quad \\hat x_k=\\left(\\frac{1}{2}\\right)^{2^k}\n",
    "$$\n",
    "\n",
    "The values obtained for the first terms of these sequences are\n",
    "\n",
    "|k  | 0   |1 |  2|  3|  4| 5|\n",
    "|----|----|----|----|----|----|----|\n",
    "| $x_k$ | 1     |      0.5 |  0.25 |  0.125 |  0.0625| 0.03125|\n",
    "| $\\bar x_k$ | 1     |      0.14285 |  0.02041 |  0.00291 |  4.164 e -4| 5.94 e -5|\n",
    "| $\\hat x_k$ |0.5 |   0.25 |   0.0625|   0.00390.. | 1.52 e -5 | 2.328 e -10|\n",
    "  \n",
    "The three sequences converge to zero but $\\hat x_k$ seems to converge to zero faster than $\\bar x_k$, itself converging faster than $x_k$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to quantify the convergence speed of a sequence is to estimate its order of convergence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Def\">\n",
    "**Order of convergence**. Suppose that the sequence $(x_k)_k$ converges to $x^*$. It is said to converge to $x^*$ *with order $\\alpha>1$* if\n",
    "\n",
    "$$\n",
    "\\exists k_0>0, \\quad \\exists C>0, \\quad \\forall k\\geq k_0, \\quad \\frac{e_{k+1}}{(e_k)^\\alpha} \\leq C.\n",
    "$$\n",
    "\n",
    "The convergence is said to be *linear* if $\\alpha=1$ and *quadratic* if $\\alpha=2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course,\n",
    "- The bigger is $\\alpha$, the better is the convergence: the number of exact digits is multiplied by $\\alpha$ at each step.\n",
    "- $\\alpha$ being given, the smaller is $C$, the better is the convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Consider again the three following sequences converging to $x^*=0$:\n",
    "\n",
    "$$\n",
    "x_k=\\left(\\frac{1}{2}\\right)^k, \\quad \\bar x_k=\\left(\\frac{1}{7}\\right)^k, \\quad \\text{and}\\quad \\hat x_k=\\left(\\frac{1}{2}\\right)^{2^k}\n",
    "$$\n",
    "\n",
    "Explain the results given in the previous example by studying the order of convergence of the three sequences. Justify your answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical study of convergence\n",
    "\n",
    "The convergence of a sequence can be observed plotting $e_k$ versus $k$.\n",
    "\n",
    "Then, remarking that, for a method of order $\\alpha$, one have\n",
    "\n",
    "$$\n",
    "\\log e_{k+1} \\leq \\alpha \\log e_k + \\log C.\n",
    "$$\n",
    "\n",
    "a graphical method to observe the convergence rate is to plot $\\log e_{k+1}$ versus $\\log e_k$. \n",
    "\n",
    "In the following code, we plot $e_k$ versus $k$ and $\\log e_{k+1}$ versus $\\log e_k$ for the three considered sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Run the following cell and explain the resulting plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = np.arange(0,6,1)\n",
    "x1 = (1./2) ** N \n",
    "x2 = (1./7) ** N\n",
    "x3 = (1./2) ** (2**N)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(N, x1, marker=\"o\", label='error for $x_k$')\n",
    "plt.plot(N, x2, marker=\"o\", label='error for bar$x_k$')\n",
    "plt.plot(N, x3, marker=\"o\", label='error for hat$x_k$')\n",
    "plt.legend(loc='lower left', fontsize=18)\n",
    "plt.xlabel('k', fontsize=18)\n",
    "plt.ylabel('$e_{k}$', fontsize=18)\n",
    "plt.yscale('log')        # log scale for the error\n",
    "plt.title('Convergence', fontsize=18)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.loglog(x1[:-1:], x1[1:], marker=\"o\", label='slope 1 for $x_k$') #log-log scale\n",
    "plt.loglog(x2[:-1:], x2[1:], marker=\"o\", label='slope 1 for bar$x_k$') #log-log scale\n",
    "plt.loglog(x3[:-1:], x3[1:], marker=\"o\", label='slope 2 for hat$x_k$') #log-log scale\n",
    "plt.legend(loc='lower right', fontsize=18)\n",
    "plt.axis('equal')\n",
    "plt.xlabel('$e_k$', fontsize=18)\n",
    "plt.ylabel('$e_{k+1}$', fontsize=18)\n",
    "plt.title('Order of convergence', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To finish, notice that, most of the time, since $x$ is not known, we cannot compute the value of the true error at step $k$. Instead we try to find a (calculable) bound for the error, which gives us a “worst-case” error:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Def\">\n",
    "**Error estimator**. Suppose that a sequence $(x_k)_k$ is generated to approximate $x^*$. The sequence $(\\beta_k)_k$ is an error estimator if\n",
    "\n",
    "- $\\beta_k>0$ is computable\n",
    "- $\\beta_k$ is a bound for the error: $\\, e_k < \\beta_k$ for all $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, if the estimator $\\beta_k \\rightarrow 0$ when $k\\to \\infty$, we obtain that\n",
    "\n",
    "- the sequence $x_k$ converges to $x^*$\n",
    "- the error goes to zero at least as fast as the sequence $\\beta_k$.\n",
    "\n",
    "One has to take care that an estimator only provides an upper bound on the error. As a consequence, the error can go to zero faster than the estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"bisection\"></a>\n",
    "## The bisection method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first method to approximate the solution to $f(x)=0$ is based on the Intermediate Value Theorem (see Appendix). Suppose $f$ is a continuous function on the interval $[a,b]$ where $f(a)$ and $f(b)$ have opposit signs: $f(a)\\,f(b)<0$. Then, there exists $x^*$ in $]a,b[$ such that $f(x^*)=0$.\n",
    "\n",
    "Starting from an intervall $I_0=[a_0,b_0]$ such that $f(a_0)\\,f(b_0)<0$. Let $x_0$ be the midpoint of $I_0$:\n",
    "\n",
    "$$\n",
    "x_0 = \\frac{a_0+b_0}{2}.\n",
    "$$\n",
    "\n",
    "Then, the bisection method iterates by chosing $I_1=[a_1,b_1]$ and $x_1$ as follows:\n",
    "\n",
    "- if $f(x_0)=0$ then $x^*=x_0$ and the algorithm terminates\n",
    "- if $f(a_0)\\,f(x_0)<0$ then there exists a zero of $f$ in $[a_0,x_0]$: set \n",
    "\n",
    "$$\n",
    "a_1=a_0,\\quad b_1=x_0 \\quad \\text{and}\\quad x_1 = \\frac{a_1+b_1}{2}\n",
    "$$\n",
    "\n",
    "- if $f(x_0)\\,f(b_0)<0$ then there exists a zero of $f$ in $[x_0,b_0]$: set \n",
    "\n",
    "$$\n",
    "a_1=x_0,\\quad b_1=b_0 \\quad \\text{and}\\quad x_1 = \\frac{a_1+b_1}{2}\n",
    "$$\n",
    "\n",
    "The method iterates until a stopping criterion that will be discussed later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of the first two iterations is illustrated on an example in the figure below.\n",
    "\n",
    "<img src=\"figures/Bisection.png\" alt=\"Bisection\" style=\"width: 500px;\" />\n",
    "\n",
    "The bisection method leads to the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Algo\">\n",
    "**Bisection method.** Computes a sequence $(x_k)_k$, approximating $x^*$ solution to $f(x^*)=0$.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "INPUT:&\\quad f, a, b\\\\\n",
    "DO:&\\quad x = (a+b)/2\\\\\n",
    "&\\quad \\text{While stopping criterion is not achieved do}\\\\\n",
    "&\\quad\\quad\\quad \\text{If } \\quad f(a)\\,f(x)<0 , \\quad b=x \\quad\\text{ else }\\quad a=x\\\\\n",
    "&\\quad\\quad\\quad x = (a+b)/2\\\\\n",
    "&\\quad \\text{end while}\\\\\n",
    "RETURN:&\\quad x\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we implement the bisection method and test it to approximate $x^*$, the unique solution in $\\mathbb R$ to $f(x) = x^3-2=0$. In this first version, the stopping criterion is: stop if the requested number of iteration is achieved or if the zero was found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Complete the following function encoding $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function f: x -> x^3 -2\n",
    "\n",
    "def ftest(x):\n",
    "    return ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Complete the following function. It shall compute the sequence generated using the bisection algorithm for a given function $f$ and initialized by an interval $[a_0,b_0]$. \n",
    "\n",
    "The algorithm terminates when the zero is found or when a given maximal number $K$ of iterations have been achieved. The output is a vector $x$ with size $K+1$. It contains the values of the sequence: $x[k]=x_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bisection algorithm for function f\n",
    "## input : f = name of the function\n",
    "##         a0, b0 = initial interval I_0 with f(a)f(b)<0\n",
    "##         K = number of iterations\n",
    "## output : x = sequence approximating the zero of f\n",
    "##              x[k]=x_k for k=0..K\n",
    "\n",
    "def Bisection(f,a0,b0,K):\n",
    "    x = ---               # create vector x of zeros with size K+1\n",
    "    k = 0                 # initialize k\n",
    "    a = a0                # initialize a\n",
    "    b = b0                # initialize b\n",
    "    x[0] = ---            # initialize x_0\n",
    "    # computation of x_k for k>0\n",
    "    # stops if f(x[k])=0 or if the number of iterations is achieved\n",
    "    while  --- and --- :  #test the two stopping criterion\n",
    "        # do not stop => enter the loop and iterate the bisection algorithm\n",
    "        if --- :\n",
    "            --- #do something\n",
    "        else:\n",
    "            --- #do something\n",
    "        k = k+1\n",
    "        x[k] = ---       #compute and store x_k\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Test the bisection method to compute $x^*=2^{1/3}$ solution to $f(x)=0$. Initialize with $[a_0,b_0]=[1,2]$ and compute the first 20 iterations. Plot the error $e_k$ versus $k$. Use a log scale for the error (y-axis). Do not forget to add a title to the figure and a label to the axes (see the graphical study in the previous section as example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xstar = 2**(1.0/3)\n",
    "\n",
    "# parameters\n",
    "a0 = ---\n",
    "b0 = ---\n",
    "K = ---\n",
    "\n",
    "# compute the first 20 iterations of the bisection method for I0=[1,2]\n",
    "x=---\n",
    "\n",
    "#print x^* and x\n",
    "print('xstar =',xstar)\n",
    "print('x =',x)\n",
    "\n",
    "# compute the error\n",
    "# err is a vector, err[k]=abs(x[k]-x^*)\n",
    "err = ---\n",
    "\n",
    "# create the vector tabk : tabk[k]=k for k=0..K\n",
    "tabk = ---\n",
    "\n",
    "# plot the error versus k\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(---, ---, marker=\"o\")\n",
    "# set log scale for the error (y-axis)\n",
    "---\n",
    "# set title of the figure and labels of the axis\n",
    "---\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the convergence to zero for the bisection method is not monotone. For example, $x_8$ is closer to $x$ than $x_9$ ou $x_{10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error estimator and stopping criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the stopping criterion is simply based on the number of iterations the user wants to achieve. However, when one wants to approximate $x^*$, one has in mind the maximal error allowed and therefore, fixing the number of iterations has no sense as a stopping criterion. A criterion based on the error at the current step would be much more meaningful.\n",
    "\n",
    "Suppose that a parameter $\\epsilon$ is given, fixing the precision needed. We give below three classical stopping criteria:\n",
    "\n",
    " $\\quad\\quad\\quad\\quad$ 1. $\\quad|\\,x_k-x_{k-1}\\,| \\, <\\, \\epsilon\\quad\\quad$ 2. $\\quad |\\,f(x_k)\\,|\\,<\\,\\epsilon\\quad\\quad$ 3.$\\quad\\displaystyle \\frac{|\\,x_k-x_{k-1}\\,|}{|\\,x_k\\,|}\\, <\\, \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, each of these criteria can induce difficulties. For example, criterion 1 can be fullfilled even for non-converging sequences (think e.g. at $x_k=\\sum_{j=1}^k \\frac{1}{j}$). Criterion 2 is also non-relevant for some functions $f$ for which $f(x)$ can be close to zero while $x$ is still far from $x^*$: the test will be satisfactory if $f'(x^*)\\approx 1$, not reliable if $f'(x^*)<<1$ and too restrictive if $f'(x^*)>>1$.\n",
    "\n",
    "Without any further information on $f$ or on the convergence of the sequence, one should make criterion 3 its first choice.\n",
    "\n",
    "In order to use a more precise stopping criterion, related to the true error, one should know more about the way the sequence converges to $x$. To do so, error estimators are very useful. Concerning the bisection method we have the following result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div  markdown=1 class=\"Prop\"> \n",
    "** Convergence of the bisection method.** Let $f$ be a continuous function on $[a,b]$ with $f(a)\\,f(b)<0$. Suppose $(x_k)_k$ is the sequence generated by the bisection method to approximate $x^*$, solution to $f(x)=0$ on $[a,b]$.\n",
    "\n",
    "Then, the sequence $(x_k)_k$ converges to $x^*$ and the following estimation holds:\n",
    "\n",
    "$$\n",
    "\\forall k\\geq 0,\\quad |x_k-x^*|\\,\\leq\\,\\frac{b-a}{2^k}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> **Proof.** Since the interval is divided by 2 at each step of the method, we have\n",
    ">\n",
    ">$$\n",
    "\\forall k\\geq 0\\quad |b_k-a_k|\\leq \\frac{b-a}{2^k}\n",
    "$$\n",
    ">\n",
    "> Remarking that both $x^*$ and $x_k$ are in $I_k=[a_k,b_k]$, we obtain\n",
    ">\n",
    ">$$\n",
    "\\forall k\\geq 0\\quad |x_k-x^*|\\leq \\frac{b-a}{2^k}\n",
    "$$\n",
    ">\n",
    "> This proves the convergence of $x_k$ to $x^*$ and provides the requested estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\"> The bisection method is said to be *globally convergent*. Indeed, the initialization of $a$ and $b$ doesn't need to be close to $x$. Whatever the choice for these parameters is, the generated sequence will converge to $x$, provided that $f(a)\\,f(b)<0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This proposition provides a new stopping criterion: if one wants the error to be less than $\\epsilon$, one should stop at iteration $k$ such that \n",
    "\n",
    "$$\\frac{b-a}{2^k}\\leq \\epsilon.$$\n",
    "\n",
    "We rewrite the code for the bisection method using this criterion. Note that we still ask for a maximal number of iterations in order to avoid infinite loops in case the convergence of the method is too slow to lead to the requested precision in a reasonable time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Rewrite the bisection algorithm so that it terminates when the stopping criterion $\\frac{b-a}{2^k}\\leq \\epsilon$ is verified or when a maximal number $K_{max}$ of iterations have been achieved. If $k_{end}$ is the number of iterations needed to fulfil this criteria, we have $k_{end}\\leq K$. \n",
    "\n",
    "The function returns a tupple of two elements: the vector $x$ containing the computed iterations together with $k_{end}$, the number of iterations achieved.\n",
    "\n",
    "$x$ is a vector with size $K_{max}+1$. It contains the computed values of the sequence: $x[k]=x_k$ for $0\\leq k\\leq k_{end}+1$ and the other elements of $x$ are equal to $0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Bisection algorithm for function f\n",
    "## input : f = name of the function\n",
    "##         a0, b0 = initial intervall I_0 with f(a0)f(b0)<0\n",
    "##         eps  = tolerance\n",
    "##         Kmax = maximal number of iterations allowed\n",
    "## output : x = sequence approximating the zero of f\n",
    "##          k = total number of iterations that has been achieved (lower than Kmax)\n",
    "\n",
    "def Bisection2(f,a0,b0,eps,Kmax):\n",
    "    ---\n",
    "    return (x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Test this new function to compute $2^{1/3}$ with precision at least $\\epsilon=10^{-3}$. Use $K_{max}=20$, $I_0=[1,2]$. Plot on the same figure the error versus $k$ and the corresponding estimator. Do not forget the title, the labels of axes and the legend. Take care that the output $x$ of the bisection function is of size $K_{max}$ while the number of iterations $k_{end}$ can be strictly smaller than $K_{max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "a0 = --- \n",
    "b0 = ---\n",
    "eps = ---\n",
    "Kmax = ---\n",
    "\n",
    "xstar = 2**(1.0/3)\n",
    "\n",
    "# run the bisection method\n",
    "res = ---\n",
    "kend = res[1]         # res[1] returns the second element of the output: number of iterations achieved\n",
    "x = res[0]            # res[0] returns the first element of the output: vector x with size Kmax\n",
    "x = ---               # selection of the elements of x containing the iterations\n",
    "print('precision: eps =',eps)\n",
    "print('number of iterations =',kend)\n",
    "\n",
    "# compute the error\n",
    "# err is a vector, err[k]=abs(x[k]-x^*) for k=0..kend\n",
    "err = ---\n",
    "\n",
    "# create the vector tabk : tabk[k]=k for k=0..kend\n",
    "tabk = ---\n",
    "\n",
    "# compute the error estimator, errEstim[k]=(b-a)/2^k for k=0..kend\n",
    "# use tabk / no loop on k\n",
    "errEstim = ---\n",
    "\n",
    "# plot the error versus k\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(---, ---, marker=\"o\", label=\"Error\")\n",
    "# plot the error estimator versus k\n",
    "plt.plot(---, ---, marker=\"o\", label=\"Error estimator\")\n",
    "# set log scale for the error (y-axis)\n",
    "---\n",
    "# set title of the figure, labels of the axis and the legend\n",
    "---\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the estimator is an upper bound for the true error, the condition imposing that it has to be below the requested precision is a sufficient condition but not a necessary one. \n",
    "\n",
    "Here, for $\\epsilon=10^{-3}$, due to the non monotone convergence of the method, the estimator makes the computation terminate for $k=10$. However, $x_8$ was yet sufficiently precise and, when the stopping criterion is reached, the precision is much better than needed. \n",
    "\n",
    "However, such an estimator makes the user sure to obtain the requested precision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 1: State equation of a gaz, a solution using bisection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the bisection method to solve case study 1 and compute the volume of $1000$ molecules of $\\text{CO}_2$ at temperature $T=300\\,K$ and pressure $p=3.5 \\cdot 10^7 \\,Pa$. We want to compute the corresponding volume with tolerance $10^{-12}$. \n",
    "\n",
    "To do so, we have to solve the following equation for $V$:\n",
    "\n",
    "$$\n",
    "f(V)=\\left[p + a \\left( \\frac{N}{V}\\right)^2\\right] (V-Nb) - kNT =0\n",
    "$$\n",
    "\n",
    "with $N=1000$, $k=1.3806503 \\cdot 10^{-23} \\,J\\,K^{-1}$, $a=0.401 \\,Pa\\,m^6$ and $b=42.7 \\cdot 10^{-6}\\, m^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Use the following code to find values of $a_0$ and $b_0$ to initialize the bisection algorithm to find a root of $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plot of f\n",
    "tabV = np.linspace(0.042,0.043,10)\n",
    "k = 1.3806503e-23\n",
    "a = 0.401\n",
    "b = 42.7e-6\n",
    "N = 1000.0\n",
    "T = 300.0\n",
    "p = 3.5e7\n",
    "y = (p + a * (np.divide(N,tabV))**2) * (tabV-N*b) - k*N*T\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(tabV, y, marker=\"o\")\n",
    "plt.title(\"function f for case study 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Use these values to initialize the bisection algorithm and solve the problem with precision $10^{-12}$. Print the number of iterations to achieve this precision and the volume computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function f\n",
    "\n",
    "def fgaz(V):\n",
    "    k = 1.3806503e-23\n",
    "    a = 0.401\n",
    "    b = 42.7e-6\n",
    "    N = 1000.0\n",
    "    T = 300.0\n",
    "    p = 3.5e7\n",
    "    return ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Resolution\n",
    "\n",
    "res = ---\n",
    "kend = res[1]         # res[1] returns the second element of the output: number of iterations achieved\n",
    "x = res[0]            # res[0] returns the first element of the outupt: vector x with size Kmax containing the iterations\n",
    "V = ---               # V is the last element computed\n",
    "\n",
    "## print the number of iterations and the volume computed\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 2: Investment found, a solution using bisection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the bisection method to solve case study 2. We recall that we have to find $i$ solution to\n",
    "\n",
    "$$\n",
    "f(i) = d \\frac{(1+i)^{n_{end}}-1}{i} - S =0 \\quad \\text{ where } \\quad S=30\\,000, \\quad d=30,\\quad \\text{and} \\quad n_{end} = 120\n",
    "$$\n",
    "\n",
    "We use the bisection method to find the corresponding rate of interest with precision $10^{-4}$. First, we plot below the corresponding function $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Use the following code to find values of $a_0$ and $b_0$ to initialize the bisection algorithm to find a root of $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## plot of f\n",
    "tabi = ---\n",
    "d = 30.0\n",
    "S = 30000.0\n",
    "n = 120.0\n",
    "y = np.divide(d * ((1+tabi)**n-1), tabi) - S\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "plt.plot(tabi, y, marker=\"o\")\n",
    "plt.title(\"function f for case study 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Use these values to initialize the bisection algorithm and solve the problem with precision $10^{-4}$. Print the number of iterations to achieve this precision and the rate of interest computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function f\n",
    "\n",
    "def finterest(i):\n",
    "    d = 30.0\n",
    "    S = 30000.0\n",
    "    n = 120.0\n",
    "    return ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Resolution\n",
    "---\n",
    "\n",
    "## prints\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"fixedPoint\"></a>\n",
    "## Fixed point iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "        <tr>\n",
    "            <td><img src=\"figures/Brouwer.jpeg\" alt=\"Brouwer\" style=\"width: 170px;\" /></td>\n",
    "            <td><img src=\"figures/Banach.jpg\" alt=\"Banach\" style=\"width: 150px;\" /></td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    ">**Luitzen Egbertus Jan Brouwer (1881 – 1966) and Stefan Banach (1892-1945).**\n",
    "> Brouwer is a Dutch mathematician and philosopher. He proved a lot of results in topology. One of his main theorem is his fixed point theorem (1909). One of its simpler form says that a continuous function from an interval to itself has a fixed point. The proof of the theorem does not provide a method to compute the corresponding fixed point. Among lot of other fixed point results, Brouwer's theorem became very famous because of its use in various fields of mathematics or in economics. In 1922, a polish mathematician, Stefan Banach, stated a contraction mapping theorem, proving in some case the existence of a unique fixed point and providing a constructive iterative method to approximate these fixed points. Banach is one of the founders of modern analysis and is often considered as one of the most important mathematicians of the 20-th century."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fixed point for a function $g$ is a number $x$ such that $g(x)=x$. In this section we consider the problem of finding solutions of fixed point problems. This kind of problem is equivalent to rootfinding problems in the following sense:\n",
    "\n",
    "- If $x^*$ is a solution to $f(x)=0$, we can find a function $g$ such that $x^*$ is a fixed point of $g$. For example, one can choose $g(x)=f(x)+x$.\n",
    "\n",
    "- If $x^*$ is a solution to $g(x)=x$, then, $x^*$ is also a solution to $f(x)=0$ where $f(x)=g(x)-x$.\n",
    "\n",
    "If the two kind of problems are equivalent, the fixed point problem is easier to analyze. In this section, we will focus on such problems in order to understand how to use them the best way for solving rootfinding problems. In the following, functions $f$ will be used for rootfinding problems and $g$ for corresponding fixed point problems.\n",
    "\n",
    "First, note that, given a function $f$, the choice of $g$ is not unique. For example, any function $g$ of the form $g(x) = G(f(x)) + x$ where $G(0)=0$ is suitable for solving the problem. Let us consider again the problem of computing an approximation of $x^*=2^{1/3}$ as the root of $f(x)=x^3-2$. The five following functions $g$ can be chosen:\n",
    "\n",
    "- $g_1(x) = x^3-2 + x $\n",
    "- $\\displaystyle g_2(x) = \\sqrt{\\frac{x^5+x^3-2}{2}}$\n",
    "- $\\displaystyle g_3(x) = -\\frac{1}{3} (x^3-2) + x $\n",
    "- $\\displaystyle g_4(x) = -\\frac{1}{20} (x^3-2) + x$\n",
    "- $\\displaystyle g_5(x) = \\frac{2}{3} x + \\frac{2}{3x^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a numerical point a view, solutions to fixed point problems can be approximated by choosing an initial guess $x_0$ for $x^*$ and generate a sequence by iterating function $g$: \n",
    "\n",
    "$$x_{k+1} = g(x_k),\\quad\\text{for}\\quad k\\geq 0.$$ \n",
    "\n",
    "Indeed, suppose that $g$ is continuous and that the sequence $(x_k)_k$ converges to $x_\\infty$, then, passing to the limit in the previous equation gives\n",
    "\n",
    "$$\n",
    "x_\\infty = g(x_\\infty)\n",
    "$$\n",
    "\n",
    "and $x_\\infty$ is a fixed point of $g$. This leads to the following algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Algo\">\n",
    "**Fixed point iterations method.** Computes a sequence $(x_k)_k$, approximating $x^*$ solution to $g(x^*)=x^*$.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "INPUT:&\\quad g, x0\\\\\n",
    "DO:&\\quad x = x0\\\\\n",
    "&\\quad \\text{While stopping criterion is not achieved do}\\\\\n",
    "&\\quad\\quad\\quad x = g(x)\\\\\n",
    "&\\quad \\text{end while}\\\\\n",
    "RETURN:&\\quad x\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for a given function $g$, one has to answer the following questions:\n",
    "- does $g$ have a fixed point ?\n",
    "- does the sequence generated using fixed point iterations converge ?\n",
    "-  if the sequence converges, how fast does it converge ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand the behaviour of fixed point iterations, one can try to visualize them on a graph.\n",
    "\n",
    "First, the fixed point of a function $g$ can be found graphically searching for the intersection between the graph of $g$ and the graph of function $\\phi(x)=x$.\n",
    "\n",
    "Then, suppose $x_0$ is given and place it on the abscissa axis. To place $x_1=g(x_1)$ on the same axis, proceed as follows:\n",
    "- from $(x_0,0)$, go up to find the point $(x_0, g(x_0)) = (x_0,x_1)$, when crossing the graph of $g$\n",
    "- from $(x_0,x_1)$ move horizontally to find the point $(x_1,x_1)$, when crossing the graph of $\\phi$\n",
    "- finally, go down towards the abscissa axis to place the point $(x_1,0)$\n",
    "\n",
    "Then iterate the procedure to vizualize the generated sequence. Four examples are given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "        <tr>\n",
    "            <td><img src=\"figures/FixedPoint1.png\" alt=\"FixedPoint1\" style=\"width: 300px;\" /></td>\n",
    "            <td><img src=\"figures/FixedPoint2.png\" alt=\"FixedPoint1\" style=\"width: 300px;\" /></td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td><img src=\"figures/FixedPoint3.png\" alt=\"FixedPoint1\" style=\"width: 300px;\" /></td>\n",
    "            <td><img src=\"figures/FixedPoint4.png\" alt=\"FixedPoint1\" style=\"width: 300px;\" /></td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases with increasing functions $g$ are given on the left and leads to monotonous sequences. On the contrary, oscillating sequences are generated for non increasing functions $g$ (right). The two examples given at the top converge. Remark that they correspond to cases where $|g'(x)|<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\">\n",
    "** Existence of a fixed point. **\n",
    "Let $g: [a,b]\\to \\mathbb{R}$. Suppose\n",
    "\n",
    "- $g\\in \\cal C [a,b]$\n",
    "- $g: [a,b] \\to [a,b]\\quad$ (i.e. $[a,b]$ is stable for $g$)\n",
    "\n",
    "Then,  $g$ has a fixed point in $[a,b]$:\n",
    "$$\n",
    "\\exists x^*\\in[a,b],\\quad g(x^*)=x^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Complete the proof of the previous theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Proof.** \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\">\n",
    "** Existence of a unique fixed point. **\n",
    "Let $g: [a,b]\\to \\mathbb{R}$. Suppose\n",
    "\n",
    "- $g\\in \\cal C [a,b]$\n",
    "- $g: [a,b] \\to [a,b]\\quad$ (i.e. $[a,b]$ is stable for $g$)\n",
    "- $g'$ exists on $[a,b]$ and\n",
    "$$\n",
    "\\exists K<1 \\quad \\text{such that} \\quad \\forall x\\in[a,b], \\quad|g'(x)|\\leq K \\quad \\text{ (i.e. }\\,\\, g \\,\\,\\text{is a contraction mapping})\n",
    "$$\n",
    "\n",
    "Then,  $g$ has a unique fixed point in $[a,b]$:\n",
    "$$\n",
    "\\exists ! x^*\\in[a,b],\\quad g(x^*)=x^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Proof.** The existence of a fixed point $x^*$ is given by the previous theorem. The fact that $g$ is a contraction mapping ensures the uniqueness of the fixed point. Indeed, suppose that $x^1$ and $x^2$ are two fixed points of $g$ and write the Taylor Lagrange expansion of $g$ around $x^1$ at order 1:\n",
    ">\n",
    ">$$\n",
    "\\exists \\xi\\in I_{x^1,x^2}, \\quad \\text{such that} \\quad  g(x^2)=g(x^1)+(x^2-x^1)\\,g'(\\xi)\n",
    "$$\n",
    ">\n",
    ">where $I_{x^1,x^2}=[x^1,x^2]$ if $x^1<x^2$ and $I_{x^1,x^2}=[x^2,x^1]$ otherwise. \n",
    ">\n",
    ">Using $g(x^1)=x^1$ and $g(x^2)=x^2$, we obtain\n",
    ">\n",
    ">$$\n",
    "x^2-x^1 = (x^2-x^1)\\,g'(\\xi)\n",
    "$$\n",
    ">\n",
    ">and using the contraction:\n",
    ">\n",
    ">$$\n",
    "|x^2-x^1|\\leq K \\,|x^2-x^1|\n",
    "$$\n",
    ">\n",
    ">which gives $x^2=x^1$ since $K<1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\">\n",
    "** Convergence of fixed point iterations. **\n",
    "Let $g: [a,b]\\to \\mathbb{R}$. Consider the sequence $x_{k+1}=g(x_k)$ for $k\\geq 0$, $x_0$ being given. Suppose\n",
    "\n",
    "- $g\\in {\\cal C} ( [a,b] )$\n",
    "- $g: [a,b] \\to [a,b]\\quad$ (i.e. $[a,b]$ is stable for $g$)\n",
    "- $g'\\in {\\cal C}^1 ([a,b])$ and\n",
    "$$\n",
    "\\exists K<1 \\quad \\text{such that} \\quad \\forall x\\in[a,b], \\quad|g'(x)|\\leq K\n",
    "$$\n",
    "\n",
    "Then,  $g$ has a unique fixed point $x^*$ in $[a,b]$ and the sequence $(x_k)_k$ converges to $x^*$ for any choice of $x_0\\in [a,b]$. Moreover we have\n",
    "\n",
    "$$\n",
    "\\lim_{k\\to\\infty} \\frac{x_{k+1}-x^*}{x_k-x^*} = g'(x^*)\n",
    "$$\n",
    "\n",
    "so that the sequence converges at least with order 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Proof.** The existence and uniqueness of the fixed point is given by the previous theorem. The convergence analysis is given again using a Taylor expansion:\n",
    ">\n",
    ">$$\n",
    "\\forall k\\geq 0, \\quad \\exists \\xi_k\\in I_{x^*,x_{k}}, \\quad \\text{such that} \\quad  g(x_k)=g(x_*)+(x_k-x^*)\\,g'(\\xi_k).\n",
    "$$\n",
    ">\n",
    ">This, together with $g(x_k)=x_{k+1}$ and $g(x^*)=x^*$ gives\n",
    ">\n",
    ">$$\n",
    "\\forall k\\geq 0, \\quad \\exists \\xi_k\\in I_{x^*,x_{k}}, \\quad \\text{such that} \\quad  x_{k+1}-x^*=(x_k-x^*)\\,g'(\\xi_k)\n",
    "$$\n",
    ">\n",
    "> From this we obtain that \n",
    ">\n",
    ">$$\n",
    "|x_{k+1}-x^*|\\leq K |x_k-x^*| \\leq K^{k+1}|x_0-x^*| \\rightarrow 0 \\quad \\text{ when } k\\to \\infty\n",
    "$$\n",
    ">\n",
    ">and the sequence converges to $x^*$.\n",
    ">Moreover, since $x_k$ converges to $x^*$, we have that $\\xi_k$ converges to $x^*$ and from the continuity of $g'$ we obtain $g'(\\xi_k)\\to g'(x^*)$ when $k$ goes to infinity. Then, we have\n",
    ">\n",
    ">$$\n",
    "\\frac{x_{k+1}-x^*}{x_k-x^*} = g'(\\xi_k) \\rightarrow g'(x^*) \\text{ when } k\\to \\infty\n",
    "$$\n",
    ">\n",
    ">which ends the proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\">\n",
    "Note that these theorems provide sufficient but not necessary condition for convergence. \n",
    "\n",
    "- If $|g'(x^*)|>1$, if $x_k$ is sufficiently close to $x^*$ we have that $g'(\\xi_k)>1$ and then $|x_{k+1}-x^*| > |x_k-x^*| $. The sequence cannot converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Complete the following function. It shall compute the sequence generated using the fixed point algorithm for a given function $g$. The algorithm terminates when a given number $K$ of iterations have been achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Fixed point algorithm for function g\n",
    "## input : g = name of the function\n",
    "##         x0 = initialization\n",
    "##         K = number of iterations\n",
    "## output : x = sequence generated using the fixed point iteration for g (x[k]=x_k)\n",
    "\n",
    "def FixedPoint(g,x0,K):\n",
    "    # create vector x\n",
    "    x = np.zeros(K+1)\n",
    "    k = 0\n",
    "    x[0] = x0  \n",
    "    # computation of x_k\n",
    "    while ---:\n",
    "        ---\n",
    "        k=k+1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Run the two following cells to test the fixed point algorithm for the functions:\n",
    "\n",
    "- $\\phi_1(x) = x-x^3$\n",
    "- $\\phi_2(x) = x+x^3$\n",
    "\n",
    "What can you conclude for the case $|g'(x^*)|=1$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# phi1(x) = x-x^3. \n",
    "\n",
    "def phi1(x):\n",
    "    return x - x**3\n",
    "\n",
    "x0 = 0.1 \n",
    "K = 20\n",
    "x=FixedPoint(phi1,x0,K)\n",
    "print('x =',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# phi1(x) = x+x^3. \n",
    "\n",
    "def phi2(x):\n",
    "    return x + x**3\n",
    "\n",
    "x0 = 0.1\n",
    "K = 20\n",
    "x=FixedPoint(phi2,x0,K)\n",
    "print('x =',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\">\n",
    "The fixed point theorem ensures the convergence of the sequence for any choice of $x_0\\in [a,b]$ and then presents a global convergence result. \n",
    "\n",
    "However, in practice, even if $|g'(x^*)|<1$, finding a stable interval on which $g$ is a contracting mapping is not so easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, one can prove that, if $g$ is continuous and differentiable and if $|g'(x^*)|<1$, such an interval exists: more precisely, there exists a neighbourhood $I$ of $x^*$ such that, for any $x_0\\in I$, the fixed point iterations converge to $x^*$. This local convergence result is stated in the following theorem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\"> ** Local convergence for fixed point iterations.** Let $g: [a,b]\\to \\mathbb{R}$. Consider the sequence $x_{k+1}=g(x_k)$ for $k\\geq 0$, $x_0$ being given. Suppose \n",
    "\n",
    "- $x^*$ is a fixed point of $g$\n",
    "- $g\\in {\\cal C} ( [a,b] )$\n",
    "- $g$ is differentiable on $[a,b]$ and $|g'(x^*)|<1$\n",
    "\n",
    "Then, there exists a neighbourhood $I$ of $x^*$ such that, for any $x_0\\in I$, the fixed point iterations converge to $x^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "From the previous estimations, we remark that the smaller is the constant $|g'(x^*)|$, the faster is the convergence. In the next theorem, we prove (among others) that for $|g'(x^*)|=0$, the convergence is quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\">\n",
    "** \"Better than linear\" speed of convergence of fixed point iterations. **\n",
    "Let $g: [a,b]\\to \\mathbb{R}$ and suppose that the hypothesis of the previous theorem are fulfilled. If \n",
    "\n",
    "- $g\\in {\\cal C^{p+1}} ( I )$ where $I$ is a neighbourhood of $x^*$ and $p$ is an integer $p\\geq 0$\n",
    "- $g^{(i)}(x^*)=0\\quad$ for $\\quad 0\\leq i \\leq p$\n",
    "- $g^{(p+1)}(x^*)\\neq 0$ \n",
    "\n",
    "Then, the fixed point iteration method with function $g$ has order $p+1$ and \n",
    "\n",
    "$$\n",
    "\\lim_{k\\to\\infty} \\frac{x_{k+1}-x^*}{(\\,x_k-x^*\\,)\\,^{p+1}} = \\frac{g^{(p+1)}(x^*)}{(p+1)!}.\n",
    "$$\n",
    "\n",
    "This proves that the sequence converges at least with order $p+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Proof.** Again, we expand $g$ around $x^*$ at order $p+1$:\n",
    ">\n",
    ">$$ \n",
    "\\forall k\\geq 0, \\quad \\exists \\xi_k\\in I_{x^*,x^{k}}, \\quad \\text{such that} \\quad  g(x_k)=g(x^*)+\\frac{(x_k-x^*)}{(p+1)!}\\,g^{(p+1)}(\\xi_k)\n",
    "$$\n",
    ">\n",
    ">and we obtain\n",
    ">\n",
    ">$$\n",
    "\\frac{x_{k+1}-x^*}{x_k-x^*} = \\frac{g^{(p+1)}(\\xi_k)}{(p+1)!} \\rightarrow \\frac{g^{(p+1)}(x^*)}{(p+1)!}  \\text{ when } k\\to \\infty\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> We consider again the 5 iteration functions proposed at the beginning of the section to compute $x^*=2^{1/3}$. Run the following cells to observe the behaviour of the algorithm for these 5 functions and comment in light of the previous theorems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xstar = 2**(1.0/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $g_1(x) = x^3-2 + x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g1(x):\n",
    "    return x**3 - 2 + x\n",
    "\n",
    "x0 = xstar + 0.001 \n",
    "#x0 = xstar - 0.001\n",
    "K = 10\n",
    "x = FixedPoint(g1,x0,K)\n",
    "print('x =',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle g_2(x) = \\sqrt{\\frac{x^5+x^3-2}{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g2(x):\n",
    "    return np.sqrt( (x**5 + x**3 - 2) / 2 )\n",
    "\n",
    "x0 = xstar - 0.001\n",
    "#x0 = xstar + 0.001\n",
    "K = 10\n",
    "x = FixedPoint(g2,x0,K)\n",
    "print('x =',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle g_3(x) = -\\frac{1}{3} (x^3-2) + x $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g3(x):\n",
    "    return - (x**3-2)/3 + x\n",
    "\n",
    "x0 = xstar + 1\n",
    "#x0 = xstar + 2\n",
    "K = 10\n",
    "x = FixedPoint(g3,x0,K)\n",
    "print('xstar =',xstar)\n",
    "print('x =',x)\n",
    "err3 = abs(x-xstar)\n",
    "print('error =',err3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle g_4(x) = -\\frac{1}{20} (x^3-2) + x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g4(x):\n",
    "    return - (x**3-2)/20 + x\n",
    "\n",
    "x0 = xstar + 1\n",
    "#x0 = sqrt(2) + 4\n",
    "K = 10\n",
    "x = FixedPoint(g4,x0,K)\n",
    "print('xstar =',xstar)\n",
    "print('x =',x)\n",
    "err4 = abs(x-xstar)\n",
    "print('error =',err4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\displaystyle g_5(x) = \\frac{2}{3} x + \\frac{2}{3x^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g5(x):\n",
    "    return 2*x/3 + 2/(3*x**2)\n",
    "\n",
    "x0 = xstar + 1\n",
    "K = 5\n",
    "x = FixedPoint(g5,x0,K)\n",
    "print('xstar =',xstar)\n",
    "print('x =',x)\n",
    "err5 = abs(x-xstar)\n",
    "print('error =',err5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Compare graphically the convergence for iterations of $g_3$, $g_4$,  and $g_5$:\n",
    "- On the same figure, plot the three errors vers $k$ with log-scale for the error. \n",
    "- On the same figure, plot the $e_{k+1}$ versus $e_k$ in log-log scale for the three methods.\n",
    "\n",
    "Do not forget titles, labels and legends. Comment the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization\n",
    "x0 = xstar + 0.2\n",
    "\n",
    "# g3 and g4: compute 10 iterations\n",
    "K=10\n",
    "tabk1 = np.arange(0,K+1,1)\n",
    "x3 = ---\n",
    "err3 = ---\n",
    "x4 = ---\n",
    "err4 = ---\n",
    "\n",
    "# g5: compute 3 iterations (if K is too big, the error reaches 0 and log-log plots fail)\n",
    "K=3\n",
    "tabk2 = np.arange(0,K+1,1)\n",
    "x5 = ---\n",
    "err5 = ---\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(121) # plot of e_k versus k for the three methods\n",
    "plt.plot(---)\n",
    "plt.plot(---)\n",
    "plt.plot(---)\n",
    "\n",
    "plt.subplot(122) #\n",
    "plt.loglog(---) #log-log scale\n",
    "plt.loglog(---) #log-log scale\n",
    "plt.loglog(---) #log-log scale\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopping criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In general, fixed point iterations are terminated using criterion 1: for $\\epsilon$ given, the computation terminates when\n",
    "\n",
    "$$\n",
    "|x_{k+1}-x_k|<\\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is justified by the fact that, using again a taylor expansion, we have:\n",
    "\n",
    "$$\n",
    "\\exists \\xi_k\\in I_{x^*,x_{k}}, \\quad \\text{such that} \\quad  g(x_{k})=g(x^*)+(x_{k}-x^*)\n",
    "\\,g'(\\xi_k)\n",
    "$$\n",
    "\n",
    "From this, together with $g(x_k)=x_{k+1}$ and $g(x^*)=x^*$ we get\n",
    "\n",
    "$$\n",
    "x^*-x_k = (x^*-x_{k+1}) + (x_{k+1}-x_k) = - (x_{k}-x^*)g'(\\xi_k) + (x_{k+1}-x_k)\n",
    "$$\n",
    "\n",
    "and finally we obtain:\n",
    "\n",
    "$$\n",
    "x^*-x_{k} = \\frac{1}{1-g'(\\xi_k)} (x_{k+1}-x_k)\n",
    "$$\n",
    "\n",
    "Consequently, if $g'(x^*)=0$ (which is the case for methods of order 2), $x_{k+1}-x_k$ is a good estimator for the error. In the case $g'(x^*)$ is close to 1, it is not safisfactory... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Newton\"></a>\n",
    "## The Newton-Raphson method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/Newton.jpg\" alt=\"Brouwer\" style=\"width: 170px;\" />\n",
    "\n",
    ">**Isaac Newton (1643 – 1727).**\n",
    "> English mathematician, astronomer, theologian, author and physicist, Isaac Newton is known as one of the most important scientists. He made breaking contributions to classical mechanics, optic and also contributed to infinitesimal calculus. In particular, he described in an unpulished work in 1671 a method to find zeros of polynomials now known as the Newton-Raphson method. Indeed, it was first published (with a reference to Newton) by another english mathematician, Joseph Raphson in 1690. Newton finally published his analysis in 1736. Both of them focused on zeros of polynomial functions but the basis of the general method was already present in their works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Newton-Raphson (or simply Newton's) method is one of the most powerful and well-known method to solve rootfinding problems $f(x)=0$. The simplest way to describe it is to see it as a graphical procedure: $x_{k+1}$ is computed as the intersection with the $x$-axis of the tangent line to the graph of $f$ at point $(x_k,f(x_k))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/NewtonFig.png\" alt=\"Algo Newton\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that the Newton's method starts with an initial approximation $x_0$ and generates the sequence of approximations $(x_k)_k$ defined by\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\frac{f(x_{k})}{f'(x_k)},\n",
    "$$\n",
    "\n",
    "which leads to the following algoritm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Algo\">\n",
    "**Newton-Raphson method.** Computes a sequence $(x_k)_k$, approximating $x^*$ solution to $f(x^*)=0$.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "INPUT:&\\quad f, x0\\\\\n",
    "DO:&\\quad x = x0\\\\\n",
    "&\\quad \\text{While stopping criterion is not achieved do}\\\\\n",
    "&\\quad\\quad\\quad x = x - \\frac{f(x)}{f'(x)}\\\\\n",
    "&\\quad \\text{end while}\\\\\n",
    "RETURN:&\\quad x\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting Newton's method as a fixed point iteration method, one can prove the following **local** convergence theorem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\"> ** Local convergence of Newton's method. ** Let $f: [a,b]\\to \\mathbb{R}$. Consider the sequence $(x_k)_k$ generated by Newton's method for $k\\geq 0$, $x_0$ being given. Suppose \n",
    "\n",
    "- $x^*$ is a root of $f$ in $[a,b]$\n",
    "- $f\\in {\\cal C^2} ( [a,b] )$\n",
    "- $f'(x^*)\\neq 0\\quad$ ($x^*$ is a simple root of $f$)\n",
    "\n",
    "Then, there exists a neighbourhood $I$ of $x^*$ such that, for any $x_0\\in I$, the Newton's iterations converge to $x^*$ and the convergence is of order 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Proof.** Let us consider function $\\displaystyle g(x)=x - \\frac{f(x)}{f'(x)}$, such that $x_{k+1}=g(x_k)$. Using continuity of $f'$, $g$ is defined in a neighbourhood $I$ of $x^*$. Moreover $g\\in {\\cal C}(I)$ and we have\n",
    ">\n",
    ">$$\n",
    "g'(x^*) = \\frac{f(x^*)\\,f''(x^*)}{(f'(x^*))^2} = 0\n",
    "$$\n",
    ">\n",
    ">so that the fixed point local convergence theorem provides a neighbourhood $\\bar I\\subset I$ of $x^*$ for which the sequence converges towards $x^*$ if $x_0\\in \\bar I$.\n",
    ">\n",
    ">If we suppose that $f\\in {\\cal C}^3(I)$, one can prove the quadratic convergence using the corresponding result of the fixed point iterations of $g\\in {\\cal C}^2(I)$. In fact, the result is still true for $f\\in {\\cal C}^2(I)$. Indeed, a Taylor expansion of $f$ gives\n",
    ">\n",
    ">$$\n",
    "0 = f(x^*) = f(x_k) + f'(x_k) (x^*-x_k) + \\frac{f''(\\xi_k)}{2}(x^*-x_k)^2 \\quad \\text{with} \\quad \\xi_k\\in I_{x^*,x_k}\n",
    "$$\n",
    ">\n",
    ">and then using that $\\xi_k\\to x^*$ we have\n",
    ">\n",
    ">$$\n",
    "\\frac{x_{k+1}-x^*}{(x_k-x^*)^2} = \\frac{f''(\\xi_k)}{2 f'(x_k)} \\rightarrow \\frac{f''(x^*)}{2 f'(x^*)}  \\text{ when } k\\to \\infty\n",
    "$$\n",
    ">\n",
    ">which proves the quadratic convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\">\n",
    "In the previous fixed-point examples to compute $x^*=2^{1/3}$, the iteration function $g_5$ was precisely the Newton's iteration function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\">\n",
    "One of the main drawback of Newton's method is that the convergence result is a local convergence result. As a consequence, the sequence has to be carrefully initialized with an approximation $x_0$ close to $x^*$, which is not so easy to do in practice. A method to do that is to run a bisection method to compute a rough approximation of $x^*$ and then to initialize Newton methods with this approximation in order to make it much more precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\">\n",
    "Another drawback of Newton's method is that it necessitates the evaluation of the derivative of $f$ at each iteration. Most of the time, $f'$ is much more difficult to evaluate than $f$ and it can even be unknown... To skip this difficulty, the derivative can be approximated by \n",
    "$$\n",
    "f'(x_k) \\approx \\frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}.\n",
    "$$\n",
    "The corresponding algorithm is called the **secant method**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Rmk\"> Another main difficulty with Newton's method is the case where $f'(x^*)$ is close to (or equal to) zero. Suppose that it is the case but that the sequence is still defined for any $x\\geq 0$ (i.e. $f'(x_k)\\neq 0$ for all $k\\geq 0$). Then\n",
    "\n",
    "- if $f'(x^*)<<1$ but $f'(x^*)\\neq 0$. The convergence is still quadratic but is very deteriorated due to the big constant $\\displaystyle\\frac{f''(x^*)}{2\\,f'(x^*)}$\n",
    "\n",
    "- if $f'(x^*)=0$, $x^*$ is a multiple root and we do not have anymore $g'(x^*)=0$. One can prove that $\\displaystyle g'(x_k)=1-\\frac{1}{m}$ where $m$ is the multiplicity of the root. From $|g'(x^*)|<1$ we obtain the local convergence of the algorithm with order 1. The quadratic convergence can be recovered using fixed point interations with $\\displaystyle g^{new}(x)=x-m\\frac{f(x)}{f'(x)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use Newton's method to solve case study 2 and 3. To do so, we first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Implement Newton's method and test it to approximate $x^*=2^{1/3}$, the unique solution in $\\mathbb R$ to $f(x) = x^3-2=0$. Check that you recover the results obtained using the fixed point iteration with function $g_5$. In this version, the stopping criterion is: stop if the maximal number of iteration is achieved, if the zero was found or if $|x_{k+1}-x_k|<\\epsilon$ with $\\epsilon$ given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Newton's algorithm for function f\n",
    "## input : f = name of the function\n",
    "##         df = name of the derivative of function f\n",
    "##         x0 = initial guess for x^*\n",
    "##         eps = precision for stopping criterion\n",
    "##         Kmax = maximal number of iterations\n",
    "## output : x = sequence approximating the zero of f\n",
    "\n",
    "def Newton(f,df,x0,eps,Kmax):\n",
    "    ---\n",
    "    return (x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test of the newton algorithm for f(x) = x^3 -2\n",
    "## comparison with the results given by the fixed point iterations for function g5 (shall be the same)\n",
    "\n",
    "x0 = xstar + 1\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Check on the previous example that $|x^{k+1}-x^k|$ is a good estimator for the error $|x^*-x^k|$ (case of a fixed point of order 2). To do so, plot the two quantities versus $k$ on the same figure. Explain why, when the algorithm stops, the precision is much better than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err = ---\n",
    "criterion = ---\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "---\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 2: Investment found, a solution using Newton's algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that we have to find $i$ solution to\n",
    "\n",
    "$$\n",
    "f(i) = d \\frac{(1+i)^{n_{end}}-1}{i} - S =0 \\quad \\text{ where } \\quad S=30\\,000, \\quad d=30,\\quad \\text{and} \\quad n_{end} = 120\n",
    "$$\n",
    "\n",
    "We compare to the results obtained using the bisection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> We use Newton's method to solve case study 2 with tolerance $10^{-4}$. Compare the results (value computed and number of iterations) with the ones obtained using the bisection algorithm. If the bisection method is initialised by the interval $[a,b]$, Newton's method can be initialized by the initial guess $x_0=b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## derivative of function finterest\n",
    "\n",
    "def dfinterest(i):\n",
    "    ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Resolution using bisection\n",
    "---\n",
    "\n",
    "## Resolution using Newton\n",
    "---\n",
    "\n",
    "## prints\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study 3: A first population model, a solution using Newton's algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find an approximation for the natural growth rate $\\lambda$ in France. To do so, we have to solve the following non-linear equation for $\\lambda$ (we know that $\\lambda \\neq 0$ since the population increases more than the migratory balance):\n",
    "\n",
    "$$\n",
    "f(\\lambda) = N(2017) - N(2016)\\exp(\\lambda) - \\frac{r}{\\lambda}(\\exp(\\lambda)-1)\n",
    "$$\n",
    "\n",
    "where N(2016)=66 695 000, N(2017)=66 954 000 and r=67 000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Use Newton's method to solve the problem with precision $10^{-4}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Resolution of case study 3 using Newton's method\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div markdown=1 class=\"DoIt\"> Using the value of $\\lambda$ you computed, and assuming that the migratory balance will be the same in 2017, compute an estimation of the population in France at the beginning of year 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Estimation of the population at the beginning of 2018 in France\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Intermediate value thm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  markdown=1 class=\"Thm\">\n",
    "** Intermediate value Theorem**\n",
    "\n",
    "Suppose $f: [a,b]\\mapsto \\mathbb{R}$ is continuous on $[a,b]$. Define $m=\\min\\{f(a),f(b) \\}$ and $M=\\max\\{f(a),f(b) \\}$. Then,\n",
    "\n",
    "$$\n",
    "\\forall y \\in ]m,M[,\\quad \\exists x\\in]a,b[,\\quad \\text{such that}\\quad f(x)=y.\n",
    "$$\n",
    "\n",
    "As a consequence, if a continuous function has values of opposite signs in an interval, it has a root in this interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure provides an example of choice for $x$ garanteed by this theorem. In this case, the choice is not unique.\n",
    "\n",
    "<img src=\"figures/ThmValInt.png\" alt=\"Intermediate Value Thm\" style=\"width: 600px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Oswald|Raleway\" rel=\"stylesheet\" type='text/css'> \n",
       "<style>\n",
       ".prompt{\n",
       "    display: none !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre {\n",
       "    border: 1px solid #f0f6f9 !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre, .rendered_html code {\n",
       "    background-color: #d3d8db !important;\n",
       "    padding: 1% !important;\n",
       "    line-height: 200% !important;\n",
       "    border-radius: 10px !important;\n",
       "}\n",
       "\n",
       "div.input_area {\n",
       "    border-radius: 10px !important;\n",
       "    background-color: #e1e1e6 !important;\n",
       "}\n",
       "\n",
       "div.cell{\n",
       "        width:85% !important;\n",
       "        margin-left:5% !important;\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    h1, h2, h3, h4, h5 {\n",
       "        font-family: 'Oswald', sans-serif; !important;\n",
       "        font-style: oblique !important;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Raleway', sans-serif; !important;\n",
       "        line-height: 135% !important;\n",
       "        font-size: 120% !important;\n",
       "        width:100%;/*600px;*/\n",
       "        /*margin-left:auto;*/\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\" !important;\n",
       "\t\t\tfont-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render p{\n",
       "        text-align: justify !important;\n",
       "    }\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 10.em !important;\n",
       "        margin-top: 50.em !important;\n",
       "        padding-bottom: 50.em !important;\n",
       "        padding-top: 50.em !important;\n",
       "        display: block !important;\n",
       "        font-size: 300% !important;\n",
       "        text-align: center !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "        border-top: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200 !important;\n",
       "\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 200% !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200 !important;\n",
       "\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 150% !important;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-style: italic !important;\n",
       "        font-weight: bold !important;\n",
       "\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200 !important;\n",
       "\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render ul {\n",
       "\tlist-style-type: disc !important;\n",
       "\tline-height: 2;\n",
       "\t/*color:#47597A !important;*/\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 ) !important;\n",
       "        }\n",
       "    .Abstract {  \n",
       "\ttext-align: justify;\n",
       "\tbackground-color: #d6edf9;\n",
       "\tborder-left: 5px solid #47597A;\n",
       "\tpadding: 0.5em;\n",
       "\tmargin: 0  150px 0 150px;\n",
       "    }\n",
       "    .Def {    \n",
       "\tbackground-color: #d9f7d7;\n",
       "\tborder-left: 5px solid #4a7047;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "    .Def:before {\n",
       "\tcontent: \"Definition.\";\n",
       "\tcolor:#4a7047;\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: normal;\n",
       "    }\n",
       "    .DoIt {    \n",
       "\tbackground-color: #e8cfc9;\n",
       "\tborder-left: 5px solid #a90e05;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "    .DoIt:before {\n",
       "\tcontent: \"Do it yourself.\";\n",
       "\tcolor:#a90e05;\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: normal;\n",
       "    }\n",
       "    .Prop {    \n",
       "\tbackground-color:#f9ecd1;\n",
       "\tborder-left: 5px solid #ba7021;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "   .Prop:before {\n",
       "       content: \"Proposition.\";\n",
       "       color:#ba7021;\n",
       "       font-weight: bold;\n",
       "       font-style: normal;\n",
       "    }\n",
       "   .Thm {    \n",
       "\tbackground-color:#f9ecd1;\n",
       "\tborder-left: 5px solid #ba7021;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "   .Thm:before {\n",
       "       content: \"Theorem.\";\n",
       "       color:#ba7021;\n",
       "       font-weight: bold;\n",
       "       font-style: normal;\n",
       "    } \n",
       "   .Algo {    \n",
       "\tbackground-color:#f9ecd1;\n",
       "\tborder-left: 5px solid #ba7021;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "   .Algo:before {\n",
       "       content: \"Algorithm.\";\n",
       "       color:#ba7021;\n",
       "       font-weight: bold;\n",
       "       font-style: normal;\n",
       "    }\n",
       "    .Rmk {    \n",
       "\tbackground-color: #dbf1fc;\n",
       "\tborder-left: 5px solid #385487;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "    .Rmk:before {\n",
       "\tcontent: \"Remark.\";\n",
       "\tcolor:#385487;\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: normal;\n",
       "    }\n",
       "    .Ex {    \n",
       "\tbackground-color: #dbf1fc;\n",
       "\tborder-left: 5px solid #385487;\n",
       "\tpadding: 0.5em;\n",
       "    }\n",
       "    .Ex:before {\n",
       "\tcontent: \"Example.\";\n",
       "\tcolor:#385487;\n",
       "\tfont-weight: bold;\n",
       "\tfont-style: normal;\n",
       "    }\n",
       "\n",
       "/*    .toc-item-num {\n",
       "#        display: none;\n",
       "#    }\n",
       "*/\n",
       "    .reveal section img{\n",
       "        margin: 0px auto;\n",
       "    }\n",
       "\n",
       "    div.output_area img{\n",
       "        display: block;\n",
       "        margin: 0px auto;\n",
       "    }\n",
       "  \n",
       "</style>\n",
       "\n",
       "<script>\n",
       "MathJax.Hub.Config({\n",
       "TeX: {extensions: [\"AMSmath.js\"] },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "\n",
       "\n",
       "\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute this part to modify the css style\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./style/custom2.css\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
