\documentclass[a4paper]{article}
\input{../../Definitions.tex}

\title{New preconditioners for Laplace and  Helmholtz integral equation on open curves: \\ \vspace{0.5cm}
	\begin{Large} 
		II. Theoretical analysis.
	\end{Large} }
\author{Martin Averseng\footnote{CMAP, Ecole polytechnique, Route de Saclay, 91128 Palaiseau Cedex.}}
\begin{document}
\maketitle

\begin{abstract}
	We apply pseudo-differential operators theory to the first-kind integral equations on open curves, allowing us to analyze two new preconditioners and study the convergence orders of a Galerkin method on weighted $L^2$ spaces.  
\end{abstract}

\section*{Introduction}

In \cite{alouges2018new} some new square-root preconditioners for the Laplace and Helmholtz integral equations have been introduced and their numerical efficiency has been demonstrated on several examples. Here, we develop the theory to prove the main results that were announced there. To this aim, we analyze the spaces $(T^s)_{s\in \R}$ and $(U^s)_{s \in \R}$, which are interlacing spaces of Chebyshev series defined on the unit segment. They provide two Hilbert interpolating scales suited to the definition of a new kind of pseudo-differential operators. The symbolic calculus available in those classes allows us to analyze the efficiency of the preconditioners of \cite{alouges2018new}. We also prove optimal approximation results for piecewise affine functions in a simple weighted Galerkin setting. 
In the first section, we establish some properties of the spaces $T^s$ and $U^s$. After briefly collecting some facts on periodic pseudo-differential operators in the second section, we define the two new classes of pseudo-differential operators. In the third section, we apply this theory to the aforementioned preconditioners. Finally, the Galerkin analysis is exposed in the fourth section. 
 
\section{Spaces $T^s$ and $U^s$}

\subsection{Definitions}

\label{sec:analyticalSetting}

The Chebyshev polynomials of first and second kinds are respectively given by
\[T_n(x) = \cos(n \arccos(x)),\]
and 
\[U_n(x) = \dfrac{\sin((n+1) \arccos(x))}{\sqrt{1 - x^2}}\,\]
for $x \in [-1,1]$, see \cite{mason2002chebyshev}. Letting $\partial_x$ the derivation operator, they satisfy
the ordinary differential equations
\begin{eqnarray}
	(1-x^2)\partial_{xx}T_n -x\partial_x T_n +n^2T_n &=& 0\label{preCheb1} \\ 
	(1-x^2)\partial_{xx}U_n -3x\partial_{x}U_n +n(n+2)U_n &=&0 \label{preCheb2}
\end{eqnarray}
Let $\omega$ the operator $u(x) \mapsto \omega(x)u(x)$ with $\omega(x) = \sqrt{1 - x^2}$. Equations \eqref{preCheb1} and \eqref{preCheb2} can be rewritten under the form
\begin{eqnarray}
	-(\omega\partial_x)^2 T_n &=& n^2T_n\,, \label{cheb1}\\
	-(\partial_x\omega)^2 U_n &=& (n+1)^2U_n\, .\label{cheb2}
\end{eqnarray}
Notice that $\partial_x\omega$ refers to the operator $f \mapsto \partial_x(\omega f)$ and not the function $\partial_x\omega(x)$. 



Both $T_n$ and $U_n$ are polynomials of degree $n$, and provide respectively a basis of the following Hilbert spaces
$$L^2_{\frac{1}{\omega}} \isdef \enstq{u \in L^1_\textup{loc}(-1,1)} {\int_{-1}^{1} \dfrac{\abs{u(x)}^2}{\sqrt{1 - x^2} }dx< + \infty}$$
and 
$$L^2_{\omega} \isdef \enstq{u \in L^1_\textup{loc}(-1,1)} {\int_{-1}^{1} {\abs{u(x)}^2}{\sqrt{1 - x^2} }dx< + \infty}.$$
We denote by $\inner{\cdot}{\cdot}_\frac{1}{\omega}$ and $\inner{\cdot}{\cdot}_\omega$ the inner products in $L^2_{\frac{1}{\omega}}$ and $L^2_{\omega}$,
\[\inner{u}{v}_{\frac{1}{\omega}} \isdef \frac{1}{\pi}\int_{-1}^{1} \frac{u(x) \overline{v(x)}}{\omega(x)}dx\,, \quad \inner{u}{v}_{\omega} \isdef \frac{1}{\pi}\int_{-1}^{1} {u(x) \overline{v(x)}}{\omega(x)}dx\,.\]
The Chebyshev polynomials satisfy
\begin{equation}
	\inner{T_n}{T_m}_\frac{1}{\omega} = \left\{
	\begin{array}{l}
	0 \mbox{ if } n\ne m\\
	1 \mbox{ if } m=n=0\\
	1/2 \mbox{ otherwise}
	\end{array} 
	\right.
\end{equation}
and
\begin{equation}
	\inner{U_n}{U_m}_{\omega} = \left\{
	\begin{array}{l}
	0 \mbox{ if } n\ne m\\
	1/2 \mbox{ otherwise,}
	\end{array} 
	\right.
\end{equation}
from which we obtain the so-called Fourier-Chebyshev decomposition: any
$u\in L^2_{\frac{1}{\omega}}$ can be decomposed through the first kind Chebyshev series 
\begin{equation}
	u(x) = \sum_{n=0}^{+\infty} \hat{u}_n T_n(x)\,.
	\label{FCseries}
\end{equation}
where the Fourier-Chebyshev coefficients of the first kind are given by $\hat{u}_n = \frac{\inner{u}{T_n}_{\frac{1}{\omega}}}{\inner{T_n}{T_n}_{\frac{1}{\omega}}}$ and satisfy the Parseval equality
\[\forall (u,v) \in L^2_\frac{1}{\omega} \quad  \inner{u}{v}_\frac{1}{\omega} = \hat{u}_0 \overline{\hat{v}}_0 + \frac{1}{2}\sum_{n=1}^{+\infty}\hat{u}_n \overline{\hat{v}}_n \,.\]
When $u$ is furthermore a smooth function, on can check that the series \eqref{FCseries} converges uniformly to $u$. Similarly, any 
function $v\in L^2_{\omega}$ can be decomposed along the $U_n$ as
\[ v(x) = \sum_{n=0}^{+\infty} \check{v}_n U_n(x)\]
where the Fourier-Chebyshev coefficients of the second kind $\check{v}_n$ are given by $ \check{v}_n \isdef 
\frac{\inner{v}{U_n}_\omega}{\inner{U_n}{U_n}_\omega}$ with the Parseval identity
\[ \inner{u}{v}_\omega =  \frac{1}{2} \sum_{n=0}^{+\infty}\check{u}_n \overline{\check{v}}_n \,.\]
The preceding analysis can be generalized to define Sobolev-like spaces. 
\begin{Def}
	We define $T^s$ as the set of formal series
	\[u = \sum_{n \in \N} \hat{u}_n T_n\]
	where the coefficients $\hat{u}_n$ satisfy
	\[\sum_{n \in \N} (1 + n^2)^s \abs{\hat{u}_n}^2 < + \infty\,.\]
	Let $T^{\infty} = \displaystyle\cap_{s \geq 0} T^s$ and $T^{-\infty} = \cup_{s \in \R} T^s$. For $u\in T^s$ when $s \geq 0$, the series defining $u$ converges in $L^2_\frac{1}{\omega}$ and the Fourier-Chebysehv coefficients of the first kind of $u$ coincide with $\hat{u}_n$, allowing to identify $T^s$ to a subspace of $L^2_\frac{1}{\omega}$ with $T^0 = L^2_\frac{1}{\omega}$. For all $u \in T^{s}$, we define the linear form $\duality{u}{\cdot}_\frac{1}{\omega}$ by
	\begin{equation}
	\label{dualiteTs}
		\forall \varphi \in T^\infty, \duality{u}{\varphi}_\frac{1}{\omega} = \frac{1}{2} \hat{u}_0 \varphi_{0} + \frac{1}{2}\sum_{n = 1}^{+ \infty} \hat{u}_n \hat{\varphi}_n\,.
	\end{equation}
	This linear form has a unique continuous extension on $T^{-s}$, and the dual of $T^s$ is the set of linear forms $\duality{u}{\cdot}_\frac{1}{\omega}$ where $u \in T^{-s}$.  
	For $u,v \in T^s$ with $s \geq 0$, by Parseval's equality 
	\[\duality{u}{v}_\frac{1}{\omega} = \inner{u}{\overline{v}}_\frac{1}{\omega} = \frac{1}{\pi}\int_{-1}^{1} \frac{uv} {\omega}\,.\]
	Endowed with the scalar product
	\[(u,v)_{T^s} \isdef \hat{u}_0 \overline{\hat{v}}_0 + \frac{1}{2}\sum_{n=1}^{+\infty}(1 + n^{2})^s\hat{u}_n \overline{\hat{v}}_n\,,\]
	$T^s$ is a Hilbert space for all $s$. A semi-norm on $T^s$ can be defined as
	\[\abs{u}_{T^s}^2 \isdef \frac{1}{2}\sum_{n = 1}^{+ \infty}n^{2s} \abs{\hat{u}_n}^2.\] 
\end{Def}
\begin{Def}
	In a similar fashion, we define $U^{s}$ as the set of formal series 
	\[u = \sum_{n \in \N}\check{u}_n U_n\]
	where the coefficients $\check{u}_n$ satisfy
	\[\sum_{n \in \N} (1 + n^2)^s \abs{\check{u}_n}^2 < + \infty\,.\]
	Let $U^\infty = \cap_{s \in \R} U^s$ and $U^{-\infty} = \cup_{s \in \R} U^s$. For $u \in U^s$ when $s \geq 0$, the series defining $u$ converges in $L^2_{\omega}$ and the Fourier-Chebyshev coefficients of the second kind of $u$ coincide with $\check{u}_n$, allowing to identify $U^s$ to a subspace of $L^2_{\omega}$ with $U^0 = L^2_\omega$. For all $u \in U^s$, we define the linear form $\duality{u}{\cdot}_\omega$ by 
	\begin{equation}
		\label{dualiteUs}
		\forall \varphi \in U^\infty, \duality{u}{\varphi}_\omega \isdef \frac{1}{2} \sum_{n = 0}^{+ \infty} \check{\varphi_n}\check{u}_n\,.
	\end{equation}
	This linear form has a unique continuous extension on $U^{-s}$, and the dual of $U^s$ may be identified to $U^{-s}$ with respect to the bilinear form $\duality{\cdot}{\cdot}_{\omega}$. For $u,v \in U^s$ with $s \geq 0$, by Parseval's equality 
	\[\duality{u}{v}_\omega = \inner{u}{\overline v}_\omega = \int_{-1}^{1} uv \omega \,.\]
	Endowed with the scalar product
	\[\inner{u}{v}_{U^s} \isdef \frac{1}{2}\sum_{n \in \N} \left(1 + (n + 1)^2\right)^s \check{u}_n \overline{\check{v}}_n\,,\] 
	$U^s$ is a Hilbert space for all $s \in \R$. 
\end{Def}
\noindent Let $s_1,s_2 \in _R$, $\theta \in (0,1)$ and let $s = \theta s_1 + (1-\theta)s_2$. It is easy to check that
\[\forall u \in T^\infty, \norm{u}_{T^s} \leq \norm{u}_{T^{s_1}}^\theta \norm{u}_{T^{s_2}}^{1 - \theta}\]
and 
\[\forall u \in U^\infty, \norm{u}_{U^s} \leq \norm{u}_{U^{s_1}}^\theta \norm{u}_{U^{s_2}}^{1 - \theta}\]
Therefore, $(T^s)_{s \in \R}$ and $(U^s)_{s \in \R}$ are interpolation scales. 
The spaces $T^s$ and $U^s$ are related through a variable change to the standard Sobolev spaces of periodic functions which we briefly define here. 

\subsection{Basic properties}

For any real $s$, if $u \in T^s$ the sequence of polynomials 
\[S_N(x) = \sum_{n=0}^{N} \hat{u}_n T_n(x)\]
converges to $u$ in $T^s$. The same assertion holds for $u \in U^s$ when $T_n$ is replaced by $U_n$. Therefore
\begin{Lem}
	\label{densite}
	$C^{\infty}([-1,1])$ is dense in $T^s$ and $U^s$ for all $s \in \R$.
\end{Lem}
\noindent The polynomials $T_n$ and $U_n$ are connected by the following formulas:
\begin{equation}
\label{TnAsUn}
T_0 = U_0, \quad T_1 = \frac{U_1}{2}, \quad \text{ and } \forall n \geq 2, \quad T_n = \frac{1}{2}\left(U_n - U_{n-2}\right),
\end{equation}
\begin{equation}
\label{UnAsTn}
\forall n \in \N, \quad U_{2n} = 2\sum_{j = 0}^n T_{2j} - 1, \quad U_{2n+1} = 2\sum_{j=0}^n T_{2j+1}.
\end{equation}
This leads to introduce the map  
\[I : T^{\infty} \to U^{\infty}\]
defined by 
\[\reallywidecheck{I \varphi}_0 = \hat{\varphi}_0 - \frac{\hat{\varphi}_2}{2}, \quad \reallywidecheck{I \varphi}_j = \frac{\hat{\varphi}_j - \hat{\varphi}_{j+2}}{2} \textup{ for } j \geq 1.\]
$I$ is bijective has the explicit inverse
\[\widehat{I^{-1} \varphi}_{0} = \sum_{n=0}^{+ \infty} \check{\varphi}_{2n}, \quad  \widehat{I^{-1}\varphi}_j = 2\sum_{n=0}^{+\infty} \check{\varphi}_{j + 2n} \textup{ for } j \geq 1.\]
\begin{Lem}
	\label{inclusionsTsUs}
	For all real $s$, $I$ has a unique continuous extension from $T^s$ to $U^s$ and for $s> \frac{1}{2}$, $I^{-1}$ has a continuous extension from $U^s$ to  $T^{s-1}$.
\end{Lem}
\noindent Before starting the proof, we introduce the Cesàro operator $C$ defined on $l^2(\N^{*})$ by
\[(Cu)_n = \frac{1}{n}\sum_{k=1}^n u_k\,.\]
As is well-known, this is a linear continuous operator on the Hilbert space $l^2(\N^*)$. Its adjoint
\[(C^* u)_n = \sum_{k = n}^{+ \infty} \frac{u_k}{k} \,,\]
is therefore also continuous on $l^2(\N^*)$. In other words, for all $u \in l^2(\N)$, 
\[ \sum_{n = 1}^{+ \infty} \left(\sum_{k = n}^{+ \infty} \frac{u_k}{k}\right)^2 \leq C \sum_{k = 1}^{+ \infty} u_k^2\, .\]
\begin{proof}
	The first result is immediate from the definition of $T^s$, $U^s$ and $I$. 
	When $u \in U^{s}$ for $s > 1/2$, the series $\sum \abs{\check{u}_n}$ is converging thus $I^{-1}u$ is well defined.
	Since $u \in U^s$, the sequence $\left((1+n^2)^{s/2} \abs{\check{u}_n}\right)_{n \geq 1}$ is in $l^2(\N^*)$. Thus, using the continuity of the adjoint of the Cesàro operator mentioned previously, the sequence $(r_n)$ defined by 
	\[\forall n \geq 0, \quad r_n \isdef \sum_{k=n}^{+ \infty} (1+k^2)^{\frac{s-1}{2}} \abs{\check{u}_k} \] is in $l^2(\N)$ with a $l^2$ norm bounded by $\norm{u}_{U^s}$. We now write
	\begin{eqnarray*}
		\norm{I^{-1} u}_{T^{s-1}}^2 &=& \sum_{n=0}^{+ \infty} (1 + n^2)^{s-1} \abs{\widehat{I^{-1} u}_n}^2\\ 
		&\leq& 4\sum_{n=0}^{+\infty}(1+n^2)^{s-1} \left(\sum_{k=n}^{+\infty} \abs{\check{u}_k}\right)^2 \\
		&\leq& 4\sum_{n=0}^{+ \infty}\left(\sum_{k=n}^{+\infty}(1+k^2)^{\frac{s-1}{2}} \abs{\check{u}_k})\right)^2.\\
		&=& 4\norm{r_n}^2_{l^2}
	\end{eqnarray*}	
	We saw that the last quantity is controlled by $\norm{u}_{U^s}^2$ so the result is proved.
\end{proof}
\noindent \toDo{Début d'une digression à potentiellement enlever (mais garder dans le manuscrit).}
\begin{Lem}
	Let $s > 1/2$ and let $u \in U^{s}$. Then there exists $0 < \varepsilon < 1$ such that ${\omega^{-\frac{1 + \varepsilon}{2}}}u \in L^2_\omega$ with 
	\[\norm{\omega^{-\frac{1 + \varepsilon}{2}}u}_\omega \leq C \norm{u}_{U^s}\,.\]
	\begin{proof}
		We start by showing the following estimate
		\[\forall \varepsilon \in (0, 1),  \, \exists C_\varepsilon : \forall n \in \N, \quad I_n \isdef \int_{-1}^{1} U_n^2 \omega^{-\varepsilon} \leq C_\varepsilon (n+1)^{\varepsilon}\,.\]
		Fix $ \varepsilon \in (0,1)$. Using the variable change $x = \cos\theta$ and the symmetry of the integrand with respect to the change $\theta \to \pi - \theta$, we transform the quantity to be estimated to
		\[I_{n} = \int_{0}^{\frac{\pi}{2}} \frac{\sin((n+1)\theta)^2}{\abs{\sin\theta}^{1 + \varepsilon}}d\theta\,.\]
		We split $I_n$ into two parts. Let $I_{n,1} =  \int_{0}^{\frac{\pi}{n+1}} \frac{\sin((n+1)\theta)^2}{\abs{\sin\theta}^{1 + \varepsilon}}d\theta$. On this interval, we use $\sin((n+1)\theta) \leq (n+1)\theta$ and $\sin\theta \geq \frac{2}{\pi}\theta$ to find 
		\[I_{n,1} \leq C (n+1)^2\int_{0}^{\frac{\pi}{n+1}} \theta^{1 - \varepsilon} \leq C_{\varepsilon,1} (n+1)^{\varepsilon}\,.\]
		Let $I_{n,2} = I - I_{n,1}$. On this interval, we estimate the numerator by 
		\[\sin((n+1)\theta) \leq 1\] 
		and use the same estimate as before for the denominator. One can check that this leads to $I_{n,2} \leq C_{\varepsilon,2}n^{\varepsilon}$. The proof of the main result is now as follows. Let $u \in U^s$ where $s > \frac{1}{2}$ and let $s = \frac{1}{2} + \varepsilon$. Then the series 
		\[{\omega^{-\frac{1 + \varepsilon}{2}}}u = \sum_{n \in \N} \check{u}_n \frac{U_n}{\omega^{\frac{1 +\varepsilon}{2}}}\]
		converges in $L^2_\omega$ since 
		\[\begin{split}
		\sum_{n \in \N} \norm{\check{u}_n \frac{U_n}{\omega^{\frac{1+\varepsilon}{2}}}}_{L^2_\omega} &\leq C \sum_{n \in \N} \abs{\check{u}_n} (n+1)^{\frac{\varepsilon}{2}}\\
		&\leq C \sqrt{\sum_{n\in \N}(n+1)^{2s}\abs{\check{u}_n}^2} \sqrt{\sum_{n\in \N}(n+1)^{-1 - \varepsilon}}\\
		&\leq C \norm{u}_{U^s}\end{split}\,.\]
		Thus $\frac{u}{\omega^{\frac{1 + \varepsilon}{2}}} \in L^2_\omega$ by normal convergence and the result is proved. 
	\end{proof} 
\end{Lem}
\noindent Notice that for $\varphi \in \Cinf([-1,1])$, for all $\varepsilon > 0$, ${\omega^{-\frac{1-\varepsilon}{2}}} \varphi \in L^2_\omega$. 
\begin{Cor}
	Let $u \in T^{-\infty}$. Then $Iu \in U^{-\infty}$ is characterized by
	\[\forall \varphi\in \Cinf([-1,1]),\quad \duality{Iu}{\varphi}_\omega = \duality{u}{\omega^2 \varphi}_\frac{1}{\omega}\,.\]
	Let $u \in U^s$ with $s > \frac{1}{2}$. Let $\varepsilon$ such that $\omega^{-\frac{1+ \varepsilon}{2} }u \in L^2_\omega$. Then $I^{-1}u \in T^{-\infty}$ is characterized by 
	\[\forall \varphi\in \Cinf([-1,1]), \quad \duality{I^{-1}u}{\varphi}_\frac{1}{\omega}=\inner{{\omega^{-\frac{1+ \varepsilon}{2} }u}}{{\omega^{-\frac{1- \varepsilon}{2} }\overline \varphi}}_\omega \]
\end{Cor}
\begin{proof}
	We only treat the second statement, the first one being similar and simpler. By density of $\Cinf([-1,1])$ in $U^s$, we can fix a sequence of $\Cinf$ functions $u_N$ converging to $u$ in $U^s$. Then, the sequence $\omega^{-\frac{1 + \varepsilon}{2}}u_N$ converges to $\omega^{-\frac{1 + \varepsilon}{2}}u$ in $L^2_\omega$ since, by the previous result,
	\[\norm{\omega^{-\frac{1+ \varepsilon}{2}}(u_N - u)}_{L^2_\omega} \leq C \norm{u - u_N}_{U^{s}}\,.\]
	Thus, there holds 
	\[\lim_{N \to \infty} \inner{{\omega^{-\frac{1+ \varepsilon}{2} }u_N}}{{\omega^{-\frac{1- \varepsilon}{2} }\overline \varphi}}_\omega = \inner{{\omega^{-\frac{1+ \varepsilon}{2} }u}}{{\omega^{-\frac{1- \varepsilon}{2} }\overline \varphi}}_\omega\,.\]
	By continuity of $I^{-1}$ from $U^s$ to $T^{s - 1}$, we also have 
	\[\lim_{N \to \infty}\duality{I^{-1} u_N}{\varphi}_{\frac{1}{\omega}} = \duality{I^{-1} u}{\varphi}_{\frac{1}{\omega}}\,. \]
	Since for all $N$, $I^{-1}u_N = u_N \in \Cinf([-1,1])$, we obviously have 
	\[\duality{I^{-1}u_N}{\varphi}_{\frac{1}{\omega}} =  \inner{{\omega^{-\frac{1+ \varepsilon}{2} }u_N}}{{\omega^{-\frac{1- \varepsilon}{2} }\overline \varphi}}_\omega\,.\] 
	This implies the result.
\end{proof}
\noindent\toDo{Fin d'une digression potentiellement à enlever.}\\
\noindent Let
\[u = \sum_{n \in \N } \hat{u}_n T_n, \quad v = \sum_{n \in \N} \check{v}_n U_n\,.\]
When $Iu = v$, we identify $u$ to $v$ as a member of $U^{-\infty}$, and $v$ to $u$ as a member of $T^{-\infty}$. The previous results have shown that this identification is compatible with the equality of functions in $L^2_\frac{1}{\omega}$ or $L^2_\omega$. The mapping property of $I$ can then be rephrased in the following continuous inclusions:
\begin{Cor}
	For all $s \in \R$, $T^s \subset U^s$ and for all $s > \frac{1}{2}$, $U^s \subset T^{s-1}$.    
\end{Cor}
\noindent 
One immediate consequence of the previous result is that $T^{\infty} = U^{\infty}$. Moreover, there holds
\begin{Lem}
	\[T^{\infty} = C^{\infty}([-1,1])\,.\]
	\label{LemTinfCinf}
\end{Lem}
\begin{proof}
	If $u \in C^{\infty}([-1,1])$, then we can obtain by induction using integration by parts and \eqref{cheb1}, that for any $k \in \N$
	\[\hat{u}_n = \frac{(-1)^k}{n^{2k}} \int_{-1}^{1} \dfrac{(\omega\partial_x)^{2k} u(x) T_n(x)}{\omega(x)}dx.\]
	Noting that $(\omega \partial_x)^2 = (1-x^2)\partial_x^2 - x \partial_ x$, the function $(\omega \partial_x)^{2k}u$ is $C^{\infty}$, and since $\norm{T_n}_\infty = 1$, the integral is bounded independently of $n$. Thus, the coefficients $\hat{u}_n$ have a fast decay, proving that $C^{\infty}([-1,1]) \subset T^{\infty}$. 
	
	For the converse inclusion, if $u \in T^{\infty}$, the series
	\[ u(x) = \sum_{n=0} \hat{u}_n T_n(x)\]
	is normally converging since $\norm{T_n}_\infty = 1$, so $u$ is a continuous function. This proves $T^{\infty} \subset C^0([-1,1])$. It suffices to show that $\partial_x u \in T^{\infty}$ and apply an induction argument. Applying term by term differentiation, since $\partial_x T_n = n U_{n-1}$ for all $n$ (with $U_{-1} = 0$),
	\[\partial_x u(x) = \sum_{n=1}^{+\infty} n \hat{u}_n U_{n-1}(x).\] 
	Therefore, $\partial_x u$ is in $U^{\infty} = T^{\infty}$ which proves the result.
\end{proof}
\begin{Lem}
	For $s \leq \frac{1}{2}$, the functions of $U^s$ cannot be identified to functions in $T^{-\infty}$. 	
\end{Lem}
\begin{proof}
	Let $s \leq \frac{1}{2}$, and let us assume by contradiction that the functions of $U^{s}$ can be identified to elements of $T^{-\infty}$. Then, there must exist a continuous map $I$ from $U^{s}$ to $T^{-\infty}$ with the property 
	\[\forall u \in C^{\infty}([-1,1]), \quad Iu = u.\]
	We introduce the function $u$ defined by $\check{u}_n = \frac{1}{n \ln(n)}$. One can check that $u \in U^{\frac{1}{2}} \subset U^s$, thus $Iu$ must be element of $T^{-\infty}$. For all $N$, the function 
	\[u_N = \sum_{n = 0}^{N} \check{u}_n U_n\]
	is in $U^{\infty}$ and $(u_N)_{N \in \N}$ converges to $u$ in $U^{s}$. By continuity of $I$, the sequence $(\duality{I u_N}{T_0}_\frac{1}{\omega})_{N\in \N}$ must converge with limit $\duality{Iu}{T_0}_\frac{1}{\omega}$. But since $Iu_N = u_N$, 
	\[\duality{Iu_N}{T_0}_\frac{1}{\omega} = \duality{u_N}{T_0}_\frac{1}{\omega} = \sum_{n=0}^{N} \check{u}_n\duality{U_n}{T_0}_\frac{1}{\omega} = \sum_{k = 0}^{\lfloor \frac{N}{2} \rfloor} \frac{1}{2k \ln(2k)}\,. \]
	This sum diverges to $+\infty$ when $N$ goes to infinity, giving the contradiction.
\end{proof}
Two natural derivation operators, $\partial_x$ and $\omega \partial_x \omega$, arise in our context, giving another link between $T^s$ and $U^s$. They are given by the identities 
\begin{align}
	\partial_x T_n &= n U_{n-1}\,, \label{der1} \\
	-\omega \partial_x \omega U_n &= (n+1)T_{n+1}\,. \label{der2}
\end{align}
The first one is obtained for example from the trigonometric definition of $T_n$. This combined with $-(\omega \partial_x)^2 T_n = n^2 T_n$ gives the second identity. 
\begin{Lem}
	\label{derivations}
	For all real $s$, the operator $\partial_x$ can be extended into a continuous map from $T^{s+1}$ to $U^{s}$ defined by 
	\[\forall v \in \Cinf([-1,1]), \quad \duality{\partial_x u}{v}_{\omega} \isdef -\duality{u}{\omega \partial_x \omega v}_{\frac{1}{\omega}} \,.\] 
	In a similar fashion, the  operator $\omega \partial_x \omega$ can be extended into a continuous map from $U^{s+1}$ to $T^{s}$ defined by
	\[\forall v \in \Cinf([-1,1]), \quad \duality{\omega \partial_x \omega u}{v}_\frac{1}{\omega} \isdef -\duality{u}{\partial_x v}_\omega.\]
\end{Lem}
\begin{proof}
	Using \cref{der1,der2}, one can check that the formulas indeed extend the usual definition of the two operators for smooth functions. We now show that the map $\partial_x$ extended this way is continuous from $T^{s+1}$ to $U^s$. The definition 
	\[\forall v \in U^{\infty}, \duality{\partial_x u}{v}_\omega \isdef -\duality{u}{\omega \partial_x \omega v}_\frac{1}{\omega}\]
	gives a sense to $\partial_x u$ for all $u$ in $T^{-\infty}$, as a duality $T^{-\infty} \times T^{\infty}$ product, because if $v \in U^{\infty} (= C^{\infty}([-1,1])$, then $\omega \partial_x \omega v = (1-x^2)v' - xv$ also lies in $C^{\infty}([-1,1]) (= T^\infty)$. Letting $w = \partial_x u$, we have by definition for all $n$
	\[\check{w}_n = \duality{w}{U_n}_{\omega} = - \duality{u}{\omega \partial_x \omega U_n}_\frac{1}{\omega} = n \duality{u}{T_{n+1}}_\frac{1}{\omega} = n\hat{u}_{n+1}\]
	Obviously, this implies the announced continuity with
	\[ \norm{w}_{U^s} \leq \norm{u}_{T^{s+1}}\,.\]
	The properties of $\omega \partial_x \omega$ on $T^s$ are established similarly. 
\end{proof}
\begin{Cor}
	\label{corDxT2T0}
	The operator $\partial_x$ is continuous from $T^{s+2}$ to $T^s$ for all $s > -1/2 $ and from $U^{s+2}$ to $U^s$ for all $s > - 3/2$. On the other hand, $\omega \partial_x \omega$ is continuous from $T^{s+1}$ to $T^s$ and from $U^{s+1}$ to $U^s$ for all $s \in \R$. 
\end{Cor}
\begin{proof}
	For the continuity of $\partial_x$ from $T^{s+2}$ to $T^s$, we use the continuity of $\partial_x$ from $T^{s+2}$ to $U^{s+1}$ and then of the identity from $U^{s+1}$ to $T^s$. For the continuity of $\partial_x$ from $U^{s+2}$ to $U^s$, we use the same arguments in reverse order. \\
	On the other hand, we have, for $n \geq 2$,
	\[\omega \partial_x \omega T_n = \omega\partial_x \omega \frac{U_n - U_{n-2}}{2} = \frac{(n+1)T_{n+1} - (n-1)T_{n-1}}{2}\,.\]
	Therefore $\omega \partial_x \omega$ is continuous from $T^{s+1}$ to $T^s$. Finally, $\omega \partial_x \omega$ is continuous from $U^{s+1}$ to $T^s$ and the inclusion $T^s \subset U^s$ is continuous thus $\omega \partial_x \omega$ is continuous from $U^{s+1}$ to $U^s$.  
\end{proof}
\begin{Lem}
	\label{LemInjectionsContinues}
	For all $\varepsilon >0$, if $u \in T^{\frac{1}{2} + \varepsilon}$, then $u$ is continuous and
	\[ \exists C : \forall x \in [-1,1], \quad \abs{u(x)} \leq C \norm{u}_{T^{1/2 + \varepsilon}}.\]	
	Similarly, if $u \in U^{3/2 + \varepsilon}$, then $u$ is continuous and 
	\[ \exists C : \forall x \in [-1,1], \quad \abs{u(x)} \leq C \norm{u}_{U^{3/2 + \varepsilon}}.\]
\end{Lem}
\begin{proof}
	Let $x \in [-1,1]$. Using triangular inequality,
	\[\abs{u(x)} \leq \sum_{n = 0}^{+ \infty} \abs{\hat{u}_n}\]
	since for all $n$, $\norm{T_n}_{L^\infty} = 1$. Applying Cauchy-Schwarz's inequality, one gets
	\[\abs{u(x)} \leq \sqrt{\sum_{n= 0}^{+ \infty} \frac{1}{(1+ n^2)^{\frac{1}{2}+ \varepsilon}}} \norm{u}_{T^{\frac{1}{2} + \varepsilon}}.\]
	The second statement is deduced from the fist and the continuous inclusion $U^{s} \subset T^{s-1}$ established in \autoref{inclusionsTsUs}. 
\end{proof}	
\subsection{Link with Periodic Sobolev spaces}
We briefly recall here the definition of the periodic Sobolev spaces on the torus $\mathbb{T}_{2\pi} \isdef \R / 2\pi \Z$. A smooth function $u$ on $\mathbb{T}_{2\pi}$ can be decomposed in Fourier series 
\[u(\theta) = \sum_{n \in \Z} \mathcal{F}u(n) e^{in\theta}\]
with the Fourier coefficients defined by 
\[\mathcal{F}u(n) \isdef \frac{1}{2\pi}\int_{-\pi}^\pi u(\theta) e^{-in\theta}d\theta.\]
For $n\in \Z$, let $e_n : \theta \mapsto e^{in\theta}$. We define the Fourier coefficients of any periodic distribution $u$ on $\mathbb{T}_{2\pi}$, by $\mathcal{F}u(n) \isdef u(e_{-n})$. The space $H^s$ is then defined for all $s$ as the set of periodic distributions on $\mathbb{T}_{2\pi}$ for which 
\[\norm{u}_{H^s}^2 \isdef \sum_{n \in \Z} (1 + n^{2})^s\abs{\mathcal{F}u(n)}^2 < +\infty \]
Introducing the duality product
\begin{equation}
\label{dualiteSobolevPer}
\duality{u}{v}_{\mathbb{T}_{2\pi}} = \sum_{n \in \Z} \mathcal{F}u(n) \mathcal{F}v(-n)\,,
\end{equation}
$H^s$ is identified to the dual of $H^{-s}$ and $H^0 = L^2(\mathbb{T}_{2\pi})$. For $u,v \in  H^0$, $\duality{u}{v}_{\mathbb{T}_{2\pi}} = \frac{1}{2\pi} \int_{-\pi}^{\pi} uv$. The space $H^s$ is the direct sum $H^s_e + H^s_o$ where $H^s_e \isdef \enstq{u \in H^s}{\mathcal{F}u(n) = \mathcal{F}u(-n)}$ and $H^s_o \isdef \enstq{u \in H^s}{\mathcal{F}u(n) = -\mathcal{F}u(-n)}$. Note that when $u$ is continuous, $u \in H^s_e \iff \forall \theta \in \mathbb{T}_{2\pi}, u(-\theta) = u(\theta)$ and $u \in H^s_o \iff \forall \theta \in \mathbb{T}_{2\pi}, u(-\theta) = -u(\theta)$. 
%For $s = 0$, we denote $L^2_e \isdef H^0_e$ and $L^2_o \isdef H^0_o$. 

\begin{Def}
	We define the operators $\mathcal{C} : T^{-\infty} \to H^{-\infty}_e$ by 
	\[\forall n \in \Z, \quad \mathcal{F}(\mathcal{C}u)(n) = \begin{cases}
	\hat{u}_0 & \text{ if } n = 0,\\
	\frac{\hat{u}_{\abs{n}}}{2} & \text{ otherwise,}	\end{cases}\,\]
	and $\mathcal{S} : U^{-\infty} \to H^{-\infty}_o$ by 
	\[\forall n \in \Z, \quad \mathcal{F}(\mathcal{S}u)(n) = \begin{cases}
	0 & \text{ if } n = 0,\\
	\textup{sign}(n)\frac{\hat{u}_{\abs{n}-1}}{2} & \text{ otherwise.}	\end{cases}\,\]
\end{Def}
\begin{Lem}
	\label{FormuleDualitesCetS}
	The operators $\mathcal{C}$ and $\mathcal{S}$ map smooth functions to smooth functions. For all $(u,v) \in T^{-\infty} \times T^{\infty}$, 
	\[\duality{u}{v}_{\frac{1}{\omega}} = \duality{\mathcal{C}u}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}\,.\]
	For all $(u,v) \in U^{-\infty} \times U^{\infty}$,
	\[\duality{u}{v}_{{\omega}} = \duality{\mathcal{S}u}{\mathcal{S}v}_{\mathbb{T}_{2\pi}}\]
\end{Lem}
\begin{proof}
	The first assertion is obvious from the definition of $\mathcal{C}$ and $\mathcal{S}$. Let $(u,v) \in T^{-\infty}\times T^{\infty}$. By definition of $\duality{\cdot}{\cdot}_\frac{1}{\omega}$  and $\duality{\cdot}{\cdot}_{\mathbb{T}_{2\pi}}$ \cref{dualiteTs,dualiteSobolevPer},
	\[\begin{split}
	\duality{\mathcal{C}u}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}&= \sum_{n \in \Z}\mathcal{F}(\mathcal{C}u)(n)\mathcal{F}(\mathcal{C}v)(-n)\\ 
	&= \hat{u}_0 \hat{v}_0 + \sum_{n \in \Z, n \neq 0} \frac{\hat{u}_{\abs{n}}}{2}\frac{\hat{v}_{\abs{n}}}{2}\\
	&= \hat{u}_0 \hat{v}_0 + \frac{1}{2}\sum_{n = 1}^{+ \infty} \hat{u}_{n} \hat{v}_{n} \\
	&= \duality{u}{v}_\frac{1}{\omega}\,.
	\end{split}\,. \]
	The second identity is proved similarly.
\end{proof}
\begin{Lem}
	\label{lemChar}
	For all $s \in \R$, the operators $\mathcal{C}$ and $\mathcal{S}$ induce bijective isometries respectively from $T^s$ to $H^s_e$ and from $U^s$ to $H^s_o$. For $u \in \Cinf([-1,1])$, 
	\[\mathcal{C}u(\theta) = u(\cos\theta)
	\quad \text{ and } \quad \mathcal{S}u(\theta) = \sin\theta u(\cos\theta)\,.\]
	Let $v,w \in \Cinf(\mathbb{T}_{2\pi})$, an even and an odd function respectively. Then
	\[\mathcal{C}^{-1}v(x) = v(\arccos x) \quad \text{ and } \quad \mathcal{S}^{-1}w(x) = \frac{w(\arccos x)}{\omega(x)}\,.\]
\end{Lem}
\begin{proof}
	Let $J_s^T$, $J_s^U$ and $\tilde{J}_s$ the linear continuous mappings defined respectively on $T^{-\infty}$, $U^{-\infty}$ and $H^{-\infty}$ by
	\[J_s^TT_n = (1 + n^2)^\frac{s}{2} T_n, \quad J_s^UU_{n-1} = (1 + n^2)^{\frac{s}{2}} U_{n-1}, \quad \tilde{J}_s e_n = (1 + n^2)^\frac{s}{2} e_n\]
	where we recall that $e_n$ is the function $\theta \mapsto e^{in\theta}$. One can check easily that for $u \in T^s$ and $v \in U^s$
	\[\norm{u}_{T^s}^2 = \duality{J_s^Tu}{\overline{J_s^T u}}_\frac{1}{\omega}, \quad \norm{v}_{U^s}^2 = \duality{J_s^U v}{\overline{J_s^U v}}_\omega\]
	while for $w \in H^s$, 
	\[\norm{w}_{H^s}^2 = \norm{u}_{T^s}^2 = \duality{\tilde{J}_su}{\overline{\tilde{J}_s u}}_{\mathbb{T}_{2\pi}}\,.\]
	Moreover, the following identities hold:
	\[\mathcal{C} J_s^T = \tilde{J}_s \mathcal{C}, \quad \mathcal{S} J_s^U = \tilde{J}_s \mathcal{S}\,.\]
	The isometric property of $\mathcal{C}$ may now be deduced from \autoref{FormuleDualitesCetS} as follows. Let $u_N = \sum_{n = 0}^N u_n T_n$. There holds 
	\[\begin{split}
	\duality{J_s^T u}{\overline{J_s^T u_N}}_{\frac{1}{\omega}} &= \duality{\mathcal{C} J_s^T u}{\overline{\mathcal{C} J_s^T u_N}}_{\mathbb{T}_{2\pi}}\\
	& = \duality{\tilde{J}_s \mathcal{C} u}{\overline{\tilde{J}_s \mathcal{C} u_N}}_{\mathbb{T}_{2\pi}}\,.
	\end{split}\] 
	Sending $N$ to infinity, by continuity of $J_s^T$, $\tilde{J}^s$ and $\mathcal{C}$, this yields
	\[\norm{u}_{T^s}^2 = \norm{\mathcal{C}u}_{H^s}^2\]
	The isometric property of $\mathcal{S}$ is establish in a similar manner. Let $u$ a smooth function. Since $\mathcal{C}u$ is smooth, the Fourier series of $\mathcal{C}u$ converge pointwise to $\mathcal{C}u$. Thus, for all $\theta \in \mathbb{T}_{2\pi}$,
	\[\begin{split}
	\mathcal{C}u(\theta) &= \sum_{n \in \Z} \mathcal{F}(\mathcal{C}u)(n)e^{in\theta}\\
	&= \hat{u}_0 + \sum_{n \in \Z, n\neq 0} \frac{\hat{u}_{\abs{n}}}{2} e^{in\theta}\\
	&= \hat{u}_0 + \frac{1}{2}\sum_{n = 1}^{+\infty} \hat{u}_n \left(e^{in\theta} + e^{-in\theta} \right)\\
	& = \sum_{n = 0}^{+ \infty} \hat{u}_n \cos(n \theta)\\
	& = \sum_{n = 0}^{+ \infty} \hat{u}_n T_n(\cos\theta)
	\end{split}\]
	The last sum also converges pointwise to $u(\cos\theta)$ since $u \in T^\infty$. Similar calculations show that $\mathcal{S}u(\theta) = \sin\theta u(\cos\theta)$, using this time $\sin((n+1)\theta) = \sin\theta U_n(\cos\theta)$. 
	To prove the bijectivity of $\mathcal{S}$ and $\mathcal{C}$, one can check that they have the  explicit inverses $\mathcal{C}^{-1}$ and $\mathcal{S}^{-1}$ respectively defined on $H^s_e$ and $H^s_o$ as
	\[\forall n \in \N, \quad \widehat{(\mathcal{C}^{-1}u)}_n = \begin{cases}
	\mathcal{F}u(0) & \text{ if } n = 0,\\
	2\mathcal{F}u(n) & \text{ otherwise,}	\end{cases}\,\]
	and
	\[\forall n \in \N, \quad \widehat{(\mathcal{S}^{-1}u)}_n = 2\mathcal{F}u(n+1)\,.\]
	Finally, the expression of $\mathcal{C}^{-1}u$ (resp $\mathcal{S}^{-1}u$) when $u$ is a smooth even (resp. odd) function on $\mathbb{T}_{2\pi}$ is deduced from the expression of $\mathcal{C}$ (resp. $\mathcal{S}$).
\end{proof}
\subsection{Equivalent norms on $T^n$ and $U^n$}
We now provide a characterization of the spaces $T^n$ and $U^n$ in terms of weighted $L^2$ norms of the derivatives and give equivalent norms on those spaces when $n$ is an integer. 
\begin{Lem}
	\label{omegadxetdxomga}
	The operator $\omega$ is a bijective isometry from $U^0$ to $T^0$ with inverse $\frac{1}{\omega}$. 
\end{Lem}
\begin{proof}
	This result follows from
	\[\norm{\omega u}_\frac{1}{\omega}^2 = \frac{1}{\pi}\int_{-1}^1 \frac{\abs{(\omega u)}^2}{\omega} = \frac{1}{\pi} \int_{-1}^{1} \omega \abs{u}^2 = \norm{u}_\omega\,,\]
	valid for all $u \in L^2_\omega$.
\end{proof}
\begin{Def}
	For an even integer $n$, the operator $(\omega \partial_x)^n : T^{-\infty} \to T^{-\infty}$ is defined by
	\[(\omega \partial_x)^0 = I_d,\quad \forall k > 0,\,\,\, (\omega \partial_x)^{2k} \isdef (\omega \partial_x \omega) \partial_x (\omega \partial_x)^{2k -2}\] The operator $(\partial_x \omega)^n : U^{-\infty} \to U^{-\infty}$ is defined in an analogous way. 
\end{Def}
\begin{Lem}
	\label{Lemnpair}
	Let $n$ an even integer. For all $s \in \R$, $(\omega \partial_x)^n$ is continuous from $T^s$ to $T^{s - n}$ and $(\partial_x \omega)^n$ is continuous from $U^s$ to $U^{s-n}$. 
\end{Lem}
\begin{proof}
	Those results follow from the definition of the operators and by induction using the mapping properties of $\partial_x$ and $\omega \partial_x \omega$ established in \autoref{derivations}. 
\end{proof}
\begin{Def}
	For an odd integer $n$, the operator $(\omega \partial_x)^n : T^n \to T^{0}$ is defined by
	\[(\omega \partial_x)^n \isdef \omega \partial_x (\omega \partial_x)^{n-1}\,.\] 
	The operator $( \partial_x \omega)^n : T^n \to T^{0}$ is defined in an analogous way. 
\end{Def}
\noindent From \autoref{omegadxetdxomga}, we deduce 
\begin{Cor}
	\label{Lemnimpair}
	When $n$ is odd, the operators $(\omega \partial_x)^n$ and $(\partial_x \omega)^n$ are well defined and continuous respectively from $T^n$ to $T^0$ and from $U^n$ to $U^0$. 
\end{Cor}
\begin{Lem}
	Let $n \in \N$. If $n$ is even,
	\[T^n = \enstq{ u \in L^2_\frac{1}{\omega}}{(\omega \partial_x)^n u \in L^2_\frac{1}{\omega}}\]
	If $n$ is odd, 
	\[T^n = \enstq{u \in L^2_\frac{1}{\omega}}{\partial_x(\omega \partial_x)^{n-1} u \in L^2_\omega}\] 
	Moreover $u \mapsto \sqrt{\norm{u}_\frac{1}{\omega}^2 + \norm{(\omega \partial_x)^nu}^2_{\frac{1}{\omega}}}$ defines an equivalent norm on $T^n$, and for all $u \in T^n$, 
	\[\abs{u}_{T^n} = \norm{(\omega \partial_x)^n u}_{L^2_\frac{1}{\omega}}\,.\]
\end{Lem}
\begin{proof}
	The direct inclusions follow from the mapping properties established in \autoref{derivations}, \autoref{Lemnpair} and \autoref{Lemnimpair}. 
	For the converse inclusion, let $u$ in $L^2_\frac{1}{\omega}$. If $n$ is even, say $n=2k$, we assume that $(\omega \partial_x)^{n}u \in L^2_\frac{1}{\omega}$. The Fourier-Chebyshev coefficients of $a = (\omega \partial_x)^n u$ are given for $j > 0$ by
	\[\hat{a}_j = 2\inner{(\omega \partial_x)^{2k} u(x)}{T_j}_\frac{1}{\omega} =  2\inner{ u(x)}{(\omega \partial_x)^{2k}T_j}_\frac{1}{\omega} = (-1)^k j^{2k} \hat{u_j}\,.\]
	while for $j = 0$, $\hat{a}_j = 0$. 
	Applying Parseval's equality to the function $a$, this gives
	\begin{equation}
	\label{tempp1}
		\frac{1}{2}\sum_{j > 0} j^{2n} \abs{\hat{u}_j}^2 = \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\,.
	\end{equation}
	On the other hand, if $n$ is odd, say $n = 2k+1$, let $b \isdef \partial_x (\omega \partial_x)^{2k} u$. The assumption is now $b \in L^2_\omega$, and by \autoref{omegadxetdxomga}, $\omega b \, ( = (\omega \partial_x)^n u) \, \in T^0$ with
	\[\norm{\omega b}_{\frac{1}{\omega}} = \norm{(\omega \partial_x)^n u}_{\frac{1}{\omega}} =  \norm{b}_\omega\,.\]
	One can write
	\[\check{b}_j = 2\inner{\partial_x(\omega \partial_x)^{2k} u}{U_j} = -2 \inner{u}{(\omega \partial_x)^{2k}(\omega \partial_x \omega) U_j}\,.\]
	Using $-\omega \partial_x \omega U_j = (j+1)T_{j+1}$, we obtain
	\[\check{b}_j = (-1)^k(j+1)^{2k + 1} \hat{u}_{j+1}\,.\]
	Parseval's equality then implies that \eqref{tempp1} also hold for odd $n$.
	This establishes that $u \in T^n$ and $\abs{u}_{T^n} = \norm{(\omega \partial_x)^nu}_\frac{1}{\omega}$. For the norm equivalence, adding the Parseval equality for $u \in L^2_\frac{1}{\omega}$ to \cref{tempp1}, we get 
	\begin{equation}
		\abs{\hat{u}_0}^2 + \frac{1}{2}\sum_{j > 0}  (1 + j^{2n}) \abs{\hat{u}_j}^2 = \norm{u + (\omega \partial_x)^n u}^2\,.
		\label{tempp}
	\end{equation}
	There are two constants $c$ and $C$ such that $c (1 + j^2)^n \leq (1 + j^{2n}) \leq C(1 + j^2)^n$. Injecting this in \eqref{tempp}, we obtain
	\[ \frac{c}{2}\norm{u}_{T^n}^2 \leq \norm{u + (\omega \partial_x)^n u}^2_\frac{1}{\omega} \leq C\norm{u}_{T^n}^2\,.\]
	Moreover,
	\[\norm{u}^2_\frac{1}{\omega} + \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\leq \norm{u + (\omega \partial_x)^n u}^2_\frac{1}{\omega} \leq 2\left(\norm{u}^2_\frac{1}{\omega} + \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\right)\,,\] 
	and the equivalence of the norms follows.
\end{proof}
\begin{Lem} Let $n \in \N$. If $n$ is even, then
	\[U^n = \enstq{u \in L^2_\omega}{(\partial_x \omega)^n u \in L^2_\omega}\,.\]
	If $n$ is odd, then
	\[U^n = \enstq{u \in L^2_\omega}{\omega \partial_x\omega (\partial_x \omega)^{n-1} u \in L^2_\frac{1}{\omega}}\,.\]	
	Moreover, $u \mapsto \sqrt{\int_{-1}^{1} \omega {\abs{( \partial_x \omega )^nu}^2}}$ defines an equivalent norm on $U^n$. 
\end{Lem}
\begin{proof}
	The direct inclusions follow from the mapping properties established in \autoref{derivations}, \autoref{Lemnpair} and \autoref{Lemnimpair}. For the converse inclusion, if $n$ is even, let $a = (\partial_x \omega)^n u$, we assume that $a \in L^2_\omega$. One has 
	\[\check{a}_j = (-1)^k \left(1+j\right)^{n}\check{u}_j\] 
	so by Parseval's equality, 
	\begin{equation}
		\label{tempp2}
		\frac{1}{2}\sum_{j = 0 }^{+ \infty} (j+1)^{2n} \abs{\check{u}_j}^2 = \norm{(\partial_x \omega)^nu}^2_\omega
	\end{equation}
	If $n$ is odd, the assumption is that $b = \omega \partial_x \omega(\partial_x \omega)^{n-1}u$ is in $L^2_\frac{1}{\omega}$. One has, for $j > 0$, 
	\[\hat{b}_j = \duality{\omega \partial_x \omega(\partial_x \omega)^{n-1}u}{T_j} = -\duality{u}{(\partial_x \omega)^{n-1} \partial_x T_j}\]
	Using $T_j' = jU_{j-1}$, this yields, for $j > 0$,
	\[\hat{b}_j = j^{2n} \check{u}_{j-1}\,.\]
	while $\hat{b}_0 = 0$. By \autoref{omegadxetdxomga}, $\frac{b}{\omega} \,(= (\partial_x \omega)^n u)\, \in U^0$. Applying Parseval's equality to $b$ in $L^2_\frac{1}{\omega}$ and using $\norm{\frac{b}{\omega}}_\omega = \norm{b}_\frac{1}{\omega}$, we find that \eqref{tempp2} also holds for $n$ odd, and thus the inclusion is proved. The equivalnce of the norms follows from the fact that there exists two constants $c$ and $C$ such that for all $j \in \N$, 
	\[c(1 + (j + 1))^{2n} \leq (j + 1)^{2n}  \leq C(1 + (j+1))^{2n}.\]
	\end{proof}
	
\subsection{Generalization to a curve $\Gamma$}

\subsubsection*{Parametrization of $\Gamma$}
	We start by introducing some notation that will be extensively used throughout all the remainder of this work. Let $\Gamma$ a smooth open curve in $\mathbb{R}^2$ parametrized by a smooth $C^\infty$ diffeomorphism $r : [-1,1] \to \Gamma$. We assume that $\abs{r'(x)} = \frac{\abs{\Gamma}}{2}$ for all $x\in [-1,1]$, where $\abs{\Gamma}$ is the length of $\Gamma$. This parametrization is related to the curvilinear abscissa $M(s)$ through
\[r(x) = M\left( \frac{\abs{\Gamma}}{2}(1+x)\right)\,.\]
Let $\opFromTo{R}{\Cinf(\Gamma)}{\Cinf(-1,1)}$ defined by 
\[Ru(x) = u(r(x))\,.\]
The tangent and normal vectors on the curve $\tau$ are respectively defined by 
\[\tau(x) = \frac{\partial_x r(x)}{\abs{\partial_x r(x)}}, \quad n(x) = \frac{\partial_x \tau(x)}{\abs{\partial_x \tau'(x)}}\]
Let $N : \Gamma \to \R^2$ such that $N(r(x)) = n(x)$, that is, $N = R^{-1} n$. Let $\kappa(x)$ the signed curvature of $\Gamma$ at the point $r(x)$. Frenet-Serret's formulas give
\[\begin{split}r(y) = & r(x) + (y-x) \frac{\abs{\Gamma}}{2} \tau(x) + \frac{(y-x)^2}{2} \frac{\abs{\Gamma}^2}{4} \kappa(x) n(x)\\ 
+ &\frac{(x-y)^3}{6} \frac{\abs{\Gamma}^3}{8} (\kappa'(x) n(x) - \kappa(x)^2 \tau(x)) + O\left((x-y)^4\right)\,,
\end{split}\,.\]
so that
\begin{equation}
\abs{r(x) - r(y)}^2 = \frac{\abs{\Gamma}^2}{4}(y-x)^2 - \frac{(y-x)^4}{192}\abs{\Gamma}^4 \kappa(x)^2 + O(x-y)^5\,. 
\label{expansion_r}
\end{equation}
For $u,v \in L^2(\Gamma)$, we have by change of variables in the integral
\[\duality{u}{v}_{L^2(\Gamma)} = \frac{\abs{\Gamma}}{2}\duality{Ru}{Rv}_{L^2(-1,1)} \,.\]
The tangential derivative $\partial_\tau$ on $\Gamma$ satisfies $\partial_\tau = \frac{2}{\abs{\Gamma}}R^{-1}\partial_x R$. Moreover, let $\omega_\Gamma \isdef \frac{\abs{\Gamma}}{2} R^{-1}  \omega(x) R$ the "weight" on the curve $\Gamma$. The uniform measure on $\Gamma$ is denoted by $d\sigma$.

\subsubsection*{Spaces $T^s(\Gamma)$ and $U^s(\Gamma)$}

The definition of the spaces $T^s$ can be transported on the curve $\Gamma$, replacing the basis $(T_n)$ and $(U_n)$ by $(R^{-1}T_n)$ and $(R^{-1}U_n)$. The spaces $T^s(\Gamma)$ and $U^s(\Gamma)$ are thus defined as the sets of formal series respectively of the form 
\[u = \sum_{n \in \N} \hat{u}_n R^{-1}T_n, \quad v = \sum_{n \in \N} \check{v}_n R^{-1}T_n\]
where $Ru = \sum\hat{u}_n T_n \in T^s$ and $Rv = \sum\check{v}_n U_n  \in U^s$. To $u$ and $v$ are associated the linear forms 
\[\forall \varphi \in \Cinf(\overline{\Gamma}), \quad \duality{u}{\varphi}_\frac{1}{\omega_\Gamma} \isdef \duality{Ru}{R\varphi}_\frac{1}{\omega}\,,\]
\[\forall \varphi \in \Cinf(\overline{\Gamma}), \quad \duality{v}{\varphi}_{\omega_\Gamma} \isdef \frac{\abs{\Gamma}^2}{4}\duality{Rv}{R\varphi}_{\omega}\,.\] 

 
\noindent From the results of the previous section we deduce
\begin{Lem} For all $s \in \R$, $T^s(\Gamma)$ and $U^s(\Gamma)$ are Hilbert spaces for the scalar products 
\[\inner{u}{v}_{T^s(\Gamma)} = \inner{Ru}{Rv}_{T^s}\,,\]
\[\inner{u}{v}_{U^s(\Gamma)} = \frac{\abs{\Gamma}^2}{2}\inner{Ru}{Rv}_{U^s}\,.\]
With these definitions, 
\[\inner{u}{v}_{T^0(\Gamma)} = \duality{u}{\overline{v}}_\frac{1}{\omega_\Gamma} = \int_{\Gamma} \frac{u(x) \overline{v(x)}}{ \omega_\Gamma(x)} dx\]
and
\[\inner{u}{v}_{U^0(\Gamma)} = \duality{u}{\overline{v}}_{\omega_\Gamma}  = \int_{\Gamma} \omega_\Gamma(x) u(x) \overline{v(x)} dx\]
thus $T^0(\Gamma) = L^2_\frac{1}{\omega_\Gamma}$ and $U^0(\Gamma) = L^2_{\omega_\Gamma}$. For $s \in \R$, the dual of $T^s(\Gamma)$ is the set of linear forms $\duality{u}{\cdot}_\frac{1}{\omega_\Gamma}$ where $u\in T^{-s}$, and the dual of $U^s(\Gamma)$ is the set of linear forms $\duality{u}{\cdot}_{\omega_\Gamma}$ where $u \in U^{-s}(\Gamma)$. 
For $s < t$, the injections $T^t(\Gamma) \subset T^s(\Gamma)$ and $U^t(\Gamma) \subset U^s(\Gamma)$ are compact. $(T^s(\Gamma))_{s\in \R}$ and $(U^s(\Gamma))_{s\in \R}$ are two Hilbert interpolation scales. Equivalent scalar products on $T^n$ and $U^n$ are given respectively by
\[(u,v) \mapsto \int_{\Gamma} \frac{u(x)\overline{v(x)} + (\omega_\Gamma \partial_\tau)^n u(x) (\omega_\Gamma \partial_\tau)^n \overline{v(x)}}{\omega_\Gamma(x)}d\sigma(x)\,,\]
\[(u,v) \mapsto \int_{\Gamma}(\partial_\tau\omega_\Gamma )^n u(x) (\partial_\tau\omega_\Gamma \partial)^n \overline{v(x)}\omega_\Gamma(x)d\sigma(x)\,,\]
For all $s \in \R$, $T^s(\Gamma) \subset U^s(\Gamma)$ and for all $s > \frac{1}{2}$, $U^s(\Gamma) \subset T^{s-1}(\Gamma)$ with continuous inclusions. For $\varepsilon > 0$, $T^{1/2 + \varepsilon}(\Gamma) \subset C^0(\Gamma)$ and $U^{3/2+\varepsilon} \subset C^0(\Gamma)$. Moreover, $T^\infty(\Gamma) = U^\infty(\Gamma) = C^\infty(\overline{\Gamma})$. 
\end{Lem}

\section{Pseudo-differential operators}

\subsection{Periodic pseudo-differential operators}

On the family of periodic Sobolev spaces $H^s$, a class of periodic pseudo differential operators (PPDO) is studied in \cite{thrunen1998symbol}. We quickly review here the definitions and properties needed for our purposes. A PPDO of order $\alpha$ on $H^s$ is an operator of the form 
\[Au(\theta) =  \sum_{n \in \Z} \sigma_A(\theta,n) \hat{u}_n e^{in\theta}\,.\]
for a "prolongated symbol" $\sigma_A \in C^{\infty}(\mathbb{T}_T \times \R)$ satisfying 
\begin{equation}
\label{SymbolsCond}
	\forall j,k \in \N, \exists C_{j,k} >0 : \quad \abs{D^j_\theta D_\xi^k \sigma_A(\theta,\xi)} \leq C_{j,k}(1 + \abs{\xi})^{\alpha - k}\,.
\end{equation}
Here, $\hat{u}_n = \frac{1}{2\pi}\int_{-\pi}^{\pi}u(t) e^{-in\theta}d\theta$ are the usual Fourier coefficients of $u$ and 
$${D_\theta \isdef \frac{1}{i}\frac{\partial}{\partial \theta}}, \quad  D_\xi \isdef \frac{1}{i}\frac{\partial}{\partial \xi},$$ 
with for $j \geq 1$, $D_\theta^{j+1} = D_\theta D_\theta^j$, and $D_\xi^{j+1} = D_\xi D_\xi^j$. 
The class of symbols that satisfy \eqref{SymbolsCond} is denoted by $\Sigma^\alpha$, and $\Sigma^{-\infty} \isdef \cup_{\alpha \in \Z} \Sigma^\alpha$. The operator defined by a symbol $\sigma$ is denoted by $\textit{Op}(\sigma)$ and the set of PPDOs of order $\alpha$ is denoted by $\textit{Op}(\Sigma^\alpha)$. 

The prolongated symbol is not unique but determined uniquely at the integer values of $\xi$ by 
\begin{equation}
	\label{symbolUniqueDetermine}
	\sigma_A(\theta,n) =  e_{-n}(\theta)Ae_n(\theta)\,,
\end{equation}
where $e_n : \theta \mapsto e^{in\theta}$, as shown in \cite{thrunen1998symbol}. This justifies the terminology of "prolongated symbol". The operator $A$ is in $\textit{Op}(\Sigma^\alpha)$ if and only if
\[\forall j,k \in \N, \exists C_{j,k} > 0 : \abs{D_\theta^j \Delta_n^k \sigma_A(\theta,n)} \leq C_{j,k}(1 + \abs{n})^{\alpha - k}\,,\] 
where $\Delta_n \phi(\theta,n) = \phi(\theta,n+1) - \phi(\theta,n)$ and for $k \geq 1$, $\Delta^{k+1}_n\phi = \Delta_n (\Delta^k_n \phi)$. That is, if the symbol defined in \eqref{symbolUniqueDetermine} satisfies this condition, then there exists a prolongated symbol satisfying \eqref{SymbolsCond}. Because of this, we write $\sigma \in \Sigma^p$ for a symbol $\sigma(\theta,n)$ that can be prolongated to a symbol ${\sigma}(\theta,\xi) \in \Sigma^p$. An operator in $\textit{Op}(\Sigma^\alpha)$ maps continuously $H^s$ to $H^{s + \alpha}$ for all $s \in \R$. The composition of two operators in $\textit{Op}(\Sigma^\alpha)$ and $\textit{Op}(\Sigma^\beta)$ gives rise to an operator in $\textit{Op}(\Sigma^{\alpha+\beta})$. 
If two symbols $a$ and $b$ in $\Sigma^{- \infty}$ satisfy $a - b  \in \Sigma^{\alpha}$, we write $a = b + \Sigma^\alpha$. 
\begin{Def}
	Let $a \in \Sigma^{- \infty}$. If there exists a sequence of reals $(p_j)_{j \in \N}$ such that $p_j < p_{j+1}$ and a sequence of symbols $a_j \in \Sigma^{p_j}$ such that for all $N$, $a = \sum_{i = 0}^{N}a_i + \Sigma^{p_j + 1}$, we write 
	\[a = \sum_{i = 0}^{+ \infty} a_j \,.\]
	This is called an asymptotic expansion of the symbol $a$. 
\end{Def}

The symbol of the composition of two PPDOs $A$ and $B$ is denoted by $\sigma_A \# \sigma_B$ and satisfies the asymptotic expansion
\begin{equation}
	\label{a_diese_b}
	\sigma_A \# \sigma_B(t,\xi) = \sum_{j = 0}^{+\infty}\frac{1}{j!} \left(\frac{\partial}{\partial \xi}\right)^j \sigma_A(\theta,\xi) D_\theta^j \sigma_B(\theta,\xi)\,.
\end{equation}
We will also use the following result, proved in \cite{thrunen1998symbol}:
\begin{The}
	\label{thrunen}
	Consider an integral operator $K$ of the form 
	\[K : u \mapsto \frac{1}{2\pi}\int_{-\pi}^\pi a(\theta,\theta') \kappa(\theta-\theta') u(\theta') d\theta'.\]
	where $a$ is $2\pi$-periodic and $C^{\infty}$ in both arguments and $\kappa$ is a $2\pi$-periodic distribution. Assume that the Fourier coefficients $\hat{\kappa}(n)$ of $\kappa$ can be prolonged to a function $\hat{\kappa}(\xi)$ on $\R$ such that
	\[\forall k \in \N,  \exists C_k > 0: \quad \abs{\partial^k_\xi \hat{\kappa}(\xi)} \leq C_k (1 + \abs{\xi})^{\alpha - k}\,.\]
	for some $\alpha$. Then $K$ is in $\textit{Op}(\Sigma^\alpha)$ with a symbol satisfying the asymptotic expansion
	\begin{equation}
	\label{FormuleIntegralOperatorSymbol}
		\sigma_K(\theta, \xi) = \sum_{j = 0}^{+ \infty} \frac{1}{j!} \left(\frac{\partial}{\partial \xi}\right)^j \hat{\kappa}(\xi) D_{t}^ja(t,\theta)_{| t= \theta}\,.
	\end{equation}
\end{The}
\noindent In particular, taking $\kappa = 1$, we see that for all functions $a \in C^{\infty}(\mathbb{T}_T^2)$
\[Ku = \frac{1}{2\pi}\int_{-\pi}^{\pi} a(\theta,\theta') u(\theta') d\theta'\]
is in $Op\left(\Sigma^{-\infty}\right)$.

\subsection{Pseudo-differential operators on $T^s(\Gamma)$}

\begin{Lem}
	\label{TransportPPDO_T}
	Let $A$ a PPDO that stabilizes the set of smooth even functions. Then $A$ coincides on this set with the operator $B$ defined by the symbol
	\[\sigma_B(\theta,n) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}\,.\]
	Moreover, $\sigma_B$ admits the following decomposition:
	\[ \sigma_B(\theta,n) = a_1(\cos\theta,n) + i \sin(\theta)a_2(\cos\theta,n) \]
	with 
	\[a_1(x,n) = \frac{\sigma_B(\arccos(x),n) + \sigma_B(\arccos(x),-n)}{2}\]
	\[a_2(x,n) = \frac{\sigma_B(\arccos(x),n) - \sigma_B(\arccos(x),-n)}{2i\sqrt{1-x^2}}\] 
	and $a_1$ and $a_2$ are $\Cinf$ in $x$. The functions $a_1$ and $a_2$ thus defined are denoted by $a_1^T(A)$ and $a_2^T(A)$. 
\end{Lem}
\begin{proof}
For a smooth even function $u$, one has
\[Au(\theta) = \frac{Au(\theta) + Au(-\theta)}{2}\,,\]
thus
\[Au(\theta) = \frac{1}{2}\sum_{n \in \Z} \sigma_A(\theta,n) \hat{u}_n e^{in\theta} + \frac{1}{2}\sum_{n \in \Z} \sigma_A(-\theta,n)\hat{u}_n e^{-in\theta}\,.\]
Since $u$ is even, $\hat{u}_n = \hat{u}_{-n}$, so that $Au(\theta) = Bu(\theta)$ where $B$ is the operator with symbol $\sigma_B(\theta,n) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}$. In particular, it satisfies the following symmetry:
\[\sigma_B(-\theta,-n) = \sigma_B(\theta,n)\,.\] 
We write $\sigma_B(\theta,n) = f_B(\theta,n) + g_B(\theta,n)$ where $f_B(\theta,n) = \frac{\sigma_B(\theta,n) + \sigma_B(\theta,-n)}{2}$ and $g_B(\theta,n) = \frac{\sigma_B(\theta,n) - \sigma_B(\theta,-n)}{2}$. Notice that $f_B$ (resp. $g_B$) is even (resp. odd) in both $\theta$ and $n$.
The functions $a_1$ and $a_2$ defined in the statement of the Lemma satisfy
\[a_1(x,n) = f_B(\arccos(x),n),\quad a_2(x,n) = \frac{g_B(\arccos(x),n)}{i\sqrt{1-x^2}}\,,\]
thus 
\[\sigma_B(\theta,n) = a_1(\cos\theta,n) + i \sin\theta a_2(\cos\theta,n)\,. \]
For fixed $n$, there holds $a_1(\cdot,n) = \mathcal{C}^{-1}f_B(\cdot,n)$ and $a_2(\cdot,n) = -i\mathcal{S}^{-1}g_B$. By \autoref{lemChar}, $a_1$ and $a_2$ are thus $C^\infty$ in $x$ since $f_B$ (resp. $g_B$) is a smooth even (resp. odd) function.  
\end{proof}
We use this result to transport the notion of periodic pseudo-differential operators to the segment $[-1,1]$ by the change of variable $x = \cos\theta$. 

\begin{Def}
	Let $A$ an operator on $T^{-\infty}$ and assume that there exists a couple of smooth functions $a_1$ and $a_2$ in $\Cinf([-1,1]\times \N)$ such that for all $n \in \N$,
	\begin{equation}
	AT_n = a_1(x,n) T_n - \omega^2 a_2(x,n) U_{n-1}\,.
	\label{defOpTs}
	\end{equation}
	with by convention, $U_{-1} = 0$. Such a (non-unique) couple of functions is called a pair of symbols of $A$. For $n\in \Z$ and $\theta \in [0,2\pi]$, define the symbol $\tilde{\sigma}_T(a_1,a_2)$ by
	\[\tilde{\sigma}_T(a_1,a_2)(\theta,n) \isdef a_1(\cos\theta,\abs{n}) + i \sin\theta\,\text{sign}(n) a_2(\cos\theta,\abs{n})\,.\]
	We say that $(a_1,a_2) \in S^\alpha_T$ if $\tilde{\sigma}_T(a_1,a_2) \in \Sigma^\alpha$. We also take the notation $S^{\infty}_T \isdef \cup_{\alpha \in \R} S^\alpha_T$. The operator defined by a pair of symbols $(a_1,a_2)$ is denoted by $\textit{Op}_T(a_1,a_2)$ and the set of pseudo-differential operators (of order $\alpha$) in $T^{-\infty}$ by $\textit{Op}(S^\infty_T)$ ($\textit{Op}(S^\alpha_T)$).
\end{Def} 
\noindent Recall the definition of the isometric mapping $\mathcal{C}$ from \autoref{lemChar}.
\begin{The}
	\label{PDOTs}
	Let $(a_1,a_2) \in S^\alpha_T$ and $A = \textit{Op}_T(a_1,a_2)$.  There holds
	\[\mathcal{C}A = \tilde{A}\mathcal{C}\,\]
	where $\tilde{A} = \textit{Op}(\tilde{\sigma}_T(a_1,a_2))$. 
	Reciprocally, let $A : T^{\infty} \to T^{-\infty}$ a linear operator satisfying
	\[\forall u \in T^{\infty},\quad \mathcal{C}Au = \tilde{A}\mathcal{C}u\] 
	where $\tilde{A}$ is a PPDO of order $\alpha$ with a symbol $\sigma_{\tilde{A}}$. Then $A$ has a unique linear continuous extension on $T^{-\infty}$ satisfying $\mathcal{C}A = \tilde{A} \mathcal{C}$. This extension does not depend on $\tilde{A}$ and is in $\textit{Op}(S^\alpha_T)$. Moreover, $A$ admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$.
\end{The}
\begin{proof}
	For the direct result, we start by showing the equality for $u = T_n$ for all $n \in \N$. One has $\mathcal{C}T_n(\theta) = T_n(\cos(\theta)) = \cos(n\theta)$. Consequently,
	\begin{equation}
	\label{debut}
		\tilde{A}\left(\mathcal{C}T_n\right)(\theta) = \frac{\tilde{A}e^{in\theta}+\tilde{A}e^{-in\theta}}{2}\,
	\end{equation}
	which, using the determination of the symbol \eqref{symbolUniqueDetermine}, yields
	\[\tilde{A}\left(\mathcal{C}T_n\right)(\theta) = \frac{ \sigma(\theta,n)e^{in\theta} + \sigma(\theta,-n)e^{-in\theta}}{2}\,.\]
	where $\sigma = \tilde{\sigma}_T(a_1,a_2)$. Replacing this definition in the former equation, one gets
	\[\tilde{A}\left(\mathcal{C}u\right)(\theta) = a_1(\cos\theta,n)\cos(n\theta) - \sin\theta a_2(\cos\theta,n)\sin(n\theta).\]
	Since $\cos(n\theta) = T_n(\cos\theta)$ and $\sin(n\theta) = \sin\theta U_{n-1}(\cos\theta)$,
	\begin{equation}
		\begin{split}
		\tilde{A}\left(\mathcal{C}T_n\right)(\theta) &= a_1(\cos\theta,n)T_n(\cos\theta) - (1-\cos^2 \theta) a_2(\cos\theta,n) U_{n-1}(\cos\theta)\,,\\
		& = \mathcal{C}(AT_n)
		\end{split}
		\label{fin}
	\end{equation}
	as claimed. To show the general case, fix $u\in T^{-\infty}$ and $\tilde{v} \in H^{-\infty}$. One has, by linearity and continuity of $A$, $\tilde{A}$ and $\mathcal{C}$:
	\[\begin{split}
	\duality{\mathcal{C}A u}{\tilde{v}}_{\mathbb{T}_{2\pi}} &= \sum_{n = 0}^{+ \infty} \hat{u}_n \duality{\mathcal{C}AT_n}{\tilde{v}}_{\mathbb{T}_{2\pi}}\\
	& =  \sum_{n = 0}^{+ \infty} \hat{u}_n \duality{\tilde{A} \mathcal{C} T_n}{\tilde{v}}_{\mathbb{T}_{2\pi}}\\
	&= \duality{\tilde{A} \mathcal{C}u}{\tilde{v}}_{\mathbb{T}_{2\pi}}\,.
	\end{split}\]
	The last identity shows that $\mathcal{C}A u = \tilde{A} \mathcal{C} u$ for all $u \in T^{-\infty}$, in other words, $\mathcal{C}A = \tilde{A} \mathcal{C}$. For the converse result, we now assume that for any $u \in T^{\infty}$, $\mathcal{C}Au = \tilde{A}\mathcal{C}u$ where $\tilde{A}$ is some PPDO of order $\alpha$ with a symbol $\sigma_{\tilde{A}}$. The previous computations show that any linear continuous extension of $A$ satisfies 
	\begin{equation}
	\mathcal{C}A = \tilde{A}\mathcal{C}\,.
	\label{temp4}
	\end{equation}
	This in turn defines uniquely the operator $A$ on $T^{-\infty}$ since for $u \in T^{-\infty}$ and $v \in T^{\infty}$, one has, by \autoref{FormuleDualitesCetS},
	\[\duality{Au}{v}_\frac{1}{\omega} = \duality{\mathcal{C}Au}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}\,.\]
	Obviously, this definition does not depend on $\tilde{A}$. Let us show that $A$ sends $T^{\infty}$ to $T^{\infty}$. Let $u \in T^{\infty}$ and let $s\in \R$. Using \eqref{temp4}, the continuity of $\tilde{A}$ from $H^{s+\alpha}$ to $H^{s}$ and the isometric property of $\mathcal{C}$,  
	\[\begin{split}
		\norm{Au}_{T^s} &= \norm{\mathcal{C}Au}_{H^s}\\
		&= \norm{\tilde{A}\mathcal{C}u}_{H^s}\\
		& \leq C \norm{\mathcal{C}u}_{H^{s + \alpha}}\\
		& \leq C \norm{u}_{T^{s + \alpha}}.
	\end{split}\]
	The last quantity is finite since $u \in T^{\infty} \subset T^{s+\alpha}$. This proves that $A$ sends $T^\infty$ to $T^\infty$. \\
	Eq (\ref{temp4}) implies in particular that $\tilde{A}$ stabilizes the set of smooth even functions since $\mathcal{C}Au(\theta) = Au(\cos\theta)$ is even and $A$ maps smooth functions to smooth functions. \autoref{TransportPPDO_T} can thus be applied. Let $a_1 = a_1^T(\tilde{A})$ and $a_2 = a_2^T(\tilde{A})$. Starting from eq. \eqref{temp4}, the computations from eqs. \eqref{debut} to \eqref{fin} can be performed in reverse order to show
	\[AT_n(\cos \theta) = a_1(n,\cos\theta) T_n(\cos\theta) -(1 - \cos^2\theta) a_2(n,\cos\theta) U_{n-1}(\cos\theta)\,,\]
	which, taking $x = \cos\theta$, leads to $A = \textit{Op}_T(a_1,a_2)$. To establish that $A$ is in $\textit{Op}(S^\alpha_T)$, we have to show $\tilde{\sigma}(a_1,a_2) \in  \Sigma^\alpha$. By \autoref{TransportPPDO_T}, this is exactly the symbol $\sigma_B$ defined by 
	\[\sigma_B(\theta,n) = \frac{\sigma_{\tilde{A}}(\theta,n) + \sigma_{\tilde{A}}(-\theta,-n)}{2}\,.\] 
	This is indeed in $\Sigma^\alpha$ since it is the case for $\sigma_{\tilde{A}}$ by assumption. 
\end{proof}
\begin{Rem}
	When $A \in \textit{Op}(S^\alpha_T)$, there is an infinity of operators $\tilde{A}$ satisfying $\mathcal{C}A = \tilde{A} \mathcal{C}$. Indeed, if this holds for some $\tilde{A}$, it also holds for $\tilde{A} + B$ where $B$ is any PPDO of order $\alpha$ with the property that $Bu = 0$ when $u$ is even. This non-uniqueness is also reflected by the fact that the couple of symbols of an operator $A$ in $\textit{Op}(S^\alpha_T)$ is not unique, or in other words, the null operator has non-trivial pair of symbols in $S^{-\infty}_T$. For example take $a_1$ and $a_2$ as follows: fix $n_0 \in \N$ and let 
	\[a_1(x,n_0) = -\omega^2 U_{n_0-1}(x)\,, \quad a_2(x,n_0) = T_{n_0}(x)\]
	while $a_1(x,n) = a_2(x,n) = 0$ for $n \neq 0$. Obviously, $(a_1,a_2) \in S^{-\infty}_T$ and $\textit{Op}_T(a_1,a_2) \equiv 0$. 
	One idea to enforce uniqueness would be to take for $\tilde{A}$ the operator $\tilde{A}^*$ satisfying $\tilde{A}^*u = 0$ whenever $u$ is odd. Such a condition would demand the following symmetry on the symbol $\sigma_{\tilde{A}^*}:$
	\[\sigma_{\tilde{A}^*}(\theta,-n) = e^{2in\theta}\sigma_{\tilde{A}^*}(\theta,n)\,.\]
	One can show that if $\mathcal{C}A = \tilde{A} \mathcal{C}$ for some operator $\tilde{A}$, then the symbol of $\tilde{A}^*$ must be given by
	\[\sigma_{\tilde{A}^*}(\theta,n) = \sigma_{\tilde{A}}(\theta,n) + e^{-2in\theta}\sigma_{\tilde{A}}(\theta,-n)\,.\] 
	However, in general, this symbol is not in $\Sigma^\alpha$ because of the oscillatory term $e^{-2in\theta}$. In other words, one cannot always construct an operator $\tilde{A}^*$  satisfying the following three conditions 
	\begin{itemize}
		\item[-] $\tilde{A}^*$ coincides on the set of even functions with some given PPDO $\tilde{A}$ of order $\alpha$.
		\item[-] $\tilde{A}^*$ vanishes on the set of odd functions
		\item[-] $\tilde{A}^*$ is a PPDO of order $\alpha$. 
	\end{itemize}
	As a conclusion, it is not clear how to fix a natural representative in the class of pairs $(a_1,a_2)$ that define the same operator $A$. 
\end{Rem}
\begin{Def}
	Let $A : T^{-\infty}(\Gamma) \to T^{-\infty}(\Gamma)$. We say that $A$ is a pseudo-differential operator (of order $\alpha$) on $T^{-\infty}(\Gamma)$ if $R A R^{-1} \in Op(S^{\infty}_T)$ ($\in Op(S_T^{\alpha})$). The set of pseudo-differential operators of order $\alpha$ on $T^{-\infty}(\Gamma)$ is denoted by $\textit{Op}(S^{\alpha}_T(\Gamma))$. We say that $(a_1,a_2)$ is a pair of symbols of $A$ if it is a pair of symbols of $RAR^{-1}$.  
\end{Def}
\noindent As a corollary of \autoref{PDOTs}, we have he following properties
\begin{Cor}
	\label{CorContinuitePDOTs}
	Let $A \in \textit{Op}(S^\alpha_T(\Gamma))$. Then for all $s$, $A$ is continuous from $T^s(\Gamma)$ to $T^{s - \alpha}(\Gamma)$. If $B$ and $C$ respectively belong to $\textit{Op}(S^{\alpha_1}_T(\Gamma))$ and $\textit{Op}(S^{\alpha_2}_T(\Gamma))$, with pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2}_T(\Gamma))$ and admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$ where
	\[\tilde{A} = \textit{Op}(\tilde{\sigma}_T(b_1,b_2)) \textit{Op}(\tilde{\sigma}_T(c_1,c_2)) = \textit{Op}(\tilde{\sigma}_T(b_1,b_2)\#\tilde{\sigma}_T(c_1,c_2))\,.\]
\end{Cor}
\begin{proof}
	Let $A \in \textit{Op}(S^\alpha_T(\Gamma)$ and $s \in \R$. By \autoref{PDOTs}, there exists $\tilde{A} \in \textit{Op}(\Sigma^\alpha)$ such that 
	\[\mathcal{C}RAR^{-1} = \tilde{A}\mathcal{C}\]
	Using the definition of the norm on $T^s(\Gamma)$, the isometric property of $\mathcal{C}$ and the continuity of $\tilde{A}$ from $H^s$ to $H^{s - \alpha}$, we have for all $u \in T^s(\Gamma)$,  
	\[\begin{split}
	\norm{Au}_{T^{s-\alpha}(\Gamma)} &= \norm{RA u}_{T^{s-\alpha}}
	=\norm{\mathcal{C}RA u}_{H^{s-\alpha}}
	=\norm{\tilde{A}\mathcal{C}Ru}_{H^{s-\alpha}}\\
	&\leq C \norm{\mathcal{C}Ru}_{H^s} = C\norm{Ru}_{T^s}\\
	& = C\norm{u}_{T^s(\Gamma)}
	\end{split}\]
	\toDo{très moche, non ?}\\
	Let $B,C \in \textit{Op}(S^{\alpha_1}_T(\Gamma))\times\textit{Op}(S^{\alpha_2}_T(\Gamma))$, with respective pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$. Let $\tilde{B} = \textit{Op}(\tilde{\sigma}{(b_1,b_2)})$ and $\tilde{C} = \textit{Op}(\tilde{\sigma}{(c_1,c_2)})$. We have 
	\[\mathcal{C} RBR^{-1} = \tilde{B} \mathcal{C}, \quad \text{ and } \quad  \mathcal{C} RCR^{-1} = \tilde{C} \mathcal{C}\,.\]
	Therefore, 
	\[\mathcal{C} RBCR^{-1} = \tilde{A} \mathcal{C}.\]
	where $\tilde{A} = \tilde{B}\tilde{C}$. One has $\tilde{A} \in \textit{Op}(\Sigma^{\alpha_1 + \alpha_2})$. By \autoref{PDOTs}, $RBCR^{-1}$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2})$ and admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$. By definition, this means that $BC \in \textit{Op}(S^{\alpha_1 + \alpha_2}(\Gamma))$ and admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$. 
\end{proof}
\begin{Rem}
	\label{RemSymb}
	The previous result gives a method for a symbolic calculus on the class $S^\alpha_T(\Gamma)$ as follows. If $B$ and $C$ respectively admit the pair of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ admits the pair of symbols 
	\[(b_1,b_2) \#_T (c_1,c_2) \isdef (a_1^T(\tilde{\sigma}_T(b_1,b_2) \# \tilde{\sigma}_T(c_1,c_2)),a_2^T(\tilde{\sigma}_T(b_1,b_2) \# \tilde{\sigma}_T(c_1,c_2)))\,.\]
	One can use \eqref{a_diese_b} to compute an asymptotic expansion of $\tilde{\sigma}(b_1,b_2) \# \tilde{\sigma}(c_1,c_2)$ which, in turn, gives an asymptotic expansion of $(b_1,b_2) \#_T (c_1,c_2)$.
	\toDo{Mettre une remarque disant que les calculs seront omis car trop longs, mais faits avec un programme maple qui sera mis en ligne ?}
\end{Rem}
\subsection{Pseudo-differential operators on $U^s(\Gamma)$}

We define similarly a class of pseudo-differential operators on the spaces $U^s(\Gamma)$. One can show the following result:
\begin{Lem}
	\label{TransportPPDO_U}
	Let $A$ a PPDO that stabilizes the set of smooth odd functions. Then $A$ coincides on this set with the operator $B$ with symbol given by 
	\[\sigma_B(n,\theta) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}\,.\]
	Moreover, $\sigma_B$ admits the following decomposition
	\[\sigma_B(n,\theta) = i a_1(\cos\theta,n) + \sin\theta a_2(\cos\theta,n)\]
	with
	\[a_1(x,n) = \frac{\sigma_B(\arccos(x),n) + \sigma_B(\arccos(x),-n)}{2i}\]
	\[a_2(n,x) = \frac{\sigma_B(\arccos(x),n) - \sigma_B(\arccos(x),-n)}{2\sqrt{1-x^2}}\] 
	and $a_1$ and $a_2$ are $\Cinf$. The functions $a_1$ and $a_2$ thus defined are denoted by $a_1^U(A)$ and $a_2^U(A)$. 
\end{Lem}
Let $A$ an operator on $U^{-\infty}$ and assume that there exists a couple of smooth functions $a_1$ and $a_2$ in $\Cinf([-1,1]\times \N)$ such that for all $n \in \N$,
\[AU_n = a_1(x,n) U_n + a_2(x,n) T_{n+1}\,.\]
Such a (non-unique) couple of functions is called a pair of symbols of $A$. For $n\in \Z$ and $\theta \in [0,2\pi]$, define the symbol $\tilde{\sigma}_U(a_1,a_2)$ by
\[\tilde{\sigma}_U(a_1,a_2)(\theta,n) = i a_1(\cos\theta,\abs{n}) + \sin\theta\,\text{sign}(n) a_2(\cos\theta,\abs{n})\,.\]
We say that $(a_1,a_2) \in S^\alpha_U$ if $\tilde{\sigma}_U(a_1,a_2) \in \Sigma^\alpha$, and $S^{\infty}_U \isdef \cup_{\alpha \in \Z} S^\alpha_U$. The operator defined by a pair of symbols $(a_1,a_2)$ is denoted by $\textit{Op}_U(a_1,a_2)$ and the set of pseudo-differential operatos of order $\alpha$ in $U^{-\infty}$  by $\textit{Op}(S^\alpha_U)$. 
Recall the definition of the isometric mapping $\mathcal{S}$ from \autoref{lemChar}. Adapting the proof of \autoref{PDOTs}, oe can show
\begin{The}
	\label{PDOUs}
	Let $(a_1,a_2) \in S^\alpha_U$ and $A = \textit{Op}_U(a_1,a_2)$.  There holds
	\[\mathcal{S}A = \tilde{A}\mathcal{S}\,\]
	where $\tilde{A} = \textit{Op}(\tilde{\sigma}_U(a_1,a_2))$. 
	Reciprocally, let $A : T^{\infty} \to T^{-\infty}$ a linear operator satisfying
	\[\forall u \in T^{\infty},\quad \mathcal{S}Au = \tilde{A}\mathcal{S}u\] 
	where $\tilde{A}$ is a PPDO of order $\alpha$ with a symbol $\sigma_{\tilde{A}}$. Then $A$ has a unique linear continuous extension on $T^{-\infty}$ satisfying $\mathcal{S}A = \tilde{A} \mathcal{S}$. This extension is in $\textit{Op}(S^\alpha_U)$ and $A$ admits the pair of symbols $\left(a_1^U(\tilde{A}),a_2^U(\tilde{A})\right)$.
\end{The}
\begin{Def}
	Let $A : U^{-\infty}(\Gamma) \to U^{-\infty}(\Gamma)$. We say that $A$ is a pseudo-differential operator (of order $\alpha$) on $U^{-\infty}(\Gamma)$ if $R A R^{-1} \in Op(S^{\infty}_U)$ ($\in Op(S_U^{\alpha})$). The set of pseudo-differential operators of order $\alpha$ on $U^{-\infty}(\Gamma)$ is denoted by $\textit{Op}(S^{\alpha}_U(\Gamma))$. We say that $(a_1,a_2)$ is a pair of symbols of $A$ if it is a pair of symbols of $RAR^{-1}$.  
\end{Def}
\begin{Cor}
	Let $A \in \textit{Op}(S^\alpha_U(\Gamma))$. Then for all $s$, $A$ is continuous from $U^s$ to $U^{s - \alpha}$. If $B$ and $C$ respectively belong to $\textit{Op}(S^{\alpha_1}_U(\Gamma))$ and $\textit{Op}(S^{\alpha_2}_U(\Gamma))$, with pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2}_U(\Gamma))$ and admits the pair of symbols $(a_1^U(\tilde{A}),a_2^U(\tilde{A}))$ where
	\[\tilde{A} = \textit{Op}(\tilde{\sigma}_U(b_1,b_2)) \textit{Op}(\tilde{\sigma}_U(c_1,c_2)) = \textit{Op}(\tilde{\sigma}_U(b_1,b_2)\#\tilde{\sigma}_U(c_1,c_2))\,.\]
\end{Cor}
\begin{Lem}
	Let $A \in \textit{Op}(S_T^{\alpha}(\Gamma))$ and $B = -\partial_\tau A \omega_\Gamma \partial_\tau \omega_\Gamma$. Then $B \in \textit{Op}(S_U^{\alpha+2}(\Gamma))$ and if $\tilde{A}$ is a PPDO such that $\mathcal{C}RAR^{-1} = \tilde{A} \mathcal{C}$, then $\mathcal{S}RBR^{-1} = -\partial_\theta \tilde{A} \partial_\theta \mathcal{S}$.
	\label{LemdxAomegadeomega}
\end{Lem}
\toDo{Déplacer avant et laisser en paramétrique ? A priori non. }
\begin{proof}
	On can check the following identities:
	\begin{align*}
	\partial_\theta \mathcal{S} &= - \mathcal{C} \omega \partial_x \omega \,,\\
	\partial_\theta \mathcal{C} &= - \mathcal{S} \partial_x\,.
	\end{align*}
	Let $A' = RAR^{-1}$ and $B' = RBR^{-1}$. Assuming that $\mathcal{C} A' = \tilde{A} \mathcal{C}$, there holds
	\begin{align*}
	\mathcal{S}B' &= -\mathcal{S}R \partial_\Gamma A \omega_\Gamma \partial_\Gamma \omega_\Gamma R^{-1}\\
	&= -\mathcal{S}\partial_x A' \omega \partial_x \omega\\
	&=\partial_\theta \mathcal{C}A'\omega \partial_x \omega\\
	&=\partial_\theta \tilde{A} \mathcal{C} \omega \partial_x\omega\\
	&= -\partial_\theta \tilde{A} \partial_\theta \mathcal{S}\,.
	\end{align*}
	Since $\tilde{A}$ can be chosen as a PPDO of order $\alpha$ by \autoref{PDOTs}, $\partial_\theta \tilde{A} \partial_\theta$ is then a PPDO of order $\alpha +2 $ and by \autoref{PDOUs}, we conclude that $B \in \textit{Op}(S_U^{\alpha + 2}(\Gamma))$.  
\end{proof}
\begin{Lem}
	Let $A \in \textit{Op}(S_T^{\alpha}(\Gamma))$ and $B = A \omega_\Gamma^2$. Then $B \in \textit{Op}(S_U^{\alpha}(\Gamma))$ and if $\tilde{A}$ is a PPDO such that $\mathcal{C}RAR^{-1} = \tilde{A} \mathcal{C}$, then $\mathcal{S}RBR^{-1} = \sin\tilde{A} \sin \mathcal{S}$ where $\sin$ denotes the operator $f(\theta) \mapsto \sin(\theta) f(\theta)$. 
	\label{LemAomega2}
\end{Lem}
\begin{proof}
	This follows from the identities
	\[\mathcal{S} = \sin \mathcal{C}, \quad \mathcal{C}\omega^2 = \sin \mathcal{S}\]
	and the same arguments as in the proof of \autoref{LemdxAomegadeomega}. 
\end{proof}
\begin{Def}
	Let $A$ and $B$ in $\textit{Op}(S^{\infty}_T(\Gamma))$ (resp. $\textit{Op}(S^{\infty}_U(\Gamma))$). If $A - B \in \textit{Op}(S^\alpha_T(\Gamma))$ (resp. $\textit{Op}(S^\alpha_U(\Gamma))$), we write 
	$A = B + T_\alpha \,$ (resp. $A = B + U_\alpha \,$). 
\end{Def}
	
%
%\subsubsection{Classes of operators}
%
%We shall now introduce a class of pseudo-differential operators on the open segment. Essentially, they are, up to a change of variables, the periodic pseudo-differential operators on the torus $\mathbb{T}_{1} = \mathbb{R} / \Z$ that preserve the space of 1-periodic even functions, that is, that map $H^n_e(0,1)$ to itself. A particular property of these pseudo-differential operators is that their symbol is not defined uniquely. We show that a symbolic calculus is still available within this restricted class. 
%
%\begin{Def}
%	Let $p\in \R$. If  $A : T^{\infty} \to T^{-\infty}$ can be extended into a continuous operator from $T^{s}$ to $T^{s + p}$ for any $s \in \R$, we shall say that it is of order $p$ in the scale $T^s$. When an operator is of order $p$ for all $p \in \N$, we call it a smoothing operator. 
%	
%	An operator $A : U^{\infty} \to U^{-\infty}$ which maps continuously $U^s$ to $U^{s+p}$ for all real $s$ is said to be of order $p$ in the scale $U^s$. When the family ($U^s$ or $T^s$) is clear from the context, we simply say that $A$ is of order $p$. 
%\end{Def}
%
%\begin{Def}
%	\label{DefEquivModTp}
%	Let $A$ and $B$ two operators of order $s$ in the scale $T^s$. When the operator 
%	$A - B$ is of order $p \in (0,+\infty]$, we shall write 
%	\[A = B + T_{p}.\]
%	When the scale is $U^s$ instead of $T^s$, we write 
%	\[A = B + U_{p}.\]
%\end{Def}
%
%\label{subsec:classesOfOp}
%
%To ease the computations, we define $T_n = T_{\abs{n}}$ for $n \in \Z$. 
%
%
%\begin{Def}
%	An operator $A \in \mathcal{L}(T^{-\infty})$ belongs to the class $S^{-\infty}$ if there exists a "discrete symbol" $\sigma_A : \N \times \Z$ of $A$ such that, for all $n \in \N$,
%	\[AT_n = \sum_{i \in \Z} \sigma_A(n,i) T_{n-i}\,,\]
%	with furthermore the property that there exists an integer $N$ for which 
%	\[ \abs{i} \geq N \implies \forall n \in \N, \quad \sigma_A(n,i) = 0\,.\]
%\end{Def}
%A single operator $A$ admits infinitely many discrete symbols as shown by the following example. Given $n_0$, let $\sigma$ the symbol defined by 
%\[ \sigma(n,i) = \begin{cases}
%0 & \text{ if } n \neq n_0, i \neq 0 \text{ or } i \neq 2n_0\\
%1 & \text{ if } n = n_0 \text{ and } i = 0\\
%-1 & \text{ if } n = n_0 \text{ and } i = 2 n_0\,.
%\end{cases}\]
%Then, $\sigma$ is a non-trivial discrete symbol of the null operator. Nevertheless, the next result ensures that two symbols of the same operator agree for $n$ large enough. 
%\begin{Lem}
%	\label{NonUniqueness}
%	Let $\sigma$ a discrete symbol of the null operator. Then there exists an integer $N$ such that 
%	\[n \geq N \implies \forall i \in \Z, \quad \sigma(n,i) = 0\,.\]
%	\begin{proof}
%		 By definition of $S^{-\infty}$, there exists an integer $N$ such that 
%		\[ \abs{i} \geq N \implies \forall n \in \N, \quad \sigma_A(n,i) = 0\,.\]
%		Let $n \geq N$, we can write 
%		\[0 = \sum_{i = -N+1}^{N-1} \sigma(n,i) T_{n-i} \,.\]
%		Two Chebyshev polynomials of the same order do not arise in the summation since $\forall i \in [-N +1,N-1]$, $n - i \geq 1$. Orthogonal projection against each $T_{n-i}$ thus yields 
%		\[\forall i \in [-N+1,N-1], \quad \sigma(n,i) = 0\,,\]
%		and by definition of $N$,
%		\[\forall i \in \Z, \quad \sigma(n,i) = 0\,.\]
%		This has been shown for all $n \geq N$ so the claim is proved. 
%	\end{proof}
%\end{Lem}
%
%An alternative definition is given as follows 
%\begin{Def}
%	An operator $A$ belongs to $S^{-\infty}$ if there exists two functions $a_1, a_2 : \R \times \N \to \R$ and an integer $N$ such that for all $n$, $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are polynomials of order at most $N$, and such that, for $n \geq 1$, 
%	\[AT_n(x) = a_1(n,x)T_n(x) + a_2(n,x) \omega^2 U_{n-1}(x),\]
%	while 
%	\[A T_0(x) = a_1(0,x) T_0 \,.\]
% 	We say that $(a_1,a_2)$ is a couple of semi-discrete symbols of $A$. 
%\end{Def}
%Let us prove the equivalence betwwen the two definitions.
%\begin{proof}
%	We prove that the first definition implies the second one. The calculations can also be made in the reverse order to prove the converse. Let $A\in S^{-\infty}$ and let $\sigma_A$ a discrete symbol of $A$. For $(n,i) \in \N \times \Z$, let 
%	\[f_A(n,i) = \frac{\sigma_A(n,i) + \sigma_A(n,-i)}{2}\,,\]
%	\[g_A(n,i) = \frac{\sigma_A(n,i) - \sigma_A(n,-i)}{2}\,.\]
%	We then have
%	\[\begin{split}
%	AT_n = f_A(n,0) T_n &+ \sum_{i = 1}^{+\infty} f_A(n,i) \left(T_{n+i} + T_{n-i}\right)\\
%	& + \sum_{i = 1}^{+\infty} g_A(n,i) \left(T_{n-i} - T_{n+i}\right)\,.
%	\end{split}\]
%	We use the trigonometric identities
%	\[T_iT_n = \frac{T_{n+i} + T_{n-i}}{2}\,.\]
%	\[\omega^2U_{i-1}U_{n-1} = \frac{T_{n-i} - T_{n+i}}{2}\,,\]
%	to get
%	\[AT_n = a_1(n,x) T_n + \omega^2 a_2(n,x) U_{n-1}\]
%	with 
%	\[a_1(n,x) = f_A(n,0) + 2\sum_{i = 1}^{+\infty}f_A(n,i) T_i(x)\,,\]
%	\[a_2(n,x) = 2\sum_{i = 1}^{+\infty}g_A(n,i) U_{i-1 }(x)\,.\]
%	There exists $N$ such that for each $n$, $f_A(n,i)$ and $g_A(n,i)$ are null for $ \abs{i} \geq N$. This implies that $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are polynomials of degree at most $N$. 
%\end{proof}
%As before, there are non-trivial couple of semi-discrete symbols for the null operator. For example, let $a_1$ and $a_2$ be defined as follows. Fix $n_0$ and take $a_1(x,n) = a_2(x,n) = 0$ for $n \neq n_0$, while 
%\[a_1(n_0,x) = -\omega^2 U_{n_0-1}(x) \,,\] 
%\[a_2(n_0,x) = T_{n_0}(x)\,. \]
%Nevertheless, two couple of semi-discrete symbols of the same operator agree for $n$ large enough:
%\begin{Lem}
%	\label{NonUniqueness2}
%	Let $(a_1,a_2)$ a couple of semi-discrete symbols for the null operator. Then there exists $N$ such that $n \geq N$ implies $a_1(n,x) = a_2(n,x) = 0$. 
%\end{Lem}
%\begin{proof}
%	By definition, there exists an integer $N$ such that for all $n$, $a_1(n,\cdot)$ is a polynomial of order less than $N$. Fix $n \geq N$. We have 
%	\[0 = a_1(n,x) T_n(x) + a_2(n,x)\omega^2 U_{n-1}(x)\]
%	and let $(z_i)$ the $(n+1)$ distinct roots of $\omega^2 U_{n-1}$. Note that $T_n(z_i)$ is non-zero for all $i$, thus, for 
%	\[\forall 1 \leq i \leq n+1, \quad a_1(n,z_i) = 0 \,.\]
%	Thus, $a_1(n,\cdot)$ has $n+1$ distinct roots while being a polynomial of order less than $n$. Therefore, $a_1(n,\cdot) = 0$. This in turn implies that $a_2(n,\cdot) = 0$. 
%\end{proof}
%As $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are required to be polynomials, it is in fact possible to ensure uniqueness of the couple by Euclidean division. We may for example ask that $a_1(n,x)$ has a degree less than $n$. If there exists an admissible couple, then we can change $a_1$ such that this condition be satisfied by writing 
%\[a_1(n,\cdot) = b_1(n,\cdot) + Q(x)\omega^2 U_{n-1}(x)\]
%where $b_1(n,\cdot)$ has a degree less than $n$. Then, letting $b_2(n,x) = a_2(n,x) + Q(x)$, we have exhibited such a couple. Of course, with this condition, the null operator only has trivial semi-discrete symbols, by the same arguments as in the proof of the previous lemma. In practice, this uniqueness condition does no seem to bear any special interest. 
%
%Notice that the action of $A$ on a function $u$ is given in terms of a couple of semi-discrete symbols $(a_1, a_2)$ by 
%\[Au(x) = \sum_{n = 0}^{+ \infty} a_1(n,x) \hat{u}_n T_n(x) + \omega^2 \sum_{n = 1}^{+ \infty} a_2(n,x) \hat{u}_n U_{n-1}(x)\, .\]
%Letting $x = \cos(\theta)$ we have 
%\[\begin{split}
%Au (\cos(\theta)) =  &\sum_{n = 0}^{+ \infty} a_1(n,\cos(\theta)) \hat{u}_n \cos(n\theta)\\ 
%&+ \sum_{n = 1}^{+ \infty} \sin(\theta) a_2(n,\cos(\theta)) \hat{u}_n \sin(n\theta)\,.
%\end{split}\]
%Let $\tilde{A}$ the operator defined on $H^n_e(0,1)$ by  
%\[\tilde{A} f (t) = A u (\cos(2\pi t))\]
%where $f(\theta) = u(\cos(2\pi t))$. The Fourier coefficients of $f$ defined by 
%\[\hat{f}_n = \int_{0}^{1}e^{-2i \pi t \cdot n} f(t) dt\]
%satisfy $\hat{f}_n = \frac{\hat{u}_n}{2}$ 
%for $n \neq 0$, and $\hat{f}_0 = \hat{u}_0$. Thus
%\[\begin{split}
%\tilde{A}f (t) =  a(0,x) \hat{f}_0 + &2\sum_{n = 1}^{+ \infty} a_1(n,\cos(2\pi t)) \hat{f}_n \cos(2n \pi t)\\ 
%+&2\sum_{n = 1}^{+ \infty} \sin(2 \pi t) a_2(n,\cos(2 \pi t)) \hat{f}_n \sin(2n \pi t)\,.
%\end{split}\,.\]
%This coincides with a discrete pseudo-differential operator, as defined in \cite{thrunen1998symbol}, with a symbol $\sigma_A$ equal, for $n \neq 0$, to
%\[\sigma_A(n,t) = a_1(\abs{n},\cos(2\pi t)) + i \text{sign}(n) \sin(2\pi t)a_2(\abs{n},\cos(2\pi t))\,.\]
%and for $n= 0$ to
%\[\sigma_A(0,t) = a_1(0,\cos(2\pi t))\,.\]
%Contrary to \cite{thrunen1998symbol}, the resulting symbol $\sigma_A$ is restricted to the class of trigonometric polynomials of bounded degree in the second variable as would result here of our hypothesis for $a_1$ and $a_2$. We need this assumption in order to have a form of uniqueness in our symbols, but consequently, this prevents us from directly applying the results of the previous work. We thus need to prove that our class is still an algebra. 
%
%\begin{Def}
%	\label{defClassSk2}
%	For any real $p$, an operator $A$ belongs to the class $S^{p}$ if one of its discrete symbols $\sigma_A$ satisfies:  \begin{equation}
%		\label{Condition2}
%		\forall (\alpha,i) \in \N \times \Z \,,\exists C_{i,k} >0 : \forall k  \in \Z, \quad  \abs{\Delta_k^\alpha \sigma_A(k,i)} \leq C_{\alpha,i} (1 + k)^{-p - \alpha}\,.
%	\end{equation}
%	Here $\Delta_k$ is the difference operator in the variable $k$ (denoted simply by $\Delta$ when there is only one variable), defined by
%	\[\Delta_k a(k,i) = a(k+1,i) - a(k,i),\]
%	and $\Delta^\alpha_k$ is the $\alpha$-th iterate of $\Delta_k$.
%\end{Def}
%By \autoref{NonUniqueness}, if $A \in S^p$, then any symbol of $A$ satisfies the previous condition. 
%We state an equivalent definition using this time a couple of semi-discrete symbols.
%\begin{Lem}
%	The following conditions are equivalent:
%	\begin{itemize}
%		\item[-] $A \in S^p$
%		\item[-] There exists a couple of semi-discrete symbols $(a_1,a_2)$ of $A$ such that, for $i = 1,2$,
%		\begin{equation}
%		\label{Condition2bis}
%		\forall (\alpha,x) \in \N\,,\exists C_{\alpha} >0 : \forall (k,x)  \in \Z\times[-1,1], \quad  \abs{\Delta_k^\alpha a_i(k,x)} \leq C_{\alpha} (1 + k)^{-p - \alpha}\,.
%		\end{equation}
%	\end{itemize}
%If one of those conditions hold, then the condition \eqref{Condition2bis} holds for any couple of semi-discrete symbols of $A$. 
%\end{Lem}
%\begin{proof}
%	Given a discrete symbol $\sigma_A$ of $A$, $A$ admits the couple of semi-discrete symbols $(a_1,a_2)$ given by 
%	\[a_1(n,x) = f_A(n,0) + 2\sum_{i = 1}^{+\infty}f_A(n,i) T_i(x)\,,\]
%	\[a_2(n,x) = 2\sum_{i = 1}^{+\infty}g_A(n,i) U_{i-1 }(x)\,.\]
%	with $f_A$ and $g_A$ defined as
%	\[f_A(n,i) = \frac{\sigma_A(n,i) + \sigma_A(n,-i)}{2}\,,\]
%	\[g_A(n,i) = \frac{\sigma_A(n,i) - \sigma_A(n,-i)}{2}\,.\]
%	We have by linearity
%	\[\Delta_k^\alpha a_1(k,x) = \Delta_k^\alpha \sigma_A(n,0) + \sum_{i = 1}^{+\infty}\left(\Delta_k^\alpha \sigma_A(n,i)+\Delta_k^\alpha \sigma_A(n,-i) \right) T_i(x)\,.\]
%	We now apply condition \eqref{Condition2} to each term in the sum and with triangular inequality, 
%	\[\abs{\Delta^\alpha_na_1(k,x)} \leq C_\alpha (1 + k)^{-p-\alpha}\]
%	with $C_\alpha = \sum_{i = 0}^{+ \infty}C_{\alpha,i}$, where $C_{\alpha,i}$ are the constant from condition \eqref{Condition2} (recall the sum is actually finite). The same kind of computations gives a similar estimate for $a_2$ and the direct implication is proved. Conversely, let $(a_1,a_2)$ a couple of semi-discrete symbols of $A$ satisfying the condition \eqref{Condition2bis}. Then, reversing the computations, $A$ admits the discrete symbol $\sigma_A$ defined for $n \in \N$ and $i \in \Z$ by
%	\begin{equation}
%		\sigma_A(n,i) = f_A(n,\abs{i}) + \text{ sign} (i) g_A(n,\abs{i})
%		\label{combiner}
%	\end{equation}
%	with, for $i \in \N$, (by orthonormal projection),
%	\[f_A(n,i) = \begin{cases}\frac{1}{2 \norm{T_i}^2_\frac{1}{\omega}}\duality{a_1(n,x)}{T_i}_\frac{1}{\omega}& \text{ if } i \neq 0\\
%	\frac{1}{ \norm{T_0}^2_\frac{1}{\omega}}\duality{a_1(n,x)}{T_0}_\frac{1}{\omega} & \text{ if } i = 0\,.
%	\end{cases}\]
%	and 
%	\[g_A(n,i) = \begin{cases}\frac{1}{2 \norm{U_{i-1}}^2_{\omega}}\duality{a_2(n,x)}{U_{i-1}}_{\omega}& \text{ if } i \neq 0\\
%	0 & \text{ if } i = 0\,.
%	\end{cases}\]
%	Fix $i \in \N^*$. We have for all $k$, by linearity,
%	\[\Delta_k^\alpha f_A(k,i) = \frac{1}{2 \norm{T_i}^2_\frac{1}{\omega}}\duality{\Delta^\alpha_k a_1(k,x)}{T_i}_\frac{1}{\omega}\,.\]
%	Using Cauchy-Schwarz inequality and assumption \eqref{Condition2bis} for $a_1$, we get 
%	\[\abs{\Delta_k^\alpha f_A(k,i)} \leq C_{i}C_\alpha(1+k)^{-p - \alpha}\,,\]
%	with $C_i = \frac{1}{\norm{T_i}}_\frac{1}{\omega}$. Similar estimates can be shown in the same way for $i = 0$ and also for $g_A$. We finally combine them with \eqref{combiner} to conclude for the reverse implication. 
%	The last statement is obvious in view of \autoref{NonUniqueness2}. 
%\end{proof}
%An interpolation procedure gives the following result:
%\begin{Lem}
%	The following propositions are equivalent:
%	\begin{itemize}
%		\item[-] $A \in S^p$
%		\item[-] There exists a couple of functions $(\nu_1(\xi,x),\nu_2(\xi,x))$ defined for $(\xi,x) \in \R^+ \times [-1,1]$, and an integer $N$ such that $a_1$ and $a_2$ are $C^{\infty}$ in $\xi$ and $(\nu_{1|\N \times[-1,1]},\nu_{2|\N \times[-1,1]})$ is a couple of symbols for $A$, with furthermore the property
%		\[\forall \alpha, \exists C_\alpha > 0 : \forall (\xi,x) \in \R+ \times [-1,1], \quad \abs{\partial_\xi^\alpha \nu_i(x,\xi)} \leq C_\alpha (1 + \xi)^{-p - \alpha}\,.\]
%	\end{itemize}
%	We call $(\nu_1,\nu_2)$ a couple of continuous symbols of $A$. 
%\end{Lem}
%\begin{proof}
%	\toDo{Utiliser la procédure d'interpolation du papier PDO discrets.}
%\end{proof}
%
%
%\subsubsection{Symbols that are rational functions of $n$.}
%
%\toDo{Il va peut-être falloir enlever cette section à cause de l'équivalence du lemme précédent.}
%
%Given a discrete symbol $\sigma(n,i)$, is not straightforward to check that the condition \eqref{Condition2} holds for this symbol. We now show that this is the case when $\sigma(n,i)$ is a rational function of $n$. We will repeatedly make use the following forms of Peetre's inequality: for any real $a,b$ and $s$, 
%\begin{equation}
%\label{Peetre1}
%	(1 + \abs{a + b})^s \leq \left(1 + \abs{a}\right)^{\abs{s}} \left(1 + \abs{b}\right)^{s}
%\end{equation} 
%and
%\begin{equation}
%\label{Peetre2}
%\left(1 + \abs{a + b}^2\right)^s \leq 2^{\abs{s}}\left(1 + \abs{a}^2\right)^{\abs{s}} \left(1 + \abs{b}^2\right)^{s}\,.
%\end{equation} 
%\begin{Lem}
%	\label{lemDeltaDerivees}
%	Let $f$ a $C^{\alpha}$ function on $[k,k+\alpha]$. Then for all $k$, 
%	\begin{equation}
%	\label{formule1}
%		\Delta^{\alpha} f(k) =  \int_{x_1 =k}^{k+1}\int_{x_2 = x_{1}}^{x_{1}+1} \cdots \int_{x_\alpha = x_{\alpha-1}}^{x_{\alpha-1}+1} f^{(\alpha)}(x_\alpha)dx_1dx_2 \cdots dx_{\alpha}
%	\end{equation}
%\end{Lem}
%\begin{proof}
%	We show by induction that for all $1 \leq \beta \leq \alpha$, 
%	\begin{equation}
%	\label{hypRec1}
%		\Delta^{\alpha} f(x) = \int_{x}^{x+1} \int_{x_{1}}^{x_{1}+1} \int_{x_{\beta-1}}^{x_{\beta-1}+1} \Delta^{\alpha - \beta} f^{(\beta)}(x_\beta)dx_1dx_2 \cdots  dx_\beta.
%	\end{equation}
%	For $\beta = 1$, we write 
%	\[\Delta^{\alpha}f(x) = \Delta^{\alpha-1}f(x+1) - \Delta^{\alpha-1}f(x),\]
%	therefore,
%	\[\Delta^{\alpha}f(x) = \int_{x}^{x+1} \frac{d}{dx_1}\left(\Delta^{\alpha-1}f\right)dx_1.\]
%	This proves the property for $\beta = 1$. 
%	Let $ 1 \leq \beta < \alpha$ and assume that \eqref{hypRec1} holds for this $\beta$. Then we write
%	\[\Delta^{\alpha - \beta} f^{\beta}(x_\beta) = \int_{x_\beta}^{x_\beta+1} \frac{d}{dx_{\beta}}\Delta^{\alpha - \beta} f^{(\beta)}(x_{\beta+1})dx_{\beta+1}.\]
%	Of course, $\Delta$ and $\frac{d}{dx}$ commute, thus 
%	\[\Delta^{\alpha - \beta} f^{\beta}(x_\beta) = \int_{x_\beta}^{x_\beta+1} \Delta^{\alpha - \beta} f^{(\beta+1)}(x_{\beta+1})dx_{\beta+1}.\]
%	Replacing in \eqref{hypRec1}, this proves the heredity of the property. Finally, taking $\beta = \alpha$ in \eqref{hypRec1} gives the announced result. 
%\end{proof}
%\begin{Cor}
%	\label{lemFracRat}
%	If $f$ is a rational function of degree $p$ which poles are contained in $\mathbb{C} \setminus \N$, then there exists a constant $C_\alpha$ such that for all $k \in \N$, \[\abs{\Delta^{\alpha} f(k)} \leq C_\alpha (1+k)^{p - \alpha}\,.\]
%\end{Cor}
%\begin{proof}
%	Fix a rational fraction $F$ of degree $p$, with poles in $\mathbb{C} \setminus \N$. $F$ is of the form 
%	\[F = P + R\]
%	where $P$ is zero if $p < 0$ and a polynomial of degree $p$ otherwise, and $R$ is a finite linear combination of quantities of the form 
%	\[Q_i(X) = \frac{1}{(X - x_i)^{q}}\]
%	with $x_i \in \mathbb{C} \setminus \N$ and $q \geq -p$. The claimed result is an easy consequence of the following two fact:
%	\begin{itemize}
%		\item[-] If the polynomial $P$ is of degree $p \geq 0$, there holds
%		\[\abs{\Delta^{\alpha} P}(k)  \leq C (1+k)^{p - \alpha},\]
%		\item[-] For the terms $Q_i(X) = \frac{1}{(X - x_i)^{q}},$ there holds
%		\begin{equation}
%		\label{termeQi}
%			\abs{\Delta^{\alpha} Q_i}(k)  \leq C (1+k)^{-q - \alpha}\,.
%		\end{equation}
%	\end{itemize}
%	We first treat the polynomial case. If $\alpha > p$, we have $P^{(\alpha)} = 0$, and thus, by \autoref{lemDeltaDerivees}, $\Delta^{\alpha} P(k) = 0$, and the result is obvious. If $\alpha \leq p$, there exists a constant $C$ such that
%	\[\abs{P^{(\alpha)}(x)} \leq C (1 + x)^{p - \alpha}.\]
%	We inject this in \eqref{formule1}. In the domain of integration, $x_\alpha \leq k + \alpha$, thus
%	\[\abs{\Delta^{q} P}(k) \leq C (1 + (k + \alpha))^{p - \alpha} \leq C (1 + \alpha)^{p-\alpha}(1+k)^{p - \alpha}\]
%	by Peetre's inequality \eqref{Peetre1}. This proves the claim for the polynomial term. 
%	
%	\noindent For $Q_i$, we write:
%	\[Q_i^{(\alpha)}(x) = \frac{(-1)^k p(p+1) \cdots (p+\alpha)}{(x - x_i)^{p+\alpha}}.\]
%	For $x \geq \max \left(1,2 \abs{x_i}\right)$, using Peetre's inequaliy \eqref{Peetre1}, we get
%	\[\abs{Q^{(\alpha)}(x)} \leq \frac{p(p+1) \cdots (p+\alpha)}{(1+x)^{p + \alpha}}.\]
%	We then proceed with the same arguments as for $P$ and conclude that \eqref{termeQi} holds with some constant $C_1$ for all $k  \geq k_0$ where $k_0$ is an integer greater than $\max \left(1,2 \abs{x_i}\right)$. Then \eqref{termeQi} holds for all $k$ with 
%	\[C = \max(C_1,\Delta^{\alpha} Q_i(0), \cdots, \Delta^\alpha Q_i(k_0))\,.\]
%\end{proof}
%
%\subsubsection{Algebraic properties of $S^p$}
%\begin{Lem}
%	If $A\in S^p$, then $A$ is of order $p$ in the scale $T^s$. 
%\end{Lem}
%\begin{proof}
%	Since the sum in the condition (i) is finite, by linearity, showing that the operator $A$ is of order $p$ amounts to proving that the operator $A_i$ defined by
%	\[ \forall k \in \Z, \quad  A_i T_k = a(k,i) T_{k-i} \]
%	is of order $p$. We treat the case $i > 0$, the opposite case being analogous. Let $u \in T^s$ for some $s$, there holds 
%	\[ A_i u = \sum_{k = 0}^{+ \infty} a(i+k,i)\hat{u}_{k + i}T_k + \sum_{k = 0}^{i} a(i - k,i) \hat{u}_{i - k}T_k.\]
%	Let $Vu$ and $Ru$ respectively the two terms of the rhs. Obviously, $R$ is a smoothing operator. Now, for all $k \in \N$ let
%	\[\hat{v}_k \isdef a(i + k,i) \hat{u}_{i + k}.\]
%	Applying Peetre's inequality \eqref{Peetre2},
%	\[(1 + k^2)^{n + s}\abs{\hat{v}_k}^2 \leq 2^{\abs{p+s}}\left(1 + i^2\right)^{\abs{p + s}}\left(1 + (i + k)^2\right)^{p + s} \abs{a(k + i,i)}^2 \abs{\hat{u}_{k+i}}^2.\]
%	Condition (ii) with $\alpha = 0$ yields
%	\[\abs{a(k+i,i)}^2 \leq C\left(1 + (k+i)\right)^{-2p} \leq 2^{\abs{p}}C \left(1 + (k+i)^2\right)^{-p}.\]
%	Therefore, $\norm{V u}_{T^{s + p}} \leq C(1 + i)^{\abs{n + s}} \norm{u}_{T^s}$ which shows that $A$ is of order $p$.
%\end{proof}
%\begin{Lem}
%	\label{LemCompo}
%	If $A \in S^{p}$, $B \in S^{q}$, then $AB$ is in $S^{p + q}$, 
%\end{Lem}
%\begin{proof}
%	A symbol of $AB$ is given by
%	\[c(k,i) = \sum_{j = - \infty}^{+ \infty} a(k - j, i - j) b(k,j).\]
%	This formula is obtained writing the expression of $AB T_n$ using a symbol of $A$ and $B$ and using the identity $T_i T_j = T_{i + j} + T_{i -j}$. 
%	Let $N_a$ such that $\abs{i} \geq N_a \implies a(k,i) = 0$ and let $N_b$ defined in a similar way. Then, it is easy to check that $\abs{i} \geq N_a + N_b \implies c(k,i) = 0$. It remains to check the requirement (ii). Since the sum defining $c$ only has a finite number of non-zero terms, we just have to show that for any $j \in \Z$, the function $c_{j}(k,i) \isdef a(k-j,i-j) b(k,j)$ satisfies
%	\[\forall \alpha \in \N, \forall i,k, \in \Z, \quad  \abs{\Delta_k^\alpha c_{j}(k,i)} \leq C_{i,j,\alpha} (1 + k^2)^{p + q - \alpha}.\]
%	The announced result then follows by linearity. 
%	To prove this, one can check by induction that for any $\alpha \in \N$, $\Delta^\alpha c_j(k,i)$ is of the form 
%	\[\Delta^\alpha_k c_j(k,i) = \sum_{l = 1}^L \lambda_l \Delta_k^{\beta_l}a(k_{l,1},i-j) \Delta_k^{\alpha - \beta_l} b(k_{l,2},j)\]
%	for some coefficients $\lambda_l$, where $L$ is a finite number, and where, for all $l$, $\beta_l \leq \alpha$ while $k_{l,1}$ and $k_{l,2}$ respectively lie in the interval $[k-j,k-j + \beta_l]$ and $[k,k+\alpha - \beta_l]$. Let us fix $l \in [1,L]$. We have
%	\[\abs{\Delta_k^{\beta_l} a(k_{l,1},i-j)} \leq C_{i,j,\alpha,l}(1 + k_1)^{p - \beta_l}\]
%	and by Peetre's inequality
%	\[(1+k_1)^{p - \beta_l} \leq C(1+k)^{p - \beta}(1 + \alpha + \abs{j})^{\abs{p - \beta_l}}.\]
%	The same arguments applied to $b$ lead to 
%	\[\abs{\Delta_k^{\beta} a(k_1,i-j)\Delta_k^{\alpha - \beta} b(k_2,j)} \leq C_{i,j,\alpha,l} (1+k)^{p + q}\]
%	which implies our claim. 
%\end{proof}
%\begin{The}
%	If $A \in S^{p}$ and $B \in S^q$, then $AB - BA$ is in $S^{p + q + 1}$. 
%	\label{CommutPDO}
%\end{The}
%\begin{proof}
%	A symbol of $C= AB - BA$ is given by
%	\[\sigma_{C}(k,i) = \sum_{j = -\infty}^{+\infty} a(k-j,i-j)b(k,j) - \sum_{j = - \infty}^{+\infty} b(k-j,i-j) a(k,j).\]
%	In the second sum, we change the index to $j' = i -j$, yielding 
%	\begin{eqnarray*}
%		\sigma_{C}(k,i) &=& \sum_{j = -\infty}^{+\infty} a(k-j,i-j)b(k,j) - \sum_{j = - \infty}^{+\infty} b(k-i +j',j') a(k,i-j').\\
%		&=& \sum_{j = -\infty}^{+\infty} \left[a(k-j,i-j) - a(k,i-j)\right]b(k,j) \\
%		&& - \sum_{j = - \infty}^{+\infty} a(k,i-j) \left[b(k - i + j') -b(k,j)\right].\\
%	\end{eqnarray*}
% 	Let us consider one of the terms of the first sum when $j$ is positive. We can write 
%\begin{eqnarray*}
%	\left[ a(k-j,i-j) - a(k,i-j)\right]b(k,j) = - \sum_{l = 0}^{j-1} \Delta_k a(k-j + l+1,i-j)b(k,j).
%\end{eqnarray*}
%The estimation (ii) required for the symbol $\sigma_C$ can be established for this individual term from the same considerations as in the proof of the previous result. The other terms are treated in an analogous way.  
%\end{proof}
%\subsubsection{Symbolic calculus}
%
%For a couple of (semi-discrete or continuous) symbols $a_1,a_2$, let $H$ the operator defined by 
%\[H(a_1,a_2) = (-\omega \partial_x \omega a_2, \partial_x a_1)\]
%and let the multiplication of couples of symbols be defined by 
%\[(a_1,a_2) \times (b_1,b_2) = (a_1b_1 - \omega^2 a_2b_2, a_1b_2 + a_2 b_1)\,.\]
%
%Let $\nu = (\nu_1,\nu_2)$ a couple of continuous symbols of an operator in $S^p$. For all $\alpha \in \N$, we write $\partial_n^\alpha \nu \isdef (\partial_\xi^\alpha \nu_1, \partial_\xi^\alpha \nu_2)$. This is of course a couple of continuous symbols for an operator in $S^{p + \alpha}$. 
%\begin{Lem}
%	Let $(a_1,a_2)$ and $(b_1,b_2)$ two couple of symbols of two operators $A \in S^p$ and $B \in S^q$. Then $H(a_1,a_2)$ is a couple of symbols for an operator in $S^p$ and $(a_1,a_2) \times (b_1,b_2)$ is a couple of symbols for an operator in $S^{p+q}$. 
%\end{Lem}
%\toDo{Preuve pédestre de ça.}
%\toDo{Definition of Asymptotic expansion}
%
%\begin{The}
%	Let $A \in S^p$ and $B \in S^q$ with respctive couples of continuous symbols $a = (a_1,a_2)$ and $b = (b_1,b_2)$. Then a couple of continuous symbols $c = (c_1,c_2)$ of $C = AB$ is given by 
%	\[c = \sum_{\alpha = 0}^{+ \infty} \frac{1}{\alpha!}\partial_\xi^\alpha a \times H^k(b) \]
%\end{The}
%\begin{proof}
%	\toDo{Appliquer les résultats connus pour les opérateurs discrets, ou simplement reproduire la preuve qui est tout simple ici.}
%\end{proof}
%
%\begin{Lem}
%	\label{lem:multPolyOrdre0}
%	If $P$ is a polynomial, the multiplication by $P$ defines an operator of $S^0$. 
%\end{Lem}
%\begin{proof}
%	For all $n$, we have $xT_n = \frac{T_{n+1} + T_{n-1}}{2}$, thus $x$ is in the class $S^0$. By \autoref{LemCompo}, the same is true for $x^n$ for any $n$, and by linearity, for any polynomial. 
%\end{proof}
%The next two lemmas enlarge the class of operators for which we can assess the order. \autoref{ordreNoyauxMultipl} allows us to treat a rather general class of operators and will allow us to evaluate the order of the remainders in Taylor expansions of the kernels. 
%\begin{Lem}
%	\label{lem:multByPsiOrdre0}
%	If $\psi$ is a $C^{\infty}$ function on $[-1,1]$, then the operator
%	\[ u(x) \mapsto \psi(x) u(x)\]
%	is of order $0$, and for any $s \in \R$, 
%	\[ \norm{\psi u}_{T^s} \leq C2^{\abs{s}/2}\norm{u}_{T^s} \norm{\psi}_{T^{\abs{s}+1}}.\]
%	where $C$ is independent of $\psi$ and $s$. 
%\end{Lem}
%\begin{proof}
%	Let $u \in T^s$, we rewrite $u$ as 
%	\[ u = \sum_{n = -\infty}^{+ \infty}u_n'T_n\]
%	where for $n< 0$ we define $T_{n} = T_{\abs{n}}$, and with 
%	\[u_n' = \begin{cases}
%	u_0 & \text{ if } n = 0\\
%	\frac{u_{\abs{n}}}{2} & \text{ otherwise.}
%	\end{cases}\]
%	We apply the same idea to $\psi$, and using $T_m T_n = T_{m+n} + T_{m-n}$, 
%	\[\psi u = \sum_{m,n} u'_n \psi'_m (T_{m+n} + T_{m-n}) = \sum_{m} \left(\sum_{n}u'_n(\psi'_{n + m} + \psi'_{n - m})\right) T_m\]
%	that is,
%	\[\psi u = 2\sum_{m,n} u'_m \psi'_{m-n} T_{n}\]
%	Using Peetre's inequality, we have 
%	\[(1 + n^2)^{s/2}\abs{(\psi u)_n} \leq 2^{\abs{s}/2+1}\sum_{m}(1 + m^2)^{s/2} \abs{u'_m}  (1 + |n-m|^2)^{\abs{s/2}} \abs{\psi'_{n-m}} \]
%	and by Young's inequality with $r = 2, p = 2, q = 1$, 
%	\[\norm{\psi u}_s^2 \leq 2^{\abs{s}+2}\norm{u}_s^2 \sum_{m=-\infty}^{+\infty} (1 + m^2)^{\abs{s}/2}\abs{\psi'_m} \]		
%	The last sum is finite because $\psi \in T^{\infty}$ and
%	\[\sum_{m=-\infty}^{\infty}(1 + m^2)^{\abs{s}/2} \abs{\psi'_m} \leq \left(\sum_{m = -\infty}^{+ \infty} \frac{1}{1 + m^2} \right)\sum_{m=-\infty}^{+\infty} (1 + m^2)^{\abs{s}+1}\abs{\psi'}_m^2.\]
%\end{proof}
%\begin{Lem}
%	\label{ordreNoyauxMultipl}
%	Let $G$ an integral operator with kernel $g$, that is
%	\[G : u \mapsto \int_{-1}^{1} \frac{g(x,y) u(y)}{\omega(y)}dy\,.\]
%	We assume that $G$ is of order $p$. Let $r(x,y)$ a $C^{\infty}$ function. Then the operator 
%	\[K : \int_{-1}^{1} \frac{g(x,y) r(x,y) u(y)}{\omega(y)}dy\]
%	is of order $p$. 
%\end{Lem}
%\begin{proof}
%	Since $r$ is in $C^{\infty}$, one can show that $r$ admits the following expression:
%	\begin{equation}
%	r(x,y) = \sum_{m,n} r_{m,n} T_m(x) T_n(y)
%	\label{sommenormalementcv}
%	\end{equation}
%	Moreover, the regularity of $R$ ensures $r_{m,n}$ satisfies for all $s,t \in \R$, 
%	\[\sum_{m,n} (1 + m^2)^s (1 + n^2)^t\abs{r_{m,n}}^2 < +\infty.\] 
%	To prove this property, one can for example apply the operator $(\omega \partial_x)^2$ repeatedly in the two variables. The resulting function is $C^\infty$, and in particular, square integrable on $[0,1] \times [0,1]$. We then write the Parseval's identity and the result follows. We can write 
%	\[Ku = \sum_{m,n} r_{m,n} T_m G T_n u  \]
%	where for each $m,n$, the operator $T_m G T_n$ is defined by 
%	\[ T_m G T_n u (x)= T_m(x) \int_{-1}^{1} \dfrac{G(x,y) T_n(y)u(y)}{\omega(y)}dy.\]
%	Fix $s \in \R$, this operator is in $L(T^s,T^{s+p})$ by the previous lemma, with 	
%	\[\norm{T_m G T_n}_{T^s \to T^{s+p}} \leq \norm{G}_{T^s \to T^{s + p}} 2^{\abs{s} + \abs{s + p}}(1 + n^2)^{\abs{s}+1}(1 + m^2)^{\abs{s+ p} + 1}.\]
%	thus, the series in \eqref{sommenormalementcv} is normally convergent in $L(T^s, T^{s + p})$, which proves the claim. 
%\end{proof}
%As a consequence, since the operator $G$ with kernel $g \equiv 1$ is a smoothing operator, we have the following result:
%\begin{Cor}
%	\label{lemSmoothingOp}
%	Let $r \in C^{\infty}([-1,1]^2)$. Then
%	\[ u \mapsto \int_{-1}^{1} \frac{r(x,y)u(y)}{\omega(y)}dy\]
%	is a smoothing operator. 
%\end{Cor}


\section{Application to Helmholtz scattering}

In this section, we apply the analytical tools introduced in the previous section to the study of the Helmholtz scattering problems. The object of this section is to prove \autoref{TheSkomega} and \autoref{TheNkomega}. We start by introducing the notations, and characterize the spaces $T^s$ and $U^s$ for $s = \pm \frac{1}{2}$. 


\subsection{The scattering problem for an open curve}
\toDo{Faire les mêmes modifs que sur le papier concis.}

\label{sec:scattering}
Recall the parametrization of the curve $\Gamma$ \autoref{param}.
We seek a solution to the two problems
\begin{equation}
-\Delta u_i - k^2 u_i = 0,  \text{ in } \R^2 \setminus \Gamma, \quad i = 1,2
\label{Helmholtz}
\end{equation}
with the following additional conditions
\begin{itemize}
	\item[-] Dirichlet or Neumann boundary conditions, respectively
	\begin{equation}
	u_1 = u_D, \text{ and  } \dfrac{\partial u_2}{\partial n} = u_N \text{ on } \Gamma
	\label{DirichletEtNeumann}
	\end{equation}
	where $\frac{\partial u}{\partial n} = n_\Gamma \cdot \nabla u$.
	\item[-] Suitable decay at infinity, given for $k > 0$ by the Sommerfeld condition
	\begin{equation}
	\dfrac{\partial u}{\partial r} - iku = o\left(\frac{1}{\sqrt{r}}\right)
	\label{Sommerfeld}
	\end{equation}
	with $r=|x|$ for $x\in \mathbb{R}^2$.
\end{itemize}
When $k=0$, the radiation condition must be replaced by an appropriate decay of $u$ and $\nabla u$ at infinity, see for example \cite{wendland1990hypersingular,stephan1984augmented}, or \cite[Chap. 7]{mclean2000strongly} \toDo{Vérifier le chapitre et la page}. 
Existence and uniqueness results are available for those problems, but the solutions fail to be regular even with smooth data $u_D$ and $u_N$. More precisely,  let $\lambda = \left[\frac{\partial u_1}{\partial n}\right]_\Gamma$ and $\mu = \left[u_2\right]_\Gamma$ where $ \left[\cdot \right]_\Gamma$ refers to the jump of a quantity across $\Gamma$, we have the following result.
\begin{The}
	(see e.g. \cite{stephan1984augmented,wendland1990hypersingular,monch1996numerical}) Assume $u_D \in H^{1/2}(\Gamma)$, and $u_N \in H^{-1/2}(\Gamma)$. Then problems (\ref{Helmholtz},\ref{DirichletEtNeumann},\ref{Sommerfeld}) both possess a unique solution $u_i \in H^1_\textup{loc}(\R^2 \setminus \Gamma)$, which is of class $C^{\infty}$ outside $\Gamma$. Near the edges of the screen $\Gamma$, $\lambda$ is unbounded:
	\[\lambda(x)  = O\left(\frac{1}{\sqrt{d(x,\partial \Gamma)}}\right).\]
	while $\mu$ satisfies
	\[\mu(x) = C\sqrt{d(x,\partial \Gamma)} + \psi\]
	where $\psi \in \tilde{H}^{3/2}(\Gamma)$.
	\label{theScatt}
\end{The}

For the definition of Sobolev spaces on smooth open curves, we follow
\cite{mclean2000strongly} by considering any smooth closed curve $\tilde{\Gamma}$ containing $\Gamma$, and defining 
\[H^s(\Gamma) = \enstq{U_{|\Gamma}}{ U \in H^s(\tilde{\Gamma}) }\,.\]
Obviously, this definition does not depend on the particular choice of the closed curve $\tilde{\Gamma}$ containing $\Gamma$. Moreover,
\[\tilde{H}^s(\Gamma) = \enstq{u \in H^s(\Gamma)}{\tilde{u} \in H^s(\tilde{\Gamma})}\]
where $\tilde{u}$ denotes the extension by zero of $u$ on $\tilde{\Gamma}$.

\paragraph{Single-layer potential}  
We define the single-layer potential by
\begin{equation}
\mathcal{S}_k\lambda(x) = \int_{\Gamma}G_k(x-y)\lambda(y)d\sigma(y)
\label{defSk}
\end{equation}
where $G_k$ is the Green's function
\begin{equation}
\left\{
\begin{aligned}
G_0(z) &= -\dfrac{1}{2\pi} \ln \abs{z}, && \text{ if } k= 0,\\
G_k(z) &= \frac{i}{4}H_0(k|z|), && \text{ if } k > 0,
\end{aligned} 
\right.
\end{equation} 
for $x\in \mathbb{R}^2\setminus \Gamma$. Here $H_0$ is the Hankel function of the first kind. 
For $k > 0$, the solution $u_1$ to the Dirichlet problem admits the representation
\begin{equation}
u_1 = \mathcal{S}_k \lambda
\label{repr_u1}
\end{equation}
where $\lambda \in \tilde{H}^{-1/2}(\Gamma)$ is the jump of the normal derivative of $u_1$ across $\Gamma$ and is the unique solution to 
\begin{equation}
S_k \lambda = u_D\,.
\label{Sklambda}
\end{equation}
Here, $S_k \isdef \gamma \mathcal{S}_k$ where $\gamma$ is the trace operator on $\Gamma$. The operator $S_k$ maps continuously $\tilde{H}^{-1/2}(\Gamma)$ to $H^{1/2}(\Gamma)$. When $k = 0$, the computation of $u_1$ also involves the resolution of \eqref{Sklambda} but some subtleties arise in the representation of $u_1$ by \eqref{repr_u1}. On this topic, see \cite[Theorem 1.4]{stephan1984augmented}.

\paragraph{Double-layer and hypersingular potentials}
Similarly, we introduce the double layer potential $\mathcal{D}_k$ by 
\[\mathcal{D}_k \mu(x) = \int_{\Gamma} N(y) \cdot \nabla G_k(x-y) \mu(y) d\sigma(y), \quad  x \in \R^2 \setminus \Gamma\]
for any smooth function $\mu$ defined on $\Gamma$.
The normal derivative of $\mathcal{D}_k\mu$ is continuous across $\Gamma$, allowing us to define the hypersingular operator $N_k = \frac{\partial}{\partial_n}\mathcal{D}_k$. This operator admits the following representation for $x\in \Gamma$
\begin{equation}
N_k \mu(x) = \lim_{\varepsilon \to 0^+} \frac{\partial}{\partial \varepsilon}\int_{\Gamma} N(y) \cdot \nabla G(x + \varepsilon N(x) - y) \mu(y) d\sigma(y).
\label{defNk}
\end{equation}
The kernel of this operator has a non-integrable singularity, but numerical calculations are made possible by the following formula, valid for smooth functions $\mu$ and $\nu$ that vanish at the extremities of $\Gamma$: 
\begin{equation}
\label{NkenfonctiondeSk}
	\begin{split}
		\duality{N_k \mu}{\nu}_{L^2(\Gamma)} = &\int_{\Gamma\times \Gamma} G_k(x-y) \partial_\tau \mu(x) \partial_\tau \nu(y)\\
		& - k^2 G_k(x-y) \mu(x) \nu(y)N(x) \cdot N(y) d\sigma(x) d\sigma(y)\,.
	\end{split}
\end{equation}
It is also known that $N_k$ maps $\tilde{H}^{1/2}(\Gamma)$ to $H^{-1/2}(\Gamma)$ continuously, and that the solution $u_2$ to the Neumann problem can be written as
\begin{equation}
u_2 = \mathcal{D}_k \mu
\end{equation}
where $\mu \in \tilde{H}^{1/2}(\Gamma)$ is the jump of $u_2$ across $\Gamma$ and is the unique solution to
\begin{equation}
N_k \mu = u_N\,.
\label{Nkmu}
\end{equation}  
\paragraph{Weighted layer potentials.} \autoref{theScatt} implies that even if $u_D$ and $u_N$ are smooth, the solutions $\lambda$ and $\mu$ to the corresponding integral equations have singularities. As a remedy, we consider weighted versions of the integral operators. Let $\omega_\Gamma$ the operator $u \mapsto \omega_\Gamma(x) u(x)$ such that $\omega_\Gamma(r(x)) \isdef \frac{\abs{\Gamma}}{2}\omega(x)$ where $\abs{\Gamma}$ is the length of $\Gamma$, $\omega(x) = \sqrt{1 - x^2}$ as in the previous section. We have
\begin{equation}
	\omega_\Gamma = \frac{\abs{\Gamma}}{2}R^{-1} \omega R\,, \quad \frac{1}{\omega_\Gamma} = \frac{2}{\abs{\Gamma}}R^{-1} \frac{1}{\omega} R\,, \quad \partial_\tau = \frac{2}{\abs{\Gamma}} R^{-1}\partial_x R\,.
	\label{param}
\end{equation}
\begin{Def}
	The weighted layer potentials $S_{k,\omega_\Gamma}$ and $N_{k,\omega_\Gamma}$ are defined by
	\[S_{k,\omega_\Gamma} \isdef S_k \frac{1}{\omega_\Gamma}, \quad N_{k,\omega_\Gamma} \isdef  N_{k}\omega_\Gamma\,.\]
\end{Def}
\noindent Solving the integral equations \eqref{Sklambda} and \eqref{Nkmu}, is equivalent to solving
\begin{eqnarray*}
	S_{k,\omega_\Gamma} \alpha &=& u_D\\
	N_{k,\omega_\Gamma} \beta &=& u_N
\end{eqnarray*}
and letting $\lambda = \frac{\alpha}{\omega_\Gamma}$, $\mu = \omega_\Gamma u_N$. Those weighted integral operators appear in many related works such as \cite{bruno2012second,jerez2012explicit,jiang2004second}. 
We also define the parametric representations $S_{k,\omega}$ and $N_{k,\omega}$ by $S_{k,\omega} \isdef R S_{k,\omega_\Gamma}R^{-1}$ and $N_{k,\omega} \isdef R N_{k,\omega_\Gamma} R^{-1}$. 
\begin{Lem}
	\label{NkomegaSkomega}
	There holds 
	\[N_{k,\omega_\Gamma} = -\partial_\tau S_{k,\omega_\Gamma} \omega_\Gamma \partial_\tau \omega_\Gamma - k^2 V_k \omega_\Gamma^2\]
	where $V_k$ is the integral operator defined by 
	\[V_k u = \int_{\Gamma} \frac{G_k(x - y) N(x) \cdot N(y) u(y)}{\omega_\Gamma(y)} d\sigma(y)\,. \]
\end{Lem}
\begin{proof}
	Eq. \eqref{NkenfonctiondeSk} can be rewritten equivalently as 
	\[N_k u = -\partial_\tau S_k \partial_\tau u - k^2 \int_{\Gamma} G_k(x - y) N(x) \cdot N(y) u(y) d\sigma(y)\,. \]
	Using the definitions of $N_{k,\omega_\Gamma}$ and $S_{k,\omega_\Gamma}$, the results follow from simple manipulations on this expression. 
\end{proof}
\begin{Lem}
	The operator $N_{k,\omega}$ satisfies, for all $\beta, \beta' \in C^\infty([-1,1])$
	\[\begin{split}
		\duality{N_{k,\omega} \beta}{\beta'}_\omega& = \duality{S_{k,\omega}(\omega \partial_x \omega)\beta}{(\omega \partial_x \omega) \beta'}_\frac{1}{\omega}\\
		&-k^2 \frac{\abs{\Gamma}^2}{4}\int_{-1}^{1} G_k(r(x) - r(y))\omega(x)\beta(x)\omega(y)\beta'(y) n(x) \cdot n(y) dx dy
	\end{split}\]
\end{Lem}
\begin{proof}
	By definition, we have
	\begin{equation*}
	\label{NkomegaenfonctiondeSkomega}
	\begin{split}
	\duality{N_{k,\omega} \beta}{\beta'}_\omega = 
	&\duality{N_{k,\omega} \beta}{\omega \beta'}_{L^2(-1,1)}\\
	=&\left(\frac{2}{\abs{\Gamma}}\right)\duality{R^{-1}N_{k,\omega} \beta}{R^{-1}\omega \beta'}_{L^2(\Gamma)}\\
	= &\left(\frac{2}{\abs{\Gamma}}\right)^2\duality{N_{k}\omega_\Gamma R^{-1} \beta}{\omega_\Gamma R^{-1}\beta'}_{L^2(\Gamma)}
	\end{split}
	\end{equation*}
	which gives, using the identity \eqref{NkenfonctiondeSk},
	\begin{equation}
		\duality{N_{k,\omega} \beta}{\beta'}_\omega =\left(\frac{2}{\abs{\Gamma}}\right)^2 \left(I_1 -k^2 I_2\right)\,,
		\label{ident_step1}
	\end{equation}
	where 
	\[I_1=\duality{S_{k}\partial_\tau\omega_\Gamma R^{-1} \beta}{\partial_\tau\omega_\Gamma R^{-1}\beta'}_{L^2(\Gamma)}\]
	and 
	\[I_2 = \int_{\Gamma \times \Gamma}G_k(x - y) \omega_\Gamma(x) \beta(r^{-1}(x))\omega_\Gamma(y)\beta'(r^{-1}(y)) n_\Gamma(x)\cdot n_\Gamma(y) dxdy\,.\]
	Using the parametrization $r$ of $\Gamma$, we can rewrite
	\begin{equation}
		I_2 = \left(\frac{\abs{\Gamma}}{2}\right)^4\int_{-1}^{1} G_k(r(x)-r(y)) \omega(x)\beta(x) \omega(y)\beta(y)n(x) \cdot n(y)dxdy
		\label{ident_step2}
	\end{equation}
	For $I_1$, we write 
	\begin{equation*}
		\begin{split}
		I_1=\frac{\abs{\Gamma}}{2}\duality{RS_{k}\partial_\tau\omega_\Gamma R^{-1} \beta}{R\partial_\tau\omega_\Gamma R^{-1}\beta'}_{L^2(-1,1)}
		\end{split}
	\end{equation*}
	And we have 
	\[\begin{split}
	RS_k \partial_\tau \omega_\Gamma R^{-1} &= RS_k\frac{1}{\omega_\Gamma} R^{-1} R \omega_\Gamma R^{-1} R\partial_\tau R^{-1} R \omega_\Gamma R^{-1}\\
	&=  \frac{\abs{\Gamma}}{2} S_{k,\omega} \omega \partial_x \omega
	\end{split}\]
	similarly, $R\partial\tau \omega_\Gamma R^{-1} = \partial_x \omega $. Thus, 
	\begin{equation}
		I_1 = \frac{\abs{\Gamma}^2}{4}\duality{S_{k,\omega}(\omega\partial_x \omega) \beta}{\omega \partial_x \omega \beta'}_\frac{1}{\omega}\,.
		\label{ident_step3}
	\end{equation}
	 We obtain the result by combining \eqref{ident_step1}, \eqref{ident_step2} and \eqref{ident_step3}. 
\end{proof}
\toDo{Réécrire ce lemme sans le côté paramétrique ? C'est fait. Probablement enlever cette version paramétrique et alléger la preuve du cas Neumann. }
\subsection{Operators $S_{0,\omega}$ and $N_{0,\omega}$ on the flat segment}

In this section, we assume that the wavenumber $k$ is equal to $0$ and the curve $\Gamma = (-1,1)\times{0}$. The parametrization $r$ is thus the constant function equal to $1$, $\partial_\tau = \partial_x$ and $\omega_\Gamma = \omega$. In this simple context, $S_{0,\omega}$ and $N_{0,\omega}$ have elementary properties that allow us to characterize $T^{s}$ and $U^s$ for $s = \pm \frac{1}{2}$. 
\paragraph{Single layer potential} The operator $S_{0,\omega}$ takes the form 
\[S_{0,\omega} \alpha(x) = \int_{-1}^{1} \frac{\ln \abs{x - y} \alpha(y)}{\sqrt{1 - y^2}}dy \,.\]
There holds 
\begin{equation}
	\label{explicitEigs}
	S_{0,\omega} T_n = \sigma_n T_n
\end{equation}
where 
\[\sigma_n = \begin{cases}
\dfrac{\ln(2)}{2} & \text{if } n=0\\
\dfrac{1}{2n} & \text{otherwise}.
\end{cases}\]
Those identities are fundamental in our analysis. A proof can be found in \cite{} \toDo{reprendre ref}. As a consequence, $S_{0,\omega}$ is in the class $\textit{Op}(S^{-1}_T)$. In particular, $S_{0,\omega}$ maps $T^{\infty}$ to itself, so the image of a smooth function by $S_{0,\omega}$ is a smooth function. We can also derive an explicit inverse of $S_{0,\omega}$ as the square root of a local operator. Recall that
\[-(\omega \partial_x)^2 T_n = n^2 T_n\]
the operator $-(\omega \partial_x)^2$ is thus in $\textit{Op}(S^{2}_T)$ and 
\begin{equation}
\label{prelude1}
	-(\omega \partial_x)^2 S_{0,\omega}^2 = \frac{I_d}{4} + T_\infty.
\end{equation}
\autoref{TheSkomega} extends this result to non-zero wavenumber and non-flat arc. 
We now proceed to show the following characterization of $T^{-1/2}$ and $T^{1/2}$. The next result, and \autoref{LemU12} stated below are equivalent to results formulated in \cite{jerez2012explicit} (see equations (4.77-4.86), and Propositions 3.1 and 3.3 therein).
\begin{Lem}
	\label{LemmaT-1/2}
	We have $T^{-1/2} = \omega\tilde{H}^{-1/2}(-1,1)$ and for all $u \in \tilde{H}^{-1/2}(-1,1)$,
	\[\norm{u}_{\tilde{H}^{-1/2}} \sim \norm{\omega u}_{T^{-1/2}}.\] 
	Moreover, $T^{1/2} = H^{1/2}(-1,1)$ and 
	\[\norm{u}_{H^{1/2}} = \norm{u}_{T^{1/2}}\]
\end{Lem}
\begin{proof}
	Since the logarithmic capacity of the segment is $\frac{1}{4}$, the (unweighted) single-layer operator $S_0$ is positive and bounded from below on $\tilde{H}^{-1/2}(-1,1)$, (see \cite{mclean2000strongly} chap. 8). Therefore the norm on $\tilde{H}^{-1/2}(-1,1)$ is equivalent to 
	\[\norm{u}_{\tilde{H}^{-1/2}} \sim \sqrt{\duality{S_0u}{u}}.\]
	On the other hand, the explicit expression \eqref{explicitEigs} imply that if $\alpha\in T^{-1/2}$
	\[ \norm{\alpha}_{T^{-1/2}} \sim \sqrt{\duality{S_{0,\omega} \alpha}{\alpha}_\frac{1}{\omega}}.\]
	It remains to notice that, since $\alpha=\omega u$, $\duality{S_{0,\omega} \alpha}{\alpha}_\frac{1}{\omega} = \duality{S_0u}{u}$. This proves the first result. For the second result, we know that, $(H^{1/2}(-1,1))' =  \tilde{H}^{-1/2}(-1,1)$ (taking the dual with respect to the usual $L^2$ duality, \cite{mclean1986spectral} chap. 3), and therefore
	\[\norm{u}_{H^{\frac{1}{2}}} = \sup_{ v\neq 0} \dfrac{\duality{u}{v}}{\norm{v}_{\tilde{H}^{-\frac{1}{2}}}}\,.\]
	According to the previous result, for all $v\in \tilde{H}^{-\frac{1}{2}}$, the function $\alpha = \omega v$ is in $T^{-1/2}$, and $\norm{ v}_{\tilde{H}^{-1/2}} \sim \norm{\alpha}_{T^{-1/2}}$, while $\duality{u}{v} = \duality{u}{\alpha}_\omega$. Thus 
	\[\norm{u}_{H^{1/2}} \sim \sup_{\alpha \neq 0} \dfrac{\duality{u}{\alpha}_\frac{1}{\omega}}{\norm{\alpha}_{T^{-1/2}}}\]
	The last quantity is the $T^{1/2}$ norm of $u$ since $T^{1/2}$ is identified to the dual of $T^{-1/2}$ for $\duality{\cdot}{\cdot}_\frac{1}{\omega}$, showing the result. 
\end{proof}


\paragraph{Hypersingular operator}For $k = 0$ and when $\Gamma = (-1,1)\times \{0\}$, the identity \eqref{NkomegaenfonctiondeSkomega} becomes
\[\duality{N_{0,\omega} \beta}{\beta'}_\omega = \duality{S_{0,\omega}  (\omega \partial_x \omega) \beta}{ (\omega \partial_x \omega) \beta'}_\frac{1}{\omega}\] 
Noticing that $(\omega \partial_x \omega) U_n = -(n+1) T_{n+1}$, we have for all $n \neq m$ 
\[\duality{N_{0,\omega }U_n}{U_m}_\omega = 0 \,.\]
Therefore, we have 
\[N_{0,\omega} U_n = \nu_n U_n\] 
with 
$\nu_n\norm{U_n}_{\omega}^2 = (n+1)^2 \sigma_{n+1} \norm{T_{n+1}}_\frac{1}{\omega}^2,$
that is, $\nu_n = \frac{(n+1)}{2}$.
Thus $N_{0,\omega}$ maps $U^s$ to $U^{s-1}$ for all $s \in \R$. In particular, $N_{0,\omega}$ maps smooth functions to smooth functions. 
Here again, we can relate $N_{0,\omega}$ to the square root of a local operator. Recall that
\[-(\partial_x \omega)^2 U_n = (n+1)^2 U_n\,,\]
thus,
\begin{equation}
\label{prelude2}
	N_{0,\omega} = \frac{1}{2}\sqrt{-(\partial_x \omega)^2}\,.
\end{equation}
As before, we obtain a characterization of $U^{s}$ for $s = \pm \frac{1}{2}$ from the previous formula:
\begin{Lem} 
\label{LemU12}	
We have $U^{1/2} =  \frac{1}{\omega} \tilde{H}^{1/2}(-1,1)$ and for all $u\in \tilde{H}^{1/2}(-1,1)$,
\[\norm{u}_{\tilde{H}^{1/2}} \sim \norm{\frac{u}{\omega}}_{U^{1/2}}\,.\]
Moreover, $U^{-1/2} = H^{1/2}(-1,1)$ and 
\[\norm{u}_{H^{1/2}} = \norm{u}_{U^{1/2}}\,.\]
\end{Lem}
\begin{proof} It suffices to remark that 
	\[ \norm{u}_{\tilde{H}^{1/2}} \sim \sqrt{\duality{N_0\omega \frac{u}{\omega}}{\omega \frac{u}{\omega}}} = \sqrt{\duality{N_{0,\omega} \frac{u}{\omega}}{\frac{u}{\omega}}_\omega} \sim \norm{\frac{u}{\omega}}_{U^{1/2}}\,.\]
	The second equality follows from the same calculations that were done in Lemma \ref{LemmaT-1/2}, as well as the norm equivalence. 
\end{proof}

\subsection{Non-flat arc and non-zero frequency}

We now turn to the general case of a non-flat arc and non-zero frequency, and prove the results announced in \cite{alouges2018new}.

\paragraph{Dirichlet problem}

\begin{Lem}
	\label{LemsymbolSk}
	The operator $S_{k,\omega_\Gamma}$ is in $\textit{Op}(S^{-1}_T(\Gamma))$, and satisfies	
	\[\mathcal{C}RS_{k,\omega_\Gamma}R^{-1} = \tilde{S}_k \mathcal{C}\]
	where the symbol of $\tilde{S}_k \in \textit{Op}(\Sigma^{-1})$ has the asymptotic expansion
	\begin{equation}
		\begin{split}
		\sigma_{\tilde{S}_k}(\theta,\xi)&=\displaystyle \frac{1}{2\xi}+\frac{k^2\abs{\Gamma}^2\sin(\theta)^2}{16\xi^3}+{\frac {3i{k}^{2}{\abs{\Gamma}}^{2}\sin \theta \cos \theta }{16{\xi}^{4}}}\\
		+ &\frac{-768 k^2 \kappa(\theta)^2 \sin^4\theta + 64k^2\abs{\Gamma}^2 \sin^2 \theta - 48k^2\abs{\Gamma}^2 \cos^2\theta + 3k^4 \abs{\Gamma}^4 \sin^4\theta}{128 \xi^5}\\
		+ & \Sigma^{-6}\,.
		\end{split}
		\label{symboleSk}
	\end{equation}
\end{Lem}
In particular, by \autoref{CorContinuitePDOTs},
\begin{Cor}
	$S_{k,\omega_\Gamma}$ is continuous from $T^s(\Gamma)$ to $T^{s+1}(\Gamma)$ for all $s\in \R$ and thus maps $\Cinf(\Gamma)$ to itself. 
\end{Cor}
\begin{proof}
	The Hankel function admits the following expansion
	\begin{equation}
	\label{decompHankel}
	H_0(z) = \frac{-1}{2\pi}\ln|z| J_0(z) + F_1(z^2)
	\end{equation}
	where $J_0$ is the Bessel function of first kind and order $0$ and where $F_1$ is analytic. We fix a smooth function $u \in T^{\infty}$. One has
	\[\left(S_{k,\omega} u\right)(x) = \int_{-1}^1 H_0\left(k\abs{r(x) - r(y)}\right)\frac{u(y)}{\omega(y)}dy\,.\]
	Using the variable changes $x = \cos\theta$, $y = \cos \theta'$, we get 
	\[ S_{k,\omega} u(\cos \theta) = \int_{0}^\pi H_0(k \abs{r(\cos \theta) - r(\cos \theta')}) u(\cos(\theta)) d\theta\,,\]
	which, in view of \eqref{decompHankel}, can be rewritten as
	\[\begin{split}
	S_{k,\omega} u(\cos \theta) = &\frac{-1}{2\pi}\int_{0}^\pi \ln \abs{\cos \theta - \cos \theta'} J_0(k \abs{r(\cos \theta) - r(\cos \theta')})\mathcal{C}u(\theta) d\theta \\
	&+ \int_{0}^\pi F_2(\cos\theta,\cos\theta') \mathcal{C}u(\theta) d\theta'
	\end{split}\]
	where 
	\[F_2(x,y) = \ln \frac{\abs{r(x)-r(y)}}{\abs{x-y}} + F_1(k^2(x - y)^2)\,\]
	is a $C^\infty$ function. 
	By parity, the second integral defines an operator 
	\[Ku(\theta) = \frac{1}{2} \int_{-\pi}^{\pi} F_2(\cos\theta,\cos\theta') \mathcal{C}u(\theta) d\theta.\]
	There holds $K = \tilde{R}_1\mathcal{C}$ where, by \autoref{thrunen}, $R_1 \in \textit{Op}(\Sigma^{-\infty})$. For the first integral, we make the following classical manipulations. We first write $\cos \theta - \cos\theta' = - 2 \sin \frac{\theta + \theta'}{2}\sin \frac{\theta - \theta'}{2}$. Thus $\ln\abs{\cos \theta - \cos\theta'}= \ln \abs{\sqrt{2} \sin \frac{\theta + \theta'}{2}} + \ln \abs{\sqrt{2}\sin \frac{\theta - \theta'}{2}}$. We then integrate and apply the change of variables $\theta \to - \theta$ for the second term, yielding
	\[S_{k,\omega}u(\cos\theta) = \left(\tilde{S}_{k,1} + \tilde{R}_1 \right)\mathcal{C}u(\theta)\]
	where
	\[\begin{split}
	\tilde{S}_{k,1}u(\theta) = &\frac{-1}{2\pi} \int_{-\pi}^\pi \ln \abs{\sqrt{2} \sin \frac{\theta - \theta'}{2}}J_0(k\abs{r(\cos\theta) - r(\cos \theta')})u(\theta')d\theta'
	\end{split}\]
	Let $g \isdef \theta \mapsto -\frac{1}{2\pi}\ln \abs{\sqrt{2} \sin \frac{\theta}{2}}$. It is well-known that $\hat{g}(n) = \frac{1}{2n}$ for $n \neq 0$. We may prolong this by $g(\xi) = \frac{1}{2\xi}$ away from $\xi = 0$. Let $a(\theta,\theta') = J_0(k\abs{r(\cos \theta ) - r(\cos \theta')})$, which is a smooth function. By \autoref{thrunen}, the operator
	\[\tilde{S}_{k,1} u(\theta) \isdef \int_{-\pi}^\pi g(\theta-\theta') a(\theta,\theta')u(\theta')d\theta'\]
	is in $\textit{Op}(\Sigma^{-1})$. In particular, $\tilde{S}_{k,1}u$ is a smooth function, thereby, $\theta \mapsto S_{k,\omega}u(\cos\theta)$ is a smooth even function. \autoref{lemChar} then ensures 
	\[S_{k,\omega}u(\cos\theta) = \mathcal{C} S_{k,\omega}u(\theta)\,.\] 
	This establishes that $\mathcal{C} S_{k,\omega}u = \tilde{S}_k \mathcal{C}u$ for any smooth function $u$. By \autoref{PDOTs}, this implies that $S_{k,\omega} \in \textit{Op}\left(S_T^{-1}\right)$. We can compute the symbol of $\tilde{S}_{k,1}$ using the asymptotic expansion \eqref{FormuleIntegralOperatorSymbol}. The terms $\partial_s^ja(t,s)_{|t=s}$, can be related to the geometric characteristics of $\Gamma$ through expansion \eqref{expansion_r}. Using a computer calculator, we find that the the rhs of \eqref{symboleSk} is an asymptotic expansion of $\tilde{S}_{k,1}$. Obviously, this expansion also holds for $\tilde{S}_k \isdef \tilde{S}_{k,1} + \tilde{R}_1$. The result is proved, recalling $S_{k,\omega_\Gamma} = R^{-1}S_{k,\omega}R$.
\end{proof}
\begin{Lem}
	\label{LemsymbolDk}
	The operator $-(\omega_\tau \partial_\tau)^2 - k^2 \omega_\Gamma^2$ is in $\textit{Op}(S_{T}^2(\Gamma))$ and satisfies 
	\[\mathcal{C}R\left[-(\omega_\tau \partial_\tau)^2 - k^2 \omega_\Gamma^2\right]R^{-1} = \tilde{D}_k\mathcal{C}\] 
	where $\tilde{D}_k \in \textit{Op}(\Sigma^2)$ has the following symbol
	\begin{equation}
		\sigma_{\tilde{D}_k}(\theta,\xi) = \abs{\xi}^2 - k^2 \abs{\Gamma}^2 \sin^2(\theta)\,.
		\label{symbolDk}
	\end{equation}
\end{Lem}
\begin{proof}
	Recalling equations \eqref{param}, one has 
	\[-(\omega_\Gamma)^2 - k^2 \omega_\Gamma^2 = R^{-1} \left[-(\omega \partial_x)^2 - k^2 \omega^2\right]R\,.\]
	Letting $D_k = -(\omega \partial_x)^2 - k^2 \omega^2$,
	\[D_k T_n = (n^2 - k^2\abs{\Gamma}^2\omega^2)T_n\,.\]
	The result is then a consequence of \autoref{PDOTs}.
\end{proof}
\begin{The}
	\label{TheSkomega}
	The operators $\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]$ and  $S_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_T(\Gamma))$ and $\textit{Op}(S^{-1}_T(\Gamma))$ and satisfy
	\[\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right] S_{k,\omega_\Gamma}^2 = \frac{I_d}{4} + T_{-4}.\]
\end{The}
\begin{proof}
	Let 
	\[J_1 =R \left(\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right] S_{k,\omega_\Gamma}^2 - \frac{I_d}{4}\right) R^{-1}\]
	Combining \autoref{LemsymbolSk} and and \autoref{LemsymbolDk}, we have $\mathcal{C} J_1 = \tilde{J}_1\mathcal{C}$ where 
	\[\tilde{J}_1 = \left(\tilde{D_k} \tilde{S}_k^2  - \frac{I_d}{4}\right)\]
	Using symbolic calculus, one can check that the symbol of $\tilde{J}_1$ is in $\Sigma^{-4}$, thus $J_1 \in \textit{Op}(S^{-4}_T)$. By definition, this means that $R^{-1}J_1 R \in \textit{Op}(S_T^{-4}(\Gamma))$, which implies the result.  
\end{proof}
\toDo{Ou bien pour utiliser le calcul symbolique directement dans les $T^s(\Gamma)$} 
\begin{proof}
	We have shown that $\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]$ and  $S_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_T(\Gamma))$ and $\textit{Op}(S^{-1}_T(\Gamma))$ in the previous two lemmas. Using the method described in \autoref{RemSymb}, we can compute an asymptotic expansion of the symbol of the pseudo-differential operator \[\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]S_{k,\omega_\Gamma}^2 - \frac{I_d}{4}\,.\] 
	The symbol of this operator is found to be in $S^{-4}_T(\Gamma)$, from which the result follows.  
\end{proof}
\begin{Rem}
	The previous theorem implies the following fact
	\[-(\omega_\Gamma \partial_\tau)^2 S_{k,\omega_\Gamma}^2 = \frac{I_d}{4} + R\]
	where $R$ is in $\textit{Op}(S^2_T(\Gamma))$. This is also a compact perturbation of the identity. Nevertheless, since $R = k^2 \omega_\Gamma^2 S_{k,\omega_\Gamma}^2 + T_{-4}$ the term $k^2 \omega^2S_{k,\omega}^2$ can be viewed as the leading first order correction accounting for the wavenumber. The inclusion of this term in the preconditioner leads to a drastic reduction of the number of GMRES iterations in numerical applications, as demonstrated in \cite{alouges2018new}. 
\end{Rem}


%Using the power series definition of $J_0$, this gives
%\begin{align}
%	\begin{split}
%	\frac{i}{4}H_0(k \abs{x - y}) &= \frac{-1}{2\pi}\ln |x-y| \label{decompHankel}\\ 
%	&\quad + \frac{1}{2\pi} \frac{k^2}{4} (x- y)^2 \ln |x-y|\\
%	&\quad + (x-y)^4 \ln|x-y|F_2(x,y) + F_3(x,y)
%	\end{split}
%\end{align}
%\noindent where $F_2$ and $F_3$ are $C^{\infty}$. Let us study the operators $O_n$ defined for $n \geq 1$ as 
%\[O_n : \alpha \mapsto -\frac{1}{2\pi}\int_{-1}^{1}(x-y)^{n-1} \ln\abs{x - y} \frac{\alpha(y)}{\omega(y)}\,.\]
%\begin{Lem}
%	\label{orderOfOn}
%	For every $n$, $O_n$ is in the class $S^n$. 
%\end{Lem}
%\begin{proof}
%	This can be shown by a simple induction. $O_1$ is just $S_\omega$, which is indeed in $S^1$. Let $n \geq 2$, and assume $O_{n-1} \in S^{n-1}$. We have
%	\[ O_n = x O_{n-1} - O_{n-1} x.\]
%	As shown in \autoref{lem:multPolyOrdre0}, the multiplication by $x$ defines an operator of $S^0$. By assumption, $O_{n-1}$ is in $S^{n-1}$, thus \autoref{CommutPDO} implies that $O_{n} \in S^n$, which concludes the proof. 
%\end{proof}
%We define a new operator $y$ defined for $n \geq 1$ by 
%\[y T_n = \frac{T_{n+1} - T_{n-1}}{2}\,.\]
%and $y T_0 = 0$. 
%It is easy to check that $y$ is in $S^0$ and $y^2 = -\omega^2 + T_\infty$. Moreover, $y$ commutes with the multiplication by $x$, and the adjoint of $y$ (in the $L^2_\frac{1}{\omega}$ duality) is $-y$. Since, for $n\geq 0$, $(x+y)T_n = T_{n+1}$ and $(x-y)T_n = T_{n-1}$, we see that any operator in $A \in S^p$ can be expressed as 
%\[ A u = \sum_{n = 0}^{+ \infty} a(x,y,n) \hat{u}_n T_n(x)\]
%where for each $n$, $(x,y) \mapsto a(x,y,n)$ is a polynomial in $x$ and $y$. \toDo{A déplacer probablement.}
%We show an intermediary result:
%\begin{Lem}
%	\label{resultInterm}
%	For all $n \geq 0$, there exists an operator $R_{n+3} \in S^{n+3}$ such that
%	\begin{equation}
%		x S_\omega^n - S_\omega^n x = 2 ny S_{\omega}^{n+1} - 2n(n+1) x S_\omega^{n+2} + R_{n+3}\,.
%	\end{equation}
%\end{Lem}
%\begin{proof}
%	We must show that
%	\[R_{n+2} \isdef x S_\omega^n - S_\omega^n x -2ny S_\omega^{k+1} + 2n(n+1)x S_\omega^{n+2} \]
%	belongs to the class $S^{n+3}$ for all $n \in \N$. For $n = 0$ this is obvious. Let us fix $n \geq 1$. We check the three requirements of \autoref{defClassSk}.
%	Using $x T_k = \frac{T_{k+1} + T_{k-1}}{2}$ and $S_\omega T_k = \sigma_k T_k$, we have
%	\[R_{n+2}T_k = a(k,-1) T_{k-1} + a(k,1) T_{k+1}\]
%	with 
%	\begin{eqnarray*}
%		a(k,1) &=& \frac{\sigma_k^n - \sigma_{k+1}^{n} - 2n \sigma_k^{n+1} + 2n(n+1)\sigma_k^{n+2}}{2}\\
%		a(k,-1) &=& \frac{\sigma_k^n - \sigma_{k-1}^{n} + 2n \sigma_k^{n+1} + 2n(n+1) \sigma_{k}^{n+2}}{2}
%	\end{eqnarray*}
%	The symbol $a$ thus satisfies the requirements (i) and (iii). It remains to show the estimate (ii). We do this for $a(k,1)$, the other case being similar. Of course, it suffices to establish the estimate for $k \geq 1$. In this case, we have $\sigma_k = \frac{1}{2k}$, thus 
%	\[a(k,1) = g(k+1) - g(k) - g'(k) - \frac{g''(k)}{2}\]
%	where 
%	\[g(x) = -\frac{1}{2\times(2x)^{n}}\,.\]
%	Applying $\Delta_k^\alpha$, on both sides and using the commutation of $\frac{d}{dx}$ and $\Delta_k$, we obtain
%	\[a(k,1) = \Delta^\alpha_k g(k+1) - \Delta_k^\alpha g(k) - (\Delta^{\alpha}_k g)'(k) - \frac{\left(\Delta_k^\alpha g\right)''(k)}{2}\,.\]
%	This can be rewritten using Taylor's formula
%	\[a(k,1) = \int_{k}^{k+1}\frac{(k+1 - \xi)^2}{2} \left(\Delta^{\alpha}_k g^{(3)}\right)(\xi) d\xi\,.\]
%	Using \autoref{lemDeltaDerivees} and the explicit derivatives of $g$, for $\xi \geq 1$, there holds
%	\[ \abs{\left(\Delta^{\alpha}_k g^{(3)}\right)(\xi)} \leq \frac{C}{(1 + \xi)^{k + 3+ \alpha }}\]
%	and thus, for $k \geq 1$, 
%	\[\abs{\Delta_k^\alpha a(k,1)} \leq \frac{C}{(1+n)^{n+\alpha+3}}\,,\]
%	as needed. 
%\end{proof}
%With the same method, we obtain:
%\begin{Lem}
%	For all $n \in \N$, 
%	\[y S_\omega^n  - S_\omega^ny = 2nxS_\omega^{n+1} - 2n(n+1)y S_\omega^{n+2} + R_n+2\,.\]
%	with $R_{n+2} \in S^{n+2}$.
%\end{Lem}
%\begin{Lem}
%	For all $n \geq 1$, the operator $O_n$ satisfies 
%	\begin{equation}
%		\label{announced}
%		O_n = 2^{n-1}(n-1)! y^{n-1} S_\omega^{n} + 2^n (n-1) n! xy^{n-1} S_\omega^{n+1} + R_{n+2}
%	\end{equation}
%	where $R_{n+2} \in S^{n+2}$. 
%\end{Lem}
%\begin{proof}
%	We show this by induction. For $n=1$, the formula is obvious, with $R_{n+2} = 0$. Assume that the formula is true for $n \geq 1$. Then by definition, 
%	\[O_{n+1} = x O_n - O_n x\]
%	and using the commutation of $x$ and $y$:
%	\[\begin{split}
%	O_{n+1} =& 2^{n-1}(n-1)! y^{n-1} \left(xS_\omega^{n} - S_\omega^{n}x \right)\\
%	& + 2^n (n-1) n! xy^{n-1}\left(xS_\omega^{n+1} - S_\omega^{n+1}x\right) \\
%	& + \left(xR_{n+2} - R_{n+2}x\right)\,. 
%	\end{split}\]
%	The operator on the last line is in $S^{n+3}$ by \autoref{CommutPDO}. By \autoref{resultInterm}, there exists an operator $R_{n+3} \in S^{n+3}$ such that 
%	\[\begin{split}
%	O_{n+1} = \quad & 2^{n-1}(n-1)! y^{n-1} \left(2ny S_\omega^{n+1} - 2n(n+1)x S_\omega^{n+2}\right)\\
%	& + 2^n (n-1) n! xy^{n-1}\left( 2(n+1)y S_\omega^{n+2} \right) \\
%	& + R_{n+3}\,. 
%	\end{split}\]
%	And we obtain the expected formula for $O_{n+1}$. 
%\end{proof}
%Using the notation introduced in \autoref{DefEquivModTp}, we have the following result:
%\begin{Lem}
%	The operator $S_{k,\omega}$ admits the following expansion 
%	\[ S_{k, \omega} = S_\omega - \frac{k^2}{4} O_3 +  T_5.\]
%	\label{developpementHankel}
%\end{Lem}
%\begin{proof}
%	From equation \eqref{decompHankel}, it suffices to show that the operator 
%	\[R_5 : \alpha \mapsto \int_{-1}^{1} (x-y)^4 \ln|x - y|F_2(x,y)\frac{\alpha(y)}{\omega(y)}\]
%	is of order $5$. Since $O_5$ is of order $5$, this is true in view of \autoref{ordreNoyauxMultipl}.
%\end{proof}
%In particular, the operator $S_{k,\omega}$ is well defined on $T^{-\infty}$, and is of order $1$. 
%\begin{Lem}
%	\label{LemSwDeltaO3}
%	There holds
%	\[S_\omega (\omega \partial_x)^2 O_3 + O_3(\omega \partial_x)^2 S_\omega = 4S_\omega\omega^2S_\omega + T_4.\]
%\end{Lem}
%\begin{proof}
%	We have $S_\omega \in S^1$, $O_3 \in S^3$ and $(\omega \partial_x)^2 \in S^{-2}$. 
%\end{proof}
%\begin{The} There holds
%	\label{TheHelmholtz}
%	\[\left[-(\omega \partial_x)^2 - k^2\omega^2\right]S_{k,\omega}^2 = \frac{I_d}{4} + T_4.\]
%	\begin{proof}
%		Using the expansion of \autoref{developpementHankel}, we can write 
%		\begin{eqnarray*}
%			-S_{k,\omega}(\omega \partial_x)^2 S_{k,\omega} &=& -S_\omega (\omega \partial_x)^2 S_\omega \\
%			&& + \frac{k^2}{4}\left(S_\omega (\omega \partial_x)^2 O_3 + O_3 (\omega \partial_x)^2 S_\omega\right) + T_4
%		\end{eqnarray*}
%		By \autoref{TheSdx2S}, the first term is $\frac{Id}{4} + T_\infty$ and by \autoref{LemSwDeltaO3} the second term is $k^2 \omega^2 + T_ 4$
%		Finally, using \autoref{developpementHankel}, on can check that
%		\[S_\omega \omega^2 S_\omega =  S_{k,\omega} \omega^2 S_{k,\omega} + T_4\]
%		We have thus proved 
%		\[-S_{k,\omega} (\omega \partial_x)^2 S_{k,\omega} = \frac{I_d}{4} + k^2S_{k,\omega} \omega^2 S_{k,\omega} + T_4.\]
%		If we substract the term $k^2 S_{k,\omega} \omega^2 S_{k,\omega}$ of each side, and use the first commutation proved in \autoref{Commutations}, we finally get 
%		\[ \left[-(\omega \partial_x)^2 - k^2 \omega^2\right]S_{k,\omega}^2  = \frac{I_d}{4} + T_4,\]
%		and the result is proved. 
%	\end{proof}
%\end{The}
%Recall that $\lambda_{n,k}^2$ are the eigenvalues of $-(\omega \partial_x) - k^2\omega^2$. Let $s_{n,k}$ the eigenvalues of $S_{k,\omega}$ on the basis of Mathieu cosines, that is
%\[S_{k,\omega}T_{n}^k = s_{n,k}T_n^k.\]
%The previous theorem has the following consequence:
%\begin{Cor}
%	One has
%	\[s_{n,k} \lambda_{n,k} = \frac{1}{4} + r_{n,k}\]
%	where $r_{n,k}$ satisfies 
%	\[\sum_{n = 0}^{+ \infty}(1 + n^2)^4 \abs{r_{n,k}}^2  < + \infty\]
%\end{Cor}
%
%The results of this section prompt us to use $\sqrt{-(\omega \partial_x)^2 - k^2\omega^2}$ as a preconditioner for $S_{k,\omega}$. 
%\toDo{Problème d'inversibilité possible pour certaines valeurs de $k$. Je n'arrive pas à l'écarter.}



\paragraph{Neumann problem}

We saw in \autoref{NkomegaSkomega} that the hypersingular operator may be broken into two parts $N_{k,\omega_\Gamma} = N_1 - k^2N_2$ where 
\[N_1 = -\partial_\tau S_{k,\omega} \omega_\Gamma \partial_\tau \omega_\Gamma\]
and $N_2 = V_k\omega_\Gamma^2$ with
\[V_ku(x) = \int_{\Gamma} \frac{G_k(x-y)N(x)\cdot N(y) u(y)}{\omega_\Gamma(y)}d\sigma(y)\,.\]
\begin{Lem}
	\label{LemsymbolN1}
	The operator $N_1$ is in $\textit{Op}(S_U^2(\Gamma))$ and  
	\[\mathcal{S}RN_1R^{-1} = \tilde{N}_1 \mathcal{S}\]
	where $\tilde{N}_1$ is a PPDO with a symbol $\sigma_{\tilde{N}_1}$ satisfying
	\begin{equation}
		\sigma_{\tilde{N}_1}(\theta,\xi) = \frac{\xi}{2} + \frac{1}{16}\frac{k^2 \abs{\Gamma}^2 \sin^2(\theta)}{\xi} + i\frac{k^2 L^2 \sin\theta\cos\theta}{16\xi^2} + \Sigma^3
		\label{symboleN1}
	\end{equation}
\end{Lem}
\begin{proof}
	Using \autoref{Lem:dthetaAdtheta} and \autoref{LemsymbolSk}, we find that $N_1$ is in $\textit{Op}(S_U^1)$ and satisfies 
	\[\mathcal{S}N_1 = \tilde{N}_1 \mathcal{S}\]
	where $\tilde{N}_1 = -\partial_\theta \tilde{S}_{k} \partial_\theta$. The announced formula can then be checked using symbolic calculus. 
	\toDo{Ou bien}
	This is a direct application of \autoref{LemdxAomegadeomega}.
\end{proof}
Adapting the proof of \autoref{LemsymbolSk}, we can show the following result:
\begin{Lem}
	\label{LemsymbolVk}
	The operator $V_k$ is in $\textit{Op}(S_T^{-1}(\Gamma))$ and 
	\[\mathcal{C}RV_kR^{-1} = \tilde{V}_k \mathcal{C}\]
	where $\tilde{V}_k$ is a PPDO with a symbol $\sigma_{\tilde{N}_2}$ satisfying
	\toDo{Mettre le bon symbole.}

\end{Lem}
%\begin{proof}
%	The symbol 
%	Let $u$ a smooth function. Using the variable change $y = \cos\theta'$, one has
%	\[\begin{split}
%	\sin\theta N_2u(\cos\theta) = \tilde{N}_2 \mathcal{S}u\,, 
%	\end{split}\]
%	where $\tilde{N}_2$ is the integral operator defined by
%	\[\tilde{N}_2u(\theta) = \int_{0}^{\pi}K(\theta,\theta')u(\theta')d\theta\]
%	with 
%	\[K(\theta, \theta') = G_k(\cos\theta - \sin\theta)\sin\theta \sin \theta' n(\cos\theta) \cdot n(\cos\theta')\,.\]
%	The same arguments as in \autoref{LemsymbolSk} show that 
%	\[\tilde{N}_2 u = \int_{-\pi}^{\pi} g(\theta - \theta') b(\theta,\theta')u(\theta')d\theta' + R_2 u\]
%	where $R_2 \in \textit{Op}(\Sigma^{-\infty})$ and 
%	\[b(\theta,\theta') = a(\theta,\theta')\sin\theta \sin \theta' n(\cos\theta) \cdot n(\cos\theta')\,.\] 
%	This implies that $\tilde{N}_2$ is a PPDO of order $-1$. In particular, $\tilde{N}_2 u$ is smooth, therefore by \autoref{lemChar}, $N_2 u$ is smooth and
%	\[\sin\theta N_2u(\cos\theta) = \mathcal{S} N_2u(\theta)\,.\]
%	We have established that $\mathcal{S}N_2u = \tilde{N}_2\mathcal{S}u$ for any smooth function $u$. By \autoref{PDOUs}, this implies that $N_2 \in \textit{Op}(S_U^{-1})$. We can compute the symbol of $\tilde{N}_2$ using the asymptotic expansion \eqref{FormuleIntegralOperatorSymbol}. Like in \autoref{LemsymbolSk}, the derivatives of $b$ can be computed in terms of the geometric characteristics of $\Gamma$ using the expansion \eqref{expansion_r} and \[n(x)\cdot n(y) = 1 - \kappa^2(x) (x-y)^2 + O\left((x-y)^3\right)\,.\] 
%	One can then compute an asymptotic expansion of the symbol of $\tilde{N}_2$ using \autoref{thrunen}, which results in expression \eqref{symboleN2}.
%\end{proof}
Applying \autoref{LemAomega2}, we deduce
\begin{Cor}
	The operator $N_2$ is in $\textit{Op}(S^{-1}_U(\Gamma))$ and satisfies
	\[\mathcal{S} RN_2R^{-1} = \tilde{N}_2 \mathcal{S}\]
	where the symbol of $\tilde{N}_2$ has the asymptotic expansion
	\begin{equation}
		\sigma_{\tilde{N}_2} = \frac{\sin^2\theta}{2\xi} + i\frac{\sin\theta \cos \theta}{2 \xi^2} + \Sigma^3\,.
		\label{symboleN2}
	\end{equation}
\end{Cor}
\noindent It is also easy to check that
\begin{Lem}
	\label{LemsymbolDkBis}
	The operator $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$ is in $\textit{Op}(S_U^2(\Gamma))$ and satisfies 
	\[\mathcal{S} R\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]R^{-1}  = \tilde{D}_k \mathcal{S}\]
	where $\tilde{D}_k$ is the operator defined in \autoref{LemsymbolDk}.
\end{Lem}
\begin{The}
	\label{TheNkomega}
	The operators $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$ and  $N_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_U(\Gamma))$ and $\textit{Op}(S^{1}_U(\Gamma))$and satisfy
	\[N_{k,\omega_\Gamma}^2 = \left[-(\partial_\tau \omega_\Gamma)^2 - k^2 \omega_\Gamma^2\right] + U_2. \]
\end{The}
\begin{proof}
	Let 
	\[J_2 = R\left( N_{k,\omega_\Gamma}^2 - \left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]\right)R^{-1}\,,\]
	The results of this section imply $\mathcal{S}J_2 = \tilde{J}_2 \mathcal{S}$
	with
	\[\tilde{J}_2 = \left( \tilde{N}_1 - \frac{k^2\abs{\Gamma}^2}{4} \tilde{N_2}\right)^2 - \tilde{D}_k\]
	Using symbolic calculus and \cref{symboleN1,symboleN2,symbolDk} one can check that the symbol of $\tilde{J}_2$ is in $\Sigma^{-2}$, thus $J_2 \in \textit{Op}(S_U^{-2})$. By definition, $R^{-1}J_2 R$ is thus in $\textit{Op}(S_U^{-2}(\Gamma))$ and the result is proved. 
	\toDo{Ou bien}
	Gathering the previous lemmas, we have asymptotic expansions available for the symbols of the operators $N_{k,\omega_\Gamma}$ and $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$. We can thus, using the method of \autoref{RemSymb}, compute an asymptotic expansion of the symbol of the operator $N_{k,\omega_\Gamma}^2 - \left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$
	which turns out to be in $S^2_U(\Gamma)$, giving the result. 
\end{proof}


\section{Galerkin analysis}

\label{subsec:GalerkineSetting}

We now turn to the analysis of the Galerkin method described in \cite{alouges2018new} and prove the orders of convergences announced therein. We introduce a discretization of the segment $[-1,1]$ as $-1 = x_0 < x_1 < \cdots < x_N = 1$, and let $\theta_i \isdef \arccos(x_i)$. We define the parameter $h$ of the discretization as 
\[ h \isdef \min_{i=0\cdots N-1} \abs{\theta_{i+1} - \theta_{i}}.\]
To keep matters simple, we focus on the case $k = 0$ and $\Gamma = [-1,1]\times \{0\}$. The result shown here are extended to the general case by means of standard abstract results in Galerkin and boundary element methods theory. 

\subsection{Dirichlet problem}

In this section, we present the method to compute a numerical approximation of the solution $\lambda$ of the integral equation 
\[S_{0} \lambda = u_D\]
To achieve it, we use a variational formulation of the equation 
\[S_{0,\omega} \alpha = u_D\]
to compute an approximation $\alpha_h$ of $\alpha$, and set $\lambda_h = \frac{\alpha_h}{\omega}$. Let $V_h$ the Galerkin space of (discontinuous) piecewise affine functions with breakpoints at $x_i$. Let $\alpha_h$ the unique solution in $V_h$ to
\[ \inner{S_{0,\omega} \alpha_h}{\alpha_h'}_\frac{1}{\omega} = -\inner{u_D}{\alpha_h'}_\frac{1}{\omega}, \quad \forall \alpha_h' \in V_h.\]
We shall prove the following result:
\begin{The}
	If the data $u_D$ is in $T^{s+1}$ for some $-1/2 \leq s \leq 2$, then there holds:
	\[ \norm{\lambda - \lambda_h}_{\tilde{H}^{-1/2}} \leq C h^{s+1/2} \norm{u_D}_{T^{s+1}}.\]
	\label{theOrdreCVDirichlet}
\end{The}
In particular, when $u_D$ is smooth, it belongs to $T^{\infty}$ so the rate of convergence is $h^{5/2}$.
\noindent We start by proving an equivalent of Céa's lemma: 
\begin{Lem}
	\label{CeaDir}
	There exists a constant $C$ such that 
	\[\norm{\alpha - \alpha_h}_{T^{-1/2}} \leq C \inf_{{\alpha}_h' \in V_h}\norm{\alpha - {\alpha}_h'}_{T^{-1/2}}\]
	\begin{proof}
		In view of the properties of $S_{0,\omega}$ stated in \autoref{LemmaT-1/2}, we have the equivalent norm 
		\[\norm{\alpha - \alpha_h}_{T^{-1/2}}^2 \leq C \inner{S_{0,\omega}(\alpha - \alpha_h)}{\alpha-\alpha_h}_\frac{1}{\omega}.\] 
		Since $\inner{S_{0,\omega} \alpha}{\alpha_h'}_\frac{1}{\omega}= \inner{S_{0,\omega} \alpha_h}{\alpha_h'}_\frac{1}{\omega}  = -\inner{u_D}{\alpha_h'}_\frac{1}{\omega} $ for all $\alpha_h' \in V_h$, we deduce 
		\[\norm{\alpha - \alpha_h}_{T^{-1/2}}^2 \leq \inner{S_{0,\omega} (\alpha - \alpha_h)}{\alpha - \alpha'_h}_\frac{1}{\omega} , \quad \forall \alpha'_h \in V_N.\]
		By duality
		\[\norm{\alpha - \alpha_h}_{T^{-1/2}}^2 \leq C \norm{S_{0,\omega}(\alpha - \alpha_h)}_{T^{1/2}}\norm{\alpha - \alpha'_h}_{T^{-1/2}}\]
		which gives the desired result after using the continuity of $S_{0,\omega}$ from $T^{-1/2}$ to $T^{1/2}$. 
	\end{proof}
\end{Lem}
From this we can derive the rate of convergence for $\alpha_h$ to the true solution $\alpha$. We use the $L^2_\frac{1}{\omega}$ orthonormal projection $\mathbbm{P}_h$ on $V_h$, which satisfies the following properties:
\begin{Lem}
	For any function $u$, 
	\[\norm{(\textup{I} - \mathbbm{P}_h)u}_{L^2_\frac{1}{\omega}} \leq C\norm{u}_{L^{2}_\frac{1}{\omega}},\]
	\[\norm{(\textup{I} - \mathbbm{P}_h)u}_{L^2_\frac{1}{\omega}}  \leq C h^2 \norm{u}_{T^2}.\]
	\label{PhT0T2}
\end{Lem}
\noindent The proof requires the following well-known result:
\begin{Lem}
	\label{LemH2NulAuBord}
	Let $\tilde{u}$ in the Sobolev space $H^2(\theta_1,\theta_2)$,such that $\tilde{u}(\theta_1) = \tilde{u}(\theta_2) = 0$. Then there exists a constant $C$ independent of $\theta_1$ and $\theta_2$ such that 
	\[ \int_{\theta_1}^{\theta_2} \tilde{u}(\theta)^2 \leq C(\theta_1-\theta_2)^4 \int_{\theta_1}^{\theta_2} \tilde{u}''(\theta)^2 d\theta\]
\end{Lem}
\begin{proof}
	The first inequality is obvious since $\mathbbm{P}_h$ is an orthonormal projection. For the second inequality, we first write, since the orthogonal projection minimizes the $L^2_\frac{1}{\omega}$ norm,
	\begin{equation}
	\norm{I - \mathbbm{P}_h u}_{L^2_\frac{1}{\omega}} \leq \norm{I - I_h u}_{L^2_\frac{1}{\omega}},
	\label{estimProjParInterp}
	\end{equation}
	where $I_h u$ is the piecewise affine (continuous) function that matches the values of $u$ at the breakpoints $x_i$. By \autoref{lemChar}, on each interval $[x_i, x_{i+1}]$, the function $\tilde{u}(\theta) \isdef u(\cos(\theta))$ is in the Sobolev space $H^2(\theta_i,\theta_{i+1})$ so we can apply \autoref{LemH2NulAuBord}:
	\[ \int_{x_i}^{x_{i+1}} \frac{(u - I_h u)^2}{\omega} = \int_{\theta_i}^{\theta_{i+1}} (\tilde{u}- \tilde{I_h}u)^2 \leq (\theta_{i+1} - \theta_i)^4 \int_{\theta_{i}}^{\theta_{i+1}} (\tilde{u} - \tilde{I_hu})''^2. \]
	This gives
	\begin{equation}
	\int_{x_i}^{x_{i+1}} \frac{(u - I_h u)^2}{\omega} \leq 2h^4 \left(\int_{\theta_i}^{\theta_{i+1}} \tilde{u}''^2 + \int_{\theta_i}^{\theta_{i+1}} \tilde{I_h}u''^2 \right).
	\label{enCoursDePreuve}
	\end{equation}
	Before continuing, we need to establish the following result
	\begin{Lem}
		There holds 
		\[ \int_{\theta_i}^{\theta_{i+1}} \widetilde{I_hu}''^2 \leq C \int_{x_i}^{x_{i+1}} \frac{u'^2}{\omega}\]
	\end{Lem}
	\begin{proof}
		The expression of $I_h u$ is given by
		\[\widetilde{I_h u}(\theta) = u(x_i) + \frac{u(x_i) - u(x_{i+1})}{\cos(\theta_{i+1}) - \cos(\theta_i)} (\cos(\theta) - \cos(\theta_i)),\]
		thus
		\[\int_{\theta_i}^{\theta_{i+1}} \widetilde{I_hu}''^2 = \left(\frac{u(x_i) - u(x_{i+1})}{\cos(\theta_{i+1}) - \cos(\theta_i)}\right)^2 \int_{\theta_i}^{\theta_{i+1}} \cos(\theta)^2 d\theta.\]
		We can rewrite 
		\[\left(u(x_{i+1}) - u(x_i)\right)^2 = \left( \int_{x_i}^{x_{i+1}} u'(t)dt\right)^2,\]
		and apply Cauchy-Schwarz's inequality and the variable change $t = \cos(\theta)$ to find 
		\[\left(\tilde{u}(\theta_{i+1}) - \tilde{u}(\theta_i)\right)^2 \leq \int_{x_i}^{x_{i+1}} \frac{u'^2}{\omega} \int_{\theta_i}^{\theta_{i+1}} \sin(\theta)^2 d\theta.\]
		To conclude, it remains to notice that the quantity
		\[\frac{ \int_{\theta_i}^{\theta_{i+1}} \cos(\theta)^2\int_{\theta_i}^{\theta_{i+1}} \sin(\theta)^2}{(\cos(\theta_{i+1}) - \cos(\theta_i))^2}\]
		is bounded uniformly in $(\theta_i, \theta_{i+1})$. Indeed, since $\cos$ is injective on $[0,\pi]$, the only problematic case is the limit when $\theta_i = \theta_{i+1}$. It is easy to check that this limit is $\cos(\theta_i)^2$, which is indeed uniformly bounded in $\theta_i$. 	
	\end{proof}
	\noindent We can now conclude the proof of \autoref{PhT0T2}. Summing all inequalities \eqref{enCoursDePreuve} for $i = 0, \cdots N+1$, we get 
	\[\norm{u - I_h u}_{L^2_\frac{1}{\omega}}^2 \leq Ch^4 \left( \norm{u}_{T^2}^2 + \norm{u'}_{T^0}^2\right).\]
	By \autoref{corDxT2T0}, the operator $\partial_x$ is continuous from $T^2$ to $T^0$ which gives 
	\[\norm{u - I_hu}_{L^2_\frac{1}{\omega}} \leq Ch^2 \norm{u}_{T^2}.\]
	The prof is concluded by plugging the estimate \eqref{estimProjParInterp} in the previous. 
\end{proof}
\noindent We obtain the following corollary by interpolation:
\begin{Cor}
	\label{interpImoinsP}
	The operator $\textup{I} - \mathbbm{P}_N$ is continuous from $L^2_\frac{1}{\omega}$ to $T^s$ for $0 \leq s \leq 2$ with
	\[\norm{(\textup{I} - \mathbbm{P}_N)u}_{L^2_\frac{1}{\omega}} \leq c h^s \norm{u}_{T^s}.\]
\end{Cor}
\noindent We can now prove \autoref{theOrdreCVDirichlet}:
\begin{proof}
	First, using \autoref{LemmaT-1/2}, one has 
	\[\norm{\lambda - \lambda_h}_{\tilde{H}^{-1/2}} \sim \norm{\alpha - \alpha_h}_{T^{-1/2}}.\]
	Moreover, if $u_D$ is in $T^{s+1}$, then $\alpha = S_{0,\omega}^{-1} u_D$ is in $T^s$ and $\norm{\alpha}_{T^s} \sim \norm{u_D}_{T^{s+1}}$. 	
	By the analog of Céa's lemma, \autoref{CeaDir}, it suffices to show that 
	\[ \norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} \leq C h^{s + 1/2} \norm{\alpha}_{T^s}.\]
	For this, we write
	\[\norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} = \inf_{\eta \in T^{1/2}, \eta \neq 0} \dfrac{(\alpha - \mathbbm{P}_h \alpha,\eta)_{\frac{1}{\omega}}}{\norm{\eta}_{T^{1/2}}}\]
	and since $\mathbbm{P}_h$ is an orthonormal projection on $L^2_\frac{1}{\omega}$, 
	\[\norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} = \inf_{\eta \in T^{1/2}, \eta \neq 0} \dfrac{(\alpha - \mathbbm{P}_N \alpha,\eta -\mathbbm{P}_h \eta )_{\frac{1}{\omega}}}{\norm{\eta}_{T^{1/2}}}.\]
	Using Cauchy-Schwarz's inequality and \autoref{interpImoinsP} ($s = \frac{1}{2}$), 
	\[\norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} \leq \dfrac{h^s \norm{\alpha}_{T^s} h^{1/2}\norm{\eta}_{T^{1/2}}}{\norm{\eta}_{T^{1/2}}} = h^{s+\frac{1}{2}} \norm{\alpha}_{T^s}.\]
\end{proof}

\subsection{Neumann problem}

We now turn to the numerical resolution of the Neumann problem
\[N_0 \mu = u_N\] 
We use a variational formulation of  
\[N_{0,\omega} \beta = u_N\]
and solve it using a Galerkin method with continuous piecewise affine functions. We introduce $W_h$ the space of continuous piecewise affine functions with breakpoints at $x_i$, and we denote by $\beta_h$ the unique solution in $W_h$ to the variational equation:
\begin{equation}
\inner{N_{0,\omega} \beta_h}{\beta_h'}_{\omega} = \inner{u_N}{\beta_h'}_{\omega}, \quad \forall \beta_h' \in W_h.
\label{NomegaBetaGalerk}
\end{equation}
Then, $\mu_h = \omega \beta_h$ is the proposed approximation for $\mu$. 
We shall prove the following:
\begin{The}
	If $u_N \in U^{s-1}$, for some $\frac{1}{2} \leq s \leq 2$, there holds 
	\[\norm{\mu - \mu_h}_{\tilde{H}^{1/2}} \leq C h^{s - \frac{1}{2}}\norm{u_N}_{U^{s-1}}.\]
	\label{theOrdreCVNeumann}
\end{The}
\noindent Like before, one can establish the following analog of Céa's lemma:
\begin{Lem}
	There exists a constant $C$ such that
	\[\norm{\beta - \beta_h}_{U^{1/2}} \leq C \inf_{\beta'_h \in W_h} \norm{\beta - \beta'_h}_{U^{1/2}}\,.\] 
	\label{CeaNeumann}
\end{Lem}
\noindent Let us show the following continuity properties of the interpolation operator $I_h$: 
\begin{Lem} 
	\label{U0U2,U1U2}
	There holds 
	\[ \norm{ u - I_h u}_{L^2_\omega} \leq Ch^2\norm{u}_{U^2}\]
	and
	\[\norm{u-I_h u}_{U^1} \leq Ch \norm{u}_{U^2}\]	
\end{Lem}
\begin{proof}
	We only show the first estimation, the method of proof for the second being similar. Using again \autoref{LemH2NulAuBord} on each segment $[x_i, x_{i+1}]$, one can write
	\begin{eqnarray*}
		\int_{x_i}^{x_{i+1}} \omega (u - I_h u)^2 &\leq& C  (\theta_{i+1} - \theta_i)^4 \int_{\theta_i}^{\theta_{i+1}} (Vu- VI_h u)''^2 \\
		&\leq& C h^4 \left(2\int_{\theta_i}^{\theta_{i+1}} Vu''^2 + 2\int_{\theta_i}^{\theta_{i+1}}(VI_hu)''^2\right)
	\end{eqnarray*}
	where we recall that for any function $u$, $\mathcal{S}u$ is defined as 
	\[\mathcal{S}u(\theta) = \sin(\theta)u(\cos(\theta)).\] 
	Before continuing, we need to establish the following estimate:
\begin{Lem}
	\[\int_{\theta_i}^{\theta_{i+1}} \abs{(\mathcal{S} (I_hu))''}^2 \leq  C \left(\norm{u}^2_{U_2} \int_{\theta_i}^{\theta_{i+1}} \sin^2\theta d\theta +  \int_{x_i}^{x_{i+1}} \omega (\partial_x u)^2\right)\]
	\label{LemIntermediaire}
\end{Lem}
\begin{proof}
	Using the expression of $I_h$, one can write
	\begin{multline}
	\int_{\theta_i}^{\theta_{i+1}} (\mathcal{S} I_hu)''^2\leq C\left(\abs{ u(x_i)}^2 \int_{\theta_i}^{\theta_{i+1}} \sin^2\theta d\theta \right.\\
	\left.+ \left(\frac{u(x_{i+1}) -  u(x_{i})}{\cos\theta_{i+1} - \cos\theta_i}\right)^2 \int_{\theta_i}^{\theta_{i+1}} \sin^2\theta(1 + \cos^2\theta)d\theta\right)
	\label{CalculIntermediaire}
	\end{multline}
	We can estimate the first term, thanks to \autoref{LemInjectionsContinues}:
	\[\abs{ u(x_i)} \leq C \norm{u}_{U^2},\]
	while for the second term, the numerator of is estimated as follows: 
	\begin{eqnarray*}
		\left(u(x_{i+1}) - u(x_i)\right)^2 &=& \left(  \int_{x_i}^{x_{i+1}} \partial_x  u\right)^2 \\
		& \leq & \int_{x_i}^{x_{i+1}} \omega (\partial_x u)^2 \int_{x_i}^{x_{i+1}} \frac{1}{\omega} \\
		&  = & \abs{\theta_{i+1} - \theta_i}\int_{x_i}^{x_{i+1}} \omega (\partial_x u)^2.
	\end{eqnarray*}
	to conclude, it remains to observe that the quantity 
	\[\frac{\abs{(\theta_{i+1} - \theta_i)} \int_{\theta_i}^{\theta_{i+1}}{\sin^2\theta(1 + \cos^2\theta)d\theta}}{(\cos(\theta_{i}) - \cos(\theta_{i+1}))^2}\]
	is bounded by a constant independent of $\theta_i$ and $\theta_{i+1}$. Indeed, in the limit $\theta_{i+1} \to \theta_{i}$, the fraction has the value $1 + \cos^2(\theta_i)$. 
\end{proof}
	\noindent We now plug the estimate \autoref{LemIntermediaire} in \eqref{CalculIntermediaire}, and sum over $i$:
	\[\norm{u - I_hu}^2_{L^2_\omega} \leq C h^4(\norm{u}_{U^2}^2 + \norm{u'}_{L^2_\omega}^2).\]
	This implies the claim once we use the continuity of $\partial_x$ from $U^2$ to $U^0$, cf. \autoref{corDxT2T0}.
\end{proof}
\noindent We can now prove \autoref{theOrdreCVNeumann}
\begin{proof}
	Let us denote by $\Pi_h$ the Galerkin projection operator defined by $\beta \mapsto \beta_h$. Since it is an orthogonal projection on $W_h$ with respect to the scalar product $(\beta,\beta') \isdef \inner{N_{0,\omega} \beta}{\beta'}_\omega$, it is continuous from $U^{1/2}$ to itself, so we have for any $u$ in $U^{1/2}$. 
	\[\norm{(I - \Pi_h)u}_{U^{1/2}} \leq C \norm{u}_{U^{1/2}}.\]
	We are now going to show the estimate
	\[\norm{(I - \Pi_h)u}_{U^{1/2}} \leq C h^{3/2} \norm{u}_{U^{2}}.\]
	By the analog of Céa's lemma \autoref{CeaNeumann}, one has 
	\[\norm{(I-\Pi_h)u}_{U^{1/2}} \leq \norm{(I - I_h) u}_{U^{1/2}}\,.\] 
	By interpolation, this norm satisfies
	\[\norm{(I - I_h)u}_{U^{1/2}} \leq C \sqrt{\norm{(I - I_h)u}_{U^{0}}}\sqrt{\norm{(I - I_h)u}_{U^{1}}},\]
	which yields, applying \autoref{U0U2,U1U2},
	\[\norm{(I - I_h)u}_{U^{1/2}} \leq C h^{3/2} \norm{u}_{U^2}.\]
	By interpolation, for all $s \in [1/2,2]$, we get
	\[\norm{(I - \Pi_h)u}_{U^{1/2}} \leq C h^{s - 1/2} \norm{u}_{U^s}.\]
	In view of \autoref{LemU12}, we have $\norm{\mu - \mu_h}_{\tilde{H}^{1/2}} \sim \norm{(I - \Pi_h)\beta}_{U^{1/2}}$. In addition, since $N_{0,\omega}$ is a continuous bijection from $U^{s+1}$ to $U^s$ for all $s$, there holds
	\[\norm{\beta}_{U^s} = \norm{N_{0,\omega}^{-1} u_N}_{U^s} = \norm{u_N}_{U^{s-1}}.\]
	Consequently, 
	\[\norm{\mu - \mu_h}_{\tilde{H}^{1/2}} \leq  C\norm{(I - \Pi_h)\beta}_{U^{1/2}} \leq C h^{s - 1/2} \norm{\beta}_{U^s} \leq C h^{s - 1/2} \norm{u_N}_{U^{s-1}}\,,\]
	as announced. 
\end{proof}


\section{Conclusion}

%\section{Proof of \autoref{the:ParametrixNkomega}}
%\label{ParametrixNkomega}
%From equation \eqref{NkenfonctiondeSk}, we can deduce the following formula for the weighted operator:
%\begin{equation}
%\label{developNkomega}
%N_{k,\omega} = - \partial_x S_{k,\omega} \omega \partial_x \omega - k^2 S_{k,\omega} \omega^2
%\end{equation}
%If we define $L_n \isdef - \partial_x O_{n+2} \omega \partial_x \omega$, then using the mapping properties of $\partial_x$ and $\omega\partial_x\omega$ given by \autoref{derivations}, and since, by \autoref{orderOfOn}, $O_{n+2}$ is of order $n+2$ in the scale $T^s$, we deduce that $L_n$ is of order $n$ in the scale $U^s$. 
%The expansion obtained for the weighted single-layer operator in \autoref{developpementHankel} yields the following expansion for $N_{k,\omega}$. 
%\begin{Lem}
%	\[N_{k,\omega} = N_\omega + k^2 \left( -\frac{L_1}{4}- S_\omega \omega^2 \right) + U_3\]
%\end{Lem}
%\noindent As a consequence, $N_{k,\omega}$ is an operator of order $-1$ in the scale $U^s$. 
%Using equation \eqref{developNkomega}, we have the following expression:
%\[N_{k,\omega}^2 = N_\omega^2 - k^2\left( \frac{L_1 N_\omega + N_\omega L_1}{4} + N_\omega S_\omega \omega^2 + S_\omega \omega^2 N_\omega\right) + U_2.\]
%We have proved in
%By definition, $L_1 = -\partial_x O_3 \omega \partial_x \omega$, while $N_\omega = - \partial_x S_\omega \omega \partial_x \omega$, thus
%\[L_1 N_\omega = \partial_x (O_3 (\omega \partial_x)^2 S_\omega ) \omega \partial_x \omega.\]
%Moreover, 
%\[N_\omega L_1 =  \partial_x (S_\omega (\omega \partial_x)^2 O_3  ) \omega \partial_x \omega.\]
%Adding these two inequalities and using \autoref{LemSwDeltaO3}, we get 
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} =\partial_x ( S_\omega \omega^2 S_\omega ) \omega \partial_x \omega + U_2.\]
%Here again, we use the formula $\partial_x S_\omega \omega^2 = S_\omega \omega \partial_x \omega$, which yields
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} = S_\omega \omega \partial_x \omega \partial_x S_\omega \omega^2 = \left(-\frac{I_d}{4} + T_\infty\right)\omega^2 .\]
%Since $\omega^2$ is continuous from $U^s$ to $T^s$ by \autoref{omega2continuUsTs} and using the injections $T^s\subset U^s$, any operator of the form $R \omega^2$ is smoothing in the scale $U^s$ as soon as $R$ is smoothing in the scale $T^s$. Therefore, 
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} = -\frac{\omega^2}{4} + U_\infty.\]
%Moreover, we have
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega &=& -S_\omega \omega^2 \partial_x S_\omega \omega \partial_x \omega\\
%	&=& -S_\omega \omega^2 \partial_x^2 S_\omega \omega^2
%\end{eqnarray*}
%using again \autoref{dxSomega2=Somegadxomega}. Since $\omega^2 \partial_x ^2 = (\omega \partial_x)^2 + x \partial_x$, we get
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega &=& \frac{\omega^2}{4} - S_\omega x \partial_x S_\omega \omega^2 + U_\infty
%\end{eqnarray*}
%Futhermore, 
%\begin{eqnarray*}
%	N_\omega S_\omega \omega^2 &=& -\partial_x S_\omega \omega \partial_x \omega S_\omega \omega^2.
%\end{eqnarray*}
%We use $\omega \partial_x \omega = \omega^2 \partial_x - x$:
%\begin{eqnarray*}
%	N_\omega S_\omega \omega^2 &=& -\partial_x S_\omega \omega^2 \partial_x S_\omega \omega^2 + \partial_x S_\omega x S_\omega \omega^2\\
%	&=& \frac{\omega^2}{4} + \partial_x S_\omega x S_\omega \omega^2 
%\end{eqnarray*}
%Thus, 
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega + N_\omega S_\omega \omega^2 &=& \frac{\omega^2}{2} + \left(\partial_x S_\omega xS_\omega \omega^2  - S_\omega x \partial_x  S_\omega \omega^2 \right)+ U_\infty.
%\end{eqnarray*}
%We are done if we prove that the operator in parenthesis is of order $2$ in the scale $U^s$. For this, we may compute the action of each one of them on $U_n$. Using the various identities at our disposal, we obtain on the one hand for $n\geq 2$ 
%\[\partial_x S_\omega x S_\omega \omega^2 U_n = -\frac{T_{n+2}}{8(n+2)} -\frac{T_n}{8(n+2)} +  \frac{U_{n} + U_{n-2}}{8n(n+2)}. \]
%and on the other hand for $n>0$ 
%\[S_\omega x \partial_x S_\omega \omega^2 U_n = -\frac{T_{n+2}}{8(n+2)} - \frac{T_n}{8n}.\]
%After substracting, this gives the rather surprising identity identity for $n \geq 2$
%\[\left(\partial_x S_\omega xS_\omega \omega^2  - S_\omega x \partial_x  S_\omega \omega^2 \right)U_n = \frac{U_n}{4n(n+2)}\]
%which of course proves our claim.
%
%\section{Suggestion de découpage}
%
%J'y ai un tout petit peu réfléchi : 
%\begin{itemize}
%	\item[-] Les analyses pseudo-diffs des espaces $T^s$, bien qu'intéressantes, sont trop longues et ne se justifient pas vraiment dans le simple but de faire une méthode numérique. 
%	\item[-] La méthode de Galerkine est bien analysée et nouvelle (à ma connaissance) mais n'est pas vraiment essentielle pour le message. 
%\end{itemize}
%Je pense qu'on pourrait envisager 3 articles. 
%Un très concis sur la méthode numérique en elle-même. Utiliser le minimum d'info pour k=0, donner les inverses exacts, prouver la commutation des opérateurs pour k non nul, puis balancer les préconditionneurs, et mettre les figures. 
%
%Un article un peu à part sur la méthode de Galerkine, et tous les aspects numériques (bcp moins d'impact)
%
%Un article (peut-être juste sur arxiv ?) sur les espaces $T^s$ et $U^s$, qui donne toutes les justifications théoriques. (une sorte de version étendue de cet article.)


%	\section{Order of the operators $O_n$}
%	\label{orderOn}
%	
%	\begin{Lem}
%		\label{lemPseudoDiffOn}
%		For all $n \geq 1$, there exists a function $o_n : \N^2 \to \R$ satisfying the following conditions 
%		\begin{itemize} \item[(i)]\itemequation[sumDefiningOn]{}{$	\forall k \in \Z, \quad O_n T_k = \displaystyle\sum_{i = -\infty}^{+\infty} o_n(k,i)T_{k-i}$}{}
%			\item[(ii)] \itemequation[conditionon]{}{$	\forall \alpha, \in \N, \forall  i,k  \in \Z, \quad  \abs{\Delta_k^\alpha o_n(k,i)} \leq C_{n,\alpha,\beta} (1 + k^2)^{-n - \alpha}$}{} 
%			\item[(iii)]\itemequation[conditionon]{}{$\forall i,k \in \Z, \quad \abs{i} \geq  n \implies o_n(k,i) = 0$}{}
%		\end{itemize}
%		where $\Delta_i$ and $\Delta_k$ represent the discrete derivation operator in the variables $i$ and $k$ respectively, e.g. 
%		\[ \Delta_i o_n(k,i) = o_n(k,i+1) - o_n(k,i),\]
%		and $\Delta_i^\alpha$ denotes the $\alpha$-th iterate of $\Delta_i$. We use the convention $T_k \isdef T_{\abs{k}}$ for $k \in \Z$. 
%	\end{Lem}
%	\begin{proof}
%		We shall prove this by induction. First for $n = 1$, $O_1 = 2\pi S_\omega$, and we simply have $o_1(k,i) = \delta_{i = 0} s_k$ where $s_k$ are the eigenvalues of $S_\omega$ defined in \autoref{STn}. Obviously, $o_1$ satisfies all the requirements. Second, notice that for $n \geq 1$, 
%		\[O_{n+1} = x O_n - O_n x,\]
%		which combined with the identity 
%		\[x T_n = \dfrac{T_{n-1} + T_{n+1}}{2}\]
%		valid for all $n \in \Z$, implies
%		\[O_{n+1}T_k = \sum_{i= -\infty}^{+\infty} o_n(k,i) \dfrac{T_{k - i + 1} + T_{k _-i- 1}}{2} - \frac{1}{2} O_n T_{k+1} - \frac{1}{2} O_n T_{k - 1}.\]
%		By the recurrence assumption (i), this implies 
%		\begin{eqnarray*}
%			O_{n+1}T_k &=& \frac{1}{2} \sum_{-\infty}^{+ \infty}\left(o_n(k,i-1) - o_n(k+1,i - 1)\right) T_{k - i} \\
%			&&+ \frac{1}{2} \sum_{-\infty}^{+ \infty}\left(o_n(k,i+1) - o_n(k-1,i + 1)\right) T_{k - i}.
%		\end{eqnarray*}
%		Thus, condition (i) is satisfied with 
%		\[o_{n+1}(k,i) \isdef \frac{\left(o_n(k,i-1) - o_n(k+1,i-1) + o_n(k,i+1) - o_n(k-1,i+1)\right)}{2}.\]
%		If $\abs{i} \geq n+1$ then by triangular inequality $\abs{i-1} \geq n$ and $\abs{i+1} \geq n$ so all terms in the rhs are null by the assumption (iii), which shows that (iii) also holds for $o_{n+1}$. Finally, the assumption (ii) is easily checked for $o_{n+1}$ once we write 
%		\[ o_{n+1}(k,i) = \frac{- \Delta_ko_n(k,i-1) + \Delta_ko_n(k-1,i+1)}{2}.\]
%	\end{proof}
%	
%	
%	\begin{Lem}
%		\label{orderOfOn}
%		The operator $O_n$ is of order $n$. 
%	\end{Lem}
%	\begin{proof}
%		Since the sum in \eqref{sumDefiningOn} is finite, by linearity, it is sufficient to show that the operator $O^i_n$ defined by 
%		\[ \forall k \in \Z, \quad  O^i_n T_k = o_n(k,i) T_{k-i} \]
%		is of order $n$. We treat the case $i > 0$, the opposite case being analogous. Let $u \in T^s$ for some $s$, there holds 
%		\[ O^i_n u = \sum_{k = 0}^{+ \infty} o_n(k + i,i)\hat{u}_{k + i}T_k + \sum_{k = 0}^{i} o_n(i - k,i) \hat{u}_{i - k}T_k.\]
%		We let $Vu$ and $Ru$ respectively the two terms of the rhs. Obviously, $R$ is a smoothing operator with
%		\[ \norm{Ru}_{T^{s + n}} \leq (1 + i)^{n} \norm{u}_{T^s}.\]
%		Now, for all $k \in \N$ let
%		\[\hat{v}_k \isdef o_n(i + k,i) \hat{u}_{i + k}.\]
%		Applying Peetre's inequality, one has
%		\[(1 + k^2)^{n + s}\abs{\hat{v}_k}^2 \leq C \left(1 + i^2\right)^{\abs{n + s}}\left(1 + (i + k)^2\right)^{n + s} \abs{o_n(k + i,i)}^2 \abs{\hat{u}_{k+i}}^2.\]
%		the condition (ii) in \autoref{lemPseudoDiffOn} with $\alpha = \beta = 0$ yields
%		\[\abs{o_n(k+i,i)}^2 \leq C\left(1 + (k+i)\right)^{-2n} \leq 2C \left(1 + (k+i)^2\right)^{-n}.\]
%		Therefore, $\norm{V u}_{T^{s + n}} \leq C(1 + i)^{\abs{n + s}} \norm{u}_{T^s}$ which concludes the proof. 
%	\end{proof}

	
	
	
	
	
	
	
	
	
	\bibliographystyle{plain}
	\IfFileExists{../../Biblio/biblio.bib}{\bibliography{../../Biblio/biblio}}{\bibliography{/home/martin/Thesis/Biblio/biblio}}
	
	
\end{document}


%
%\section{Laplace equation on a flat segment}
%
%In this section, we restrict our attention to the case where $\Gamma$ is the open segment $(-1,1) \times \{0\}$, and $k=0$. We study the properties of the equations 
%\[S\lambda = -u_D\]
%and 
%\[N\mu = u_N\]
%and show their invertibility in a range of Sobolev-like spaces. This problem has been considered thoroughly, both
%in terms of analytical and numerical properties in the literature (see for instance \cite{jiang2004second,bruno2012second}), and it turns out that the Chebyshev polynomials of first and second kind play a very important role. However, we go further compared to the literature by 
%by constructing a functional framework close to Sobolev spaces, based on Chebyshev polynomials that
%allows us to give a complete framework for the existence and uniqueness of the solutions to the preceding equations, as well as
%new preconditioners.
%
%
%
%\subsection{Single layer equation}
%
%In this section we focus on the equation $S\lambda = g$, that is we seek $\lambda \in \tilde{H}^{-1/2}$ such that 
%\begin{equation}
%-\frac{1}{2\pi}\int_{-1}^{1} \log|x-y| \lambda(y) = -g(x), \quad \forall x\in (-1,1)\,.\label{Slambda}
%\end{equation} 
%
%This equation is sometimes called ``Symm's integral equation'' and its resolution has received a lot of attention in the 1990's. Numerical methods, using both collocation and Galerkin have been presented and analyzed \cite{atkinson1991numerical,yan1988integral,yan1990cosine,sloan1992collocation,yan1989mesh}. 
%
%%The solution is connected to the exterior Dirichlet problem for the Laplace operator, but attention must be paid when the solution $\lambda$ obtained does not satisfy $\duality{1}{\lambda}_\Gamma = 0$: in this case, $\textup{SL}\lambda$ is not a bounded solution of the Dirichlet problem. See \cite{atkinson1991numerical} for a link with the logarithmic capacity of the line and how we recover the bounded solution from the solution of \eqref{Slambda}.
%
%
%%
%%\paragraph{Autre idée de présentation.}
%%We first start with a commutation result
%%
%%\toDo{Commencer par le truc connu. Et en fait c'est normal. Balancer ensuite la commutation. Dire que ça n'a pas été remarqué. }
%%
%%\begin{Prop}
%%	Commutation de $S_\omega$ et $(\omega \partial_x)^2$. 
%%\end{Prop}
%%Exploitation en terme de vp. Dire qu'on a deux opérateurs avec spectre discret. (L'un est compact dans $L^2_\frac{1}{\omega}$, (sans preuve pour l'instant).
%%
%\begin{Lem}
%	\[ -\frac{1}{2\pi}\int_{-1}^{1} \frac{\ln|x-y|}{\sqrt{1 - y^2}}T_n(y)dy = s_n T_n(x)\]
%	where
%	
%	\label{STn}
%\end{Lem}
%
%Using the decomposition of $g$ and of the logarithmic kernel on the basis $T_n$, we see that the solution $\lambda$ to equation \eqref{Slambda} admits the following expansion 
%\begin{equation}
%\lambda(x) = \frac{1}{\sqrt{1-x^2}}\sum_{n=0}^{+ \infty} \frac{\hat{g}_n}{s_n} T_n(x).
%\label{expansionLambda}
%\end{equation}
%We deduce the following well-known fact:
%\begin{Cor}
%	\label{CorSingularity}
%	If the data $g$ is in $C^{\infty}([-1,1])$, the solution $\lambda$ to the equation 
%	\[S\lambda = g\]
%	is of the form 
%	\[\lambda = \dfrac{\alpha}{\sqrt{1-x^2}}\]
%	with $\alpha \in C^{\infty}([-1,1])$.  
%	\begin{proof}
%		Let $\alpha = \sqrt{1 - x^2}\lambda$ where $\lambda$ is the solution of $S\lambda = g$ where $g$ is assumed to lie in $C^{\infty}([-1,1])$. 
%		\autoref{LemTinfCinf} implies that $g \in T^{\infty}$, and by equation \eqref{expansionLambda}, 
%		\[ \hat{\alpha}_n = \frac{\hat{g}_n}{s_n},\]
%		so $\alpha$ also  belongs to $T^{\infty} = C^{\infty}([-1,1])$. 
%	\end{proof}
%\end{Cor}
%
%
%We follow \cite{bruno2012second} by noticing that the behavior in $\frac{1}{\sqrt{1-x^2}}$ is consistent with the expected singularity near the edges and introduce the weighted single layer operator as the operator that appeared in Proposition \ref{STn}.
%\begin{Def}(See \cite{bruno2012second}) 
%	Let $S_\omega$ be the weighted single layer operator defined by
%	\[\opFromTo{S_\omega}{\alpha \in \Cinf([-1,1])}{-\dfrac{1}{2\pi}}{\int_{-1}^1\dfrac{\ln|x-y|}{\omega(y)} \alpha(y)dy}\]
%\end{Def}
%\noindent We also recall that the operator $(\omega\partial_x)^2$ is defined by \[\opFromTo{(\omega\partial_x)^2}{\alpha \in \Cinf([-1,1])}{(1-x^2)\alpha''(x) - x \alpha'(x)}.\]
%
%The action of these operators on $T^{\infty}$ is easy to analyze using \eqref{cheb1} and \autoref{STn}. By density of $T^{\infty}$ in $T^s$ for all $s$, we get:
%\begin{Prop}
%	The operator $S_\omega$ is a self-adjoint, positive definite operator, and defines a continuous bijection from $T^{s}$ to $T^{s+1}$ for all real $s$. In particular, $S_\omega$ is of order $1$ and is compact in $T^s$. 
%	Similarly, for any $s \in \R$, the operator $-(\omega \partial_x)^2$ is positive, self-adjoint, and of order $-2$. 
%\end{Prop}
%\begin{proof}
%	It suffices to remark that if $u=\sum_{n=0}^\infty \hat{u}_n T_n \in T^s$, then
%	\[S_\omega u = \frac{\ln(2)}{2} \hat{u}_0 T_0 +  \sum_{n=1}^\infty \frac{\hat{u}_n}{2n} T_n\]
%	while
%	\[-(\omega \partial_x)^2 u = \sum_{n=0}^\infty n^2\hat{u}_n T_n \,.\]
%\end{proof}
%\begin{Rem}
%	Of course, $S_\omega$ is in the class $S^1$ defined in \autoref{subsec:classesOfOp}
%\end{Rem}
%\noindent To obtain the solution of \eqref{Slambda}, we can thus solve 
%\begin{equation}
%S_\omega \alpha = -u_D,
%\label{Somegaalpha}
%\end{equation}
%and let $\lambda = \frac{\alpha}{\omega}$.  
%The next lemmas make clear the connection between the spaces $T^s$ with $s = \pm \frac{1}{2}$ and the usual Sobolev spaces. Equivalent results are proved in \cite{jerez2010boundary}. 
%
%
%\begin{Lem} Similarly,
%	\[H^{1/2}(-1,1) = T^{1/2}\]
%	and for $u \in H^{1/2}(-1,1)$ we have
%	\[\norm{u}_{H^{1/2}} \sim \norm{u}_{T^{1/2}}\,.\]
%	\label{LemmaT1/2}
%\end{Lem}	
%\begin{proof}
%	 
%\end{proof}
%
%We are now in a position to find an expression for the inverse of $S_\omega$. An explicit inverse has already appeared in the literature. In 
%particular, in \cite{jerez2012explicit,urzua2014optimal}, explicit variational forms for this inverse operator are derived rigorously. (A similar method is also employed in the recent paper \cite{hiptmair2017closed} in $\R^3$ for the case of the unit disk.) We just state here the following formal decomposition:
%\[\dfrac{d^2}{dxdy}\log\frac{M(x,y)}{|x-y|^2} = \frac{-1+xy}{2|x-y|^2} = \sum_{n=1}^{+ \infty} n T_n(x)T_n(y)\]
%with 
%$M(x,y) = \frac{1}{2}\left((y-x)^2 + (\omega(x) + \omega(y))^2\right) $.
%
%However, using the preceding analysis, we have an alternative way of defining this exact inverse, which leads to an expression in the form of the square root of a local operator. To state the next result, we define the operator $\pi_{0}$ as the $L^2_{1/\omega}$ 
%orthogonal projector on $T_0$. Namely 
%\[\pi_0 \alpha(x)  = \frac{1}{\pi} \int_{-1}^{1}\frac{\alpha(y)}{\omega(y)}dy\,.\]
%The preceding definition can be extended to $u \in T^s$ for any $s \in \R$ by setting $\pi_0 u$ as the solution of
%\[\left\{
%\begin{array}{l}\duality{\alpha-\pi_0 \alpha}{T_0}_{\frac{1}{\omega}} = 0\,,\\
%\pi_0\alpha\in \mbox{Span}(T_0)\,,
%\end{array}
%\right.\]
%since $T_0\in T^\infty$. Of course, $\pi_0$ is continuous from $T^s$ to $T^{\infty}$ for any $s$. 
%
%\begin{The}
%	\label{TheSdx2S}
%	There holds
%	\begin{equation}
%		\label{Sdx2S}
%		S_{\omega}^2 = \frac{1}{4}\left(-(\omega\partial_x)^2 + \frac{1}{\ln(2)^2} \pi_0 \right)^{-1}\,.
%	\end{equation}
%\end{The}
%\begin{proof}
%	The Chebyshev polynomials $(T_n)$ are a common Hilbert basis of eigenvectors for the three operators $S_\omega$, $-(\omega \partial_x)^2$ and $\pi_0$, so it is sufficient to compute $4 S_\omega^2 \left(-(\omega\partial_x)^2 + \frac{1}{\ln(2)^2} \pi_0 \right) T_n$ and check that this is indeed equal to $T_n$. 
%	One has using the explicit eigenvalues for $S_\omega$. This is easily verified using the following expressions
%	\[ S_\omega T_n =\frac{1}{2n}T_n\,,\,\, \pi_0 T_n = 0 \mbox{ and } -(\omega\partial_x)^2T_n = n^2 T_n \mbox{ if } n\ne 0\,,\]
%	while
%	\[ S_\omega T_0 = \frac{\ln(2)}{2} T_0\,,\,\, \pi_0 T_0 = T_0 \mbox{ and } -(\omega\partial_x)^2T_0 = 0 \mbox{ otherwise.}\]
%\end{proof}
%
%From the preceding formula, we can extract the explicit inverse of $S_\omega$ in terms of the square root of the inner operator. 
%
%\begin{Cor}
%	The inverse of $S_\omega$ can be equivalently expressed as 
%	\begin{equation}
%	S_{\omega}^{-1} = 2\sqrt{-(\omega \partial_x)^2 + \frac{1}{\ln(2)^2}\pi_0}\,.
%	\end{equation}
%\end{Cor}
%
%
%	
%\begin{table}[H]
%	\begin{center}
%		\begin{tabular}{|| m{4em} | m{4em} | m{4em} | m{4em} | m{4em}||} 
%			\hline
%			\multicolumn{1}{||c|}{ }&
%			\multicolumn{2}{c|}{with Prec.}&\multicolumn{2}{c||}{without Prec.}\\
%			\hline
%			$N$ & $n_{it}$& t(s) & $n_{it}$ & t(s)\\
%			\hline\hline
%			50 & 7 & 0.11 & 35 & 0.21\\
%			\hline
%			200 & 7 & 0.14 & 53 & 0.55\\
%			\hline
%			800 & 7 & 0.29 & 76 & 2.0 \\
%			\hline
%			3200 & 7 & 0.95 & 107 & 9.5\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\caption{Number of iteration and time needed for the numerical resolution of \eqref{Somegaalpha} using Galerkin finite elements with and without preconditioner.}
%	\label{TableNitTimeLaplaceDirichlet}
%\end{table}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=0.7]{../figs/PrecondDirichletLaplaceSeg.png}
%	\caption{Number of iteration in the resolution of the single layer integral equation with a mesh of size $N = 1600$.}
%	\label{FigureNitLaplaceDirichlet}
%\end{figure}
%
%\subsection{Hypersingular equation} 
%
%We now turn our attention to the equation 
%
%\begin{equation}
%N\mu = g
%\label{Nmu}
%\end{equation} 
%
%Similarly to the previous section and following again the idea of \cite{bruno2012second}, we consider a rescaled version of the hypersingular operator $N_\omega \isdef N \omega$ defined by
%
%\[N_\omega \mu = \lim_{\varepsilon\to 0}\int_{-1}^{1} n(y)\cdot\nabla G(x + \varepsilon n(x) - y) \sqrt{1-y^2} dy\]
%We can get the solution to equation \eqref{Nmu} by solving 
%\begin{equation}
%N_\omega \beta = u_N,
%\label{Nomegabeta}
%\end{equation}
%and letting $\mu = \omega \beta$. 
%We now show that $N_\omega$ can also be analyzed in our functional framework, using this time the spaces $U^s$. 
%\begin{Lem}
%	\label{lemIPP}
%	For any $\beta$, $\beta'$, one has 
%	\[\duality{N_\omega \beta}{ \beta'}_\omega = \duality{S_\omega \omega \partial_x \omega \beta}{\omega \partial_x \omega \beta'}_\frac{1}{\omega}.\]
%	\begin{proof}
%		It is sufficient to show this formula for $\beta$ and $\beta'$ in $U^{\infty}$ by density. Indeed, for such $\beta, \beta'$, both sides of the identity define continuous bilinear forms on $T^{\infty}$. We use the well-known integration by part formula
%		\[\duality{N u}{v} = \duality{S\partial_x u}{\partial_x v},\]
%		valid when $u$ and $v$ vanish at the extremities of the segment (see for example \cite{bruno2012second}). 
%		For a smooth $\beta$, we thus have
%		\[ \duality{N (\omega \beta)}{ (\omega \beta')} = \duality{S \partial_x(\omega \beta)}{\partial_x (\omega \beta')}\] 
%		which obviously implies the announced identity. 
%	\end{proof}
%\end{Lem}
%\begin{Prop}
%	$N_\omega$ is a positive definite, self-adjoint operator continuous from $U^s$ to $U^{s-1}$ for all real $s$. For all $n \in \N$, we have 
%	\[N_\omega U_n = \frac{n+1}{2}U_n.\]
%	Moreover, $-(\partial_x\omega)^2$ is also positive definite of order $2$.
%	\label{NUn}
%\end{Prop}
%\begin{proof}
%	From identity $T_{n+1}' = (n+1)U_n$ and Equation $\eqref{cheb1}$ we obtain
%	\begin{equation*}
%	\omega \partial_x \omega U_n = -(n+1) T_{n+1}.
%	\end{equation*}
%	Therefore, by \autoref{lemIPP}
%	\begin{eqnarray*}
%		\duality{N_\omega U_m}{U_n}_\omega & = & (n+1)(m+1)\duality{S_\omega T_{m+1}}{T_{n+1}}_\frac{1}{\omega}\\
%		&=& \delta_{m=n} \frac{n+1}{2}.	
%	\end{eqnarray*}
%	The fact that $-(\partial_x \omega)^2$ is self-adjoint positive definite of order $2$ is a consequence of Equation \eqref{cheb2}.
%\end{proof}
%	Like before, we have the following link between $U^{-1/2}$, $U^{1/2}$ and the usual Sobolev spaces. 
%
%As an application of this result, one can also derive the formal expansions as in \cite{jerez2012explicit}
%\[\frac{1}{(x-y)^2} = \sum_{n=0}^{+\infty} 2(n+1)U_n(x)U_n(y)\,,\]
%that lead, by applying for $(\partial_x\omega)^{-2}$ on both sides, to the following explicit kernel for the inverse of $N_\omega$:
%\[\ln\left(\dfrac{(y-x)^2 + (\omega(x) + \omega(y))^2}{2|x-y|}\right) = \sum_{n=0}^{+\infty} \dfrac{2 U_n(x) U_n(y)}{n+1}.\]
%Here instead, we give a simple expression of the inverse of $N_\omega$ as the inverse square root of a local operator:
%\begin{The} 
%	\label{the:NeumannInverseLaplace}
%	There holds 
%	\[N_\omega^2 = -\frac{1}{4}(\partial_x \omega)^2 \,.\]
%	The inverse of $N_\omega$ is therefore 
%	\begin{equation}
%	N_\omega^{-1} = 2\sqrt{-(\partial_x \omega)^{-2}}\,.
%	\end{equation}
%\end{The}
%In \autoref{TableNitTimeLaplaceNeumann}, we compare the number of iterations for the numerical resolution of Equation \eqref{Nomegabeta} by the method detailed in \autoref{sec:numerMeth} without preconditioner, and with a preconditioner given by $M^{-1} \left[B \right] M^{-1}$ where $M$ is the mass matrix and $\left[ B \right]$ is the Galerkin matrix of the operator $\sqrt{ -( \partial_x \omega)^{-2}}$. The right hand side in \eqref{Nomegabeta} is chosen as $u_N(x) = (x^2 + 0.001)^{1/2}, x \in (-1,1)$.
%
%\begin{table}[H]
%	\begin{center}
%		\begin{tabular}{|| m{4em} | m{4em} | m{4em} | m{4em} | m{4em}||} 
%			\hline
%			\multicolumn{1}{||c|}{ }&
%			\multicolumn{2}{c|}{with Prec.}&\multicolumn{2}{c||}{without Prec.}\\
%			\hline
%			$N$ & $n_{it}$& t(s) & $n_{it}$ & t(s)\\
%			\hline\hline
%			50 & 4 & 0.05 & 50 & 0.05\\
%			\hline
%			200 & 3 & 0.05 & 200 & 0.25\\
%			\hline
%			800 & 3 & 0.06 & 799 & 3.7 \\
%			\hline
%			3200 & 3 & 0.6 & 3007 & 630\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\caption{Number of iteration and time needed for the numerical resolution of \eqref{Somegaalpha} using Galerkin finite elements with and without preconditioner.}
%	\label{TableNitTimeLaplaceNeumann}
%\end{table}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=0.7]{../figs/PrecondNeumannLaplaceSeg.png}
%	\caption{Number of iteration in the resolution of the hypersingular  integral equation with a mesh of size $N = 1600$. The importance of preconditioning in this case is more obvious than in the case of the single-layer equation.}
%	\label{FigureNitLaplaceNeumann}
%\end{figure}
%
%\begin{Rem}
%	In \cite{bruno2012second}, the main theorem is equivalent to stating that $N_\omega S_\omega$ and $S_\omega N_\omega$ are bicontinuous operators in $T^s$, with a spectrum concentrated around $\frac{1}{4}$, which can be exploited for preconditioning purposes. It is shown that $N_\omega$ is continuous from $T^s$ to $T^{s-1}$ for all $s >1$ (in fact, this remains true for $s > \frac{1}{2}$). The two main arguments involved in the proof are the explicit expression of $N_\omega T_n$ and the continuity of the adjoint of the Cesaro operator in $l^2(\N)$. The same arguments can be used to prove that $S_\omega$ is also a bicontinuous operator from $U^s$ to $U^{s+1}$ for all $s > 1/2$. 
%\end{Rem}



%\section{Helmholtz equation}

%	In this section, we introduce preconditioners for the integral equations on $\Gamma = (-1,1)$ for the Helmholtz equation. Recall the definition of the single layer and hypersingular operators, $S_k$ and $N_k$, given in \eqref{defSk} and \eqref{defNk}, and the integral equations for the Dirichlet and Neumann problems, \eqref{Sklambda} and \eqref{Nkmu}. As before, let $S_{k,\omega} \isdef S_k \frac{1}{\omega}$ and $N_{k,\omega} \isdef N_k \omega$. We begin by establishing the following result:
%	
%	\begin{The}
%		\label{Commutations}
%		The following commutations hold:
%		\[S_{k,\omega} \left[-(\omega \partial_x)^2 - k^2\omega^2\right] =  \left[-(\omega \partial_x)^2 - k^2\omega^2\right]S_{k,\omega},\]
%		\[N_{k,\omega} \left[-(\partial_x \omega)^2 - k^2\omega^2\right] =  \left[-(\partial_x \omega)^2 - k^2\omega^2\right]N_{k,\omega}.\]
%		\begin{proof}
%			We start with the first commutation. Since $(\omega \partial_x)^2$ is self adjoint and symmetric, we have 
%			\[S_{k,\omega} (\omega \partial_x)^2 = \int_{-1}^{1} \frac{(\omega_y \partial_y)^2 \left[G_k(x-y)\right] u(y)}{\omega(y)},\]
%			where we use the notation $\omega_y$ and $\partial_y$ to emphasize the dependence in the variable $y$. 
%			Thus, 
%			\[S_{k,\omega} (\omega \partial_x)^2 - (\omega \partial_x)^2 S_{k,\omega} = \int_{-1}^{1} \frac{D_k(x,y)u(y)}{\omega(y)},\]
%			where $D_k(x,y) \isdef \left[(\omega_y \partial_y)^2 - (\omega_x \partial_x)^2\right] \left[G_k(x-y)\right]$. 
%			One has 
%			\[D_k(x,y) = G_k''(x-y) (\omega^2_y - \omega^2_x) + G_k'(x-y)(y + x).\]
%			Since $G_k$ is a solution of the Helmholtz equation, we have for all $(x \neq y) \in \R^2$ 
%			\[G_k'(x-y) = (y-x)(G_k''(x-y) + k^2G(x-y)),\]
%			thus
%			\[D_k(x,y) = G_k''(x-y)\left(\omega^2_y - \omega_x^2 + y^2 - x^2\right) + k^2(y^2 - x^2)G_k(x-y) . \]
%			A careful analysis shows that no Dirac mass appears in the previous formula, that is, the previous formula is an equality of two functions in $T^{-\infty}$. 
%			Note that $y^2 - x^2 = \omega_x^2 - \omega_y^2$ so the first term vanishes and we find
%			\[S_{k,\omega} (\omega \partial_x)^2 - (\omega \partial_x)^2 S_{k,\omega} =  k^2\left(\omega^2 S_{k,\omega} -S_{k,\omega} \omega^2 \right). \]
%			The proof of the second commutation is postponed to \autoref{ann:commut}. 
%		\end{proof}
%	\end{The}
%	
%	This theorem implies that the operators $S_{k,\omega}$ and $N_{k,\omega}$ share the same eigenvectors as, respectively, $\left[-(\omega \partial_x)^2 - k^2\omega^2\right]$ and $ \left[-(\partial_x \omega)^2 - k^2\omega^2\right]$. We can look for eigenfunctions of the operator $\left[ -(\omega \partial_x)^2 - k^2\omega^2\right]$, to find a diagonal basis for $S_{k,\omega}$. They are the solutions to the differential equation 
%	\[ (1-x^2) y'' - x y' - k^2 \omega^2 y = \lambda y.\]
%	Once we set $x = \cos \theta$, $\tilde{y}(\theta) = y(x)$,  $q = \frac{k^2}{4}$, $a = \lambda + 2q$, $\tilde{y}$ is a solution of the standard Mathieu equation 
%	\begin{equation}
%	\label{MatthieuEq}
%		\tilde{y}'' + (a - 2q \cos(2\theta)) \tilde{y} = 0.
%	\end{equation}
%	There are a discrete set of values $a_{2n}(q)$ for which this equation possesses an even and $2\pi$ periodic function. The corresponding solution is known as the Mathieu cosine, and usually denoted by $\textup{ce}_n$. Here, we use the notation $\textup{ce}^k_n$ to emphasize the dependency in the parameter $k = \sqrt{2q}$ of those functions. The normalization is taken as
%	\[ \int_{0}^{2\pi} \textup{ce}^k_n(\theta)^2 d\theta = \pi.\]
% 	They satisfy
%	\[ \int_{-\pi}^{\pi}\textup{ce}^k_n(\theta) \textup{ce}^k_m(\theta) = \pi \delta_{m,n}.\]
%	Any even $2\pi$ periodic function in $L^2(-\pi,\pi)$ can be expanded along the functions $\textup{ce}_n$, with the coefficients obtained by orthonormal projection. Letting 
%	\[T_{n}^k \isdef \textup{ce}^k_n(\arccos(x)),\]
%	in analogy to the zero-frequency case, we have
%	\[\left[-(\omega \partial_x)^2 - k^2\omega^2\right] T_{n}^k = \lambda_{n,k}^2 T_{n}^k.\]
%	For large $n$, using the general results from the theory of Hill's equations (see \cite[eq. 28.29.21]{NIST:DLMF}) we have the following asymptotic formula for $\lambda_{n,k}$:
%	\[ \lambda_{n,k}^2 = n^2 - \frac{k^4}{16n^2} +o \left(n^{-2}\right). \]
%	The first commutation established in \autoref{Commutations} implies that the Matthieu cosines are also the eigenfunctions of the single-layer operator. An equivalent statement is given in \cite[Thm 4.2]{betcke2014spectral}, if we allow the degenerate case $\mu = 0$. 
%	A similar analysis can be applied to the hypersingular operator. The eigenfunctions of $\left[(\partial_x \omega)^2 - k^2 \omega^2\right]$ are given by 
%	\[U_n^k \isdef \frac{\textup{se}_n^k(\arccos(x))}{\omega(x)}\]
%	where $\textup{se}_n^k$ are the so-called Matthieu sines, which also satisfy the Matthieu differential equation \eqref{MatthieuEq}, but with the condition that they must be odd $2\pi$ periodic functions. 
%	Unfortunately, the lack of knowledge about the eigenvalues of $S_{k,\omega}$ and $N_{k,\omega}$ prevents us from applying a similar analysis as that performed in the first part of this work. Instead, we will perform a perturbation analysis, much like \cite{bruno2012second}.
