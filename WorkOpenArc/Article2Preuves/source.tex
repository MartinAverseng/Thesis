\documentclass[a4paper]{article}
\input{../../Definitions.tex}

\title{New preconditioners for Laplace and  Helmholtz integral equation on open curves: \\ \vspace{0.5cm}
	\begin{Large} 
		II. Theoretical analysis.
	\end{Large} }
\author{Martin Averseng\footnote{CMAP, Ecole polytechnique, Route de Saclay, 91128 Palaiseau Cedex.}}
\begin{document}
\maketitle

\begin{abstract}
	This theoretical paper is dedicated to establishing the results announced in the first part of this work, related to the weighted layer potentials appearing in the resolution of first kind integral equations on open curves in 2 space dimensions. Those include the optimal orders of convergence in a new Galerkin scheme for this problem, and the analysis of two new preconditioners, in the form of square root of differential operators.
\end{abstract}

\section*{Introduction}

\toDo{Je viens de faire un autre exemple d'intro, je laisse le précédent juste après, dis moi ce que tu en penses. J'avais envie de faire passer l'idée du point (i) et (ii), et d'expliquer clairement les rôles complémentaires des deux articles. Mais je ne sais pas si c'est pertinent donc je laisse l'intro précédente si tu préfères. Je commence par la nouvelle version}

In the framework of finite element methods, two desirable features are: (i) fast convergence in terms of the mesh size and (ii) availability of an efficient preconditioner for the linear system if it is ill-conditioned. In the context of first kind integral equations on open curves in the plane, those two requirements are not easily fulfilled since on the one hand, the solutions to the integral equations have singularities near the edges of the curve, leading to poor rates of convergence in the Galerkin method, and on the other hand the usual preconditioning strategies break down in the presence of geometrical singularities on the curve. In the first part of this work \cite{alouges2018new}, we recast those integral equations using weighted layer potentials, and described a Galerkin method with optimal orders of convergence for piecewise affine functions. Furthermore, two new efficient preconditioners for the weighted potentials were, thus providing a method with both features (i) and (ii). 

The work \cite{alouges2018new} and the present have been thought with the following complementary roles: 
\begin{itemize}
	\item[-] \cite{alouges2018new} aims at describing concisely the essential aspects of the method and showing its efficiency on numerical examples
	\item[-] this work contains the complete theoretical analysis.
\end{itemize}
For this reason, we omit here the discussions on the physical nature of the problem and link with other numerical methods. We instead go straight to the proofs of the mathematical results. 

The outline of the paper is as follows. We analyze in the first section the families of Hilbert spaces $T^s$ and $U^s$, which are two interpolating Hilbert scales with interlacing properties. Those spaces are used in the second section to analyze the Galerkin method for the weighted layer potentials in weighted $L^2$ spaces, and prove optimal orders of convergence for piecewise affine functions. 
The linear systems appearing in the Galerkin method are ill-conditioned because, in some sense, the operators being discretized are not of order zero. We introduce in the third section a new concept of pseudo-differential operators on open curves that gives a precise meaning to this notion of order of an operator. This allows us to build parametrix for the layer potentials, which take the form of square roots of differential operators. Those parametrix are analyzed in the fourth and last section.

\toDo{La version précédente, moins "risquée" :}

In the first part of this work \cite{alouges2018new}, some new preconditioners for the Laplace and Helmholtz integral equations are introduced and their numerical is demonstrated on several numerical examples. Here, we develop the theory to prove the main results that were announced there. To this aim, we analyze the spaces $(T^s)_{s\in \R}$ and $(U^s)_{s \in \R}$, which are two family of Hilbert spaces, formed of Chebyshev series defined on the unit segment. They provide two interpolating scales with special interlacing properties that are established in the first section of this paper. Those spaces are suited to the analysis of a new Galerkin setting for those integral equations, performed in the second section. There, the optimal orders of convergence announced in \cite{alouges2018new} for this scheme are established.  In the third section, we build on the class of Periodic Pseudo-Differential Operators (studied for example in \cite{thrunen1998symbol}), to define two classes of pseudo-differential operators respectively in the spaces $T^s$ and $U^s$. Symbolic calculus is available in those classes, which combined to a formal calculator, allows us to analyze the efficiency of the preconditioners of \cite{alouges2018new}.
In the first section, we establish some properties of the spaces $T^s$ and $U^s$. After briefly collecting some facts on periodic pseudo-differential operators in the second section, we define the two new classes of pseudo-differential operators. In the third section, we apply this theory to the aforementioned preconditioners. Finally, the Galerkin analysis is exposed in the fourth section. 
We immediately start the presentation with some theoretical considerations. The numerical applications of this work are exposed in \cite{alouges2018new}. 
 
\begin{Rem}
	Throughout all this article, we use repeatedly the letter $C$ in estimates of the form $ a \leq C b$. From line to line, the value of the constant $C$ may change but is independent of the relevant parameters defining $a$ and $b$. 
\end{Rem}

 
\section{Spaces $T^s$ and $U^s$}

\subsection{Definitions}

\label{sec:analyticalSetting}

The Chebyshev polynomials of first and second kinds are respectively given by
\[T_n(x) = \cos(n \arccos(x)),\]
and 
\[U_n(x) = \dfrac{\sin((n+1) \arccos(x))}{\sqrt{1 - x^2}}\,\]
for $x \in [-1,1]$, see \cite{mason2002chebyshev}. Letting $\partial_x$ the derivation operator and $\omega$ the operator $u(x) \mapsto \omega(x)u(x)$ with $\omega(x) = \sqrt{1 - x^2}$, $T_n$ and $U_n$ satisfy the following identities:
\begin{eqnarray}
	-(\omega\partial_x)^2 T_n &=& n^2T_n\,, \label{cheb1}\\
	-(\partial_x\omega)^2 U_n &=& (n+1)^2U_n\, .\label{cheb2}
\end{eqnarray}
Notice that here and in the following, $\partial_x\omega$ denotes the composition of operators $\partial_x$ and $\omega$ and not the function $x \mapsto \partial_x\omega(x)$. One can also check the identities 
\begin{align}
\partial_x T_n &= n U_{n-1}\,, \label{der1} \\
-\omega \partial_x \omega U_n &= (n+1)T_{n+1}\,. \label{der2}
\end{align}
The first one is obtained for example from the trigonometric definition of $T_n$. This combined with $-(\omega \partial_x)^2 T_n = n^2 T_n$ gives the second identity. 

Both $T_n$ and $U_n$ are polynomials of degree $n$, and provide respectively a basis of the following Hilbert spaces
$$L^2_{\frac{1}{\omega}} \isdef \enstq{u \in L^1_\textup{loc}(-1,1)} {\int_{-1}^{1} \dfrac{\abs{u(x)}^2}{\sqrt{1 - x^2} }dx< + \infty}\,,$$ 
$$L^2_{\omega} \isdef \enstq{u \in L^1_\textup{loc}(-1,1)} {\int_{-1}^{1} {\abs{u(x)}^2}{\sqrt{1 - x^2} }dx< + \infty}.$$
Following the notations of \cite{mclean2000strongly}, we denote the Banach duality products of $L^2_\frac{1}{\omega}$ and $L^2_\omega$ respectively by $\duality{\cdot}{\cdot}_\frac{1}{\omega}$ and $\duality{\cdot}{\cdot}_\omega$ and the inner products respectively by $\inner{\cdot}{\cdot}_\frac{1}{\omega}$ and $\inner{\cdot}{\cdot}_\omega$, with the following normalization:
\[\inner{u}{v}_{\frac{1}{\omega}} = \duality{u}{\overline v}_\frac{1}{\omega} \isdef \frac{1}{\pi}\int_{-1}^{1} \frac{u(x) \overline{v(x)}}{\omega(x)}dx\,,\]
\[\inner{u}{v}_{\omega} = \duality{u}{\overline v}_{\omega} \isdef \frac{1}{\pi}\int_{-1}^{1} {u(x) \overline{v(x)}}{\omega(x)}dx\,.\]
The Chebyshev polynomials satisfy
\begin{equation}
	\inner{T_n}{T_m}_\frac{1}{\omega} = \left\{
	\begin{array}{l}
	0 \mbox{ if } n\ne m,\\
	1 \mbox{ if } m=n=0,\\
	1/2 \mbox{ otherwise,}
	\end{array} 
	\right.
\end{equation}
and
\begin{equation}
	\inner{U_n}{U_m}_{\omega} = \left\{
	\begin{array}{l}
	0 \mbox{ if } n\ne m,\\
	1/2 \mbox{ otherwise,}
	\end{array} 
	\right.
\end{equation}
from which we obtain the so-called Fourier-Chebyshev decomposition. Any
$u\in L^2_{\frac{1}{\omega}}$ can be decomposed through the first kind Chebyshev series 
\begin{equation}
	u(x) = \sum_{n=0}^{+\infty} \hat{u}_n T_n(x)\,,
	\label{FCseries}
\end{equation}
where the Fourier-Chebyshev coefficients of the first kind are given by $\hat{u}_n = \frac{\inner{u}{T_n}_{\frac{1}{\omega}}}{\inner{T_n}{T_n}_{\frac{1}{\omega}}}$ and satisfy the Parseval equality
\[\forall (u,v) \in L^2_\frac{1}{\omega} \quad  \inner{u}{v}_\frac{1}{\omega} = \hat{u}_0 \overline{\hat{v}}_0 + \frac{1}{2}\sum_{n=1}^{+\infty}\hat{u}_n \overline{\hat{v}}_n \,.\]
When $u$ is furthermore a smooth function, one can check that the series \eqref{FCseries} converges uniformly to $u$. Similarly, any 
function $v\in L^2_{\omega}$ can be decomposed along the $U_n$ as
\[ v(x) = \sum_{n=0}^{+\infty} \check{v}_n U_n(x)\]
where the Fourier-Chebyshev coefficients of the second kind $\check{v}_n$ are given by $ \check{v}_n \isdef 
\frac{\inner{v}{U_n}_\omega}{\inner{U_n}{U_n}_\omega}$ with the Parseval identity
\[ \inner{u}{v}_\omega =  \frac{1}{2} \sum_{n=0}^{+\infty}\check{u}_n \overline{\check{v}_n} \,.\]
The preceding analysis can be used to define Sobolev-like spaces. 
\begin{Def}
	We define $T^s$ as the set of (formal) series
	\[u = \sum_{n \in \N} \hat{u}_n T_n\]
	where the coefficients $\hat{u}_n$ satisfy
	\[\sum_{n \in \N} (1 + n^2)^s \abs{\hat{u}_n}^2 < + \infty\,.\]
	Let $T^{\infty} = \displaystyle\cap_{s \geq 0} T^s$ and $T^{-\infty} = \cup_{s \in \R} T^s$. For $u\in T^s$ when $s \geq 0$, the series defining $u$ converges in $L^2_\frac{1}{\omega}$ and the Fourier-Chebysehv coefficients of the first kind of $u$ coincide with $\hat{u}_n$, allowing to identify $T^s$ to a subspace of $L^2_\frac{1}{\omega}$ with $T^0 = L^2_\frac{1}{\omega}$. For all $u \in T^{s}$, we define the linear form $\duality{u}{\cdot}_\frac{1}{\omega}$ by
	\begin{equation}
	\label{dualiteTs}
		\forall \varphi \in T^\infty, \duality{u}{\varphi}_\frac{1}{\omega} = \frac{1}{2} \hat{u}_0 \hat \varphi_{0} + \frac{1}{2}\sum_{n = 1}^{+ \infty} \hat{u}_n \hat{\varphi}_n\,.
	\end{equation}
	This linear form has a unique continuous continuation on $T^{-s}$, and the dual of $T^s$ is the set of linear forms $\duality{u}{\cdot}_\frac{1}{\omega}$ where $u \in T^{-s}$.  
	Endowed with the scalar product
	\[(u,v)_{T^s} \isdef \hat{u}_0 \overline{\hat{v}_0} + \frac{1}{2}\sum_{n=1}^{+\infty}(1 + n^{2})^s\hat{u}_n \overline{\hat{v}_n}\,,\]
	$T^s$ is a Hilbert space for all $s$. A homogeneous semi-norm on $T^s$ can be defined as
	\[\abs{u}_{T^s}^2 \isdef \frac{1}{2}\sum_{n = 1}^{+ \infty}n^{2s} \abs{\hat{u}_n}^2.\] 
\end{Def}
\begin{Def}
	In a similar fashion, we define $U^{s}$ as the set of formal series 
	\[u = \sum_{n \in \N}\check{u}_n U_n\]
	where the coefficients $\check{u}_n$ satisfy
	\[\sum_{n \in \N} (1 + n^2)^s \abs{\check{u}_n}^2 < + \infty\,.\]
	Let $U^\infty = \cap_{s \in \R} U^s$ and $U^{-\infty} = \cup_{s \in \R} U^s$. For $u \in U^s$ when $s \geq 0$, the series defining $u$ converges in $L^2_{\omega}$ and the Fourier-Chebyshev coefficients of the second kind of $u$ coincide with $\check{u}_n$, allowing to identify $U^s$ to a subspace of $L^2_{\omega}$ with $U^0 = L^2_\omega$. For all $u \in U^s$, we define the linear form $\duality{u}{\cdot}_\omega$ by 
	\begin{equation}
		\label{dualiteUs}
		\forall \varphi \in U^\infty, \duality{u}{\varphi}_\omega \isdef \frac{1}{2} \sum_{n = 0}^{+ \infty} \check{\varphi_n}\check{u}_n\,.
	\end{equation}
	This linear form has a unique continuous extension on $U^{-s}$, and the dual of $U^s$ may be identified to $U^{-s}$ with respect to the bilinear form $\duality{\cdot}{\cdot}_{\omega}$.
	Endowed with the scalar product
	\[\inner{u}{v}_{U^s} \isdef \frac{1}{2}\sum_{n \in \N} \left(1 + (n + 1)^2\right)^s \check{u}_n \overline{\check{v}}_n\,,\] 
	$U^s$ is a Hilbert space for all $s \in \R$. 
\end{Def}

Let $s_1,s_2 \in _R$, $\theta \in (0,1)$ and let $s = \theta s_1 + (1-\theta)s_2$. It is easy to check that
\[\forall u \in T^\infty, \norm{u}_{T^s} \leq \norm{u}_{T^{s_1}}^\theta \norm{u}_{T^{s_2}}^{1 - \theta}\]
and 
\[\forall u \in U^\infty, \norm{u}_{U^s} \leq \norm{u}_{U^{s_1}}^\theta \norm{u}_{U^{s_2}}^{1 - \theta}\]
Therefore, $(T^s)_{s \in \R}$ and $(U^s)_{s \in \R}$ are exact interpolation scales. 

\subsection{Basic properties}

\paragraph{Links with smooth functions and continuous inclusions.}
For any real $s$, if $u \in T^s$, the sequence of polynomials 
\[u_N(x) = \sum_{n=0}^{N} \hat{u}_n T_n(x)\]
converges to $u$ in $T^s$. The same assertion holds for $u \in U^s$ when $T_n$ is replaced by $U_n$. Therefore
\begin{Lem}
	\label{densite}
	$C^{\infty}([-1,1])$ is dense in $T^s$ and $U^s$ for all $s \in \R$.
\end{Lem}
\noindent The polynomials $T_n$ and $U_n$ are connected by the following formulas:
\begin{equation}
\label{TnAsUn}
T_0 = U_0, \quad T_1 = \frac{U_1}{2}, \quad \text{ and } \quad \forall n \geq 2, \quad T_n = \frac{1}{2}\left(U_n - U_{n-2}\right),
\end{equation}
\begin{equation}
\label{UnAsTn}
\forall n \in \N, \quad U_{2n} = 2\sum_{j = 0}^n T_{2j} - 1, \quad U_{2n+1} = 2\sum_{j=0}^n T_{2j+1}.
\end{equation}
This leads us to introduce the map  
\[I : T^{\infty} \to U^{\infty}\]
defined by 
\[\reallywidecheck{I \varphi}_0 = \hat{\varphi}_0 - \frac{\hat{\varphi}_2}{2}, \quad \reallywidecheck{I \varphi}_j = \frac{\hat{\varphi}_j - \hat{\varphi}_{j+2}}{2} \textup{ for } j \geq 1.\]
$I$ is bijective has the explicit inverse
\[\widehat{I^{-1} \varphi}_{0} = \sum_{n=0}^{+ \infty} \check{\varphi}_{2n}, \quad  \widehat{I^{-1}\varphi}_j = 2\sum_{n=0}^{+\infty} \check{\varphi}_{j + 2n} \textup{ for } j \geq 1.\]
\begin{Lem}
	For all real $s$, $I$ has a unique continuous extension from $T^s$ to $U^s$ and for $s> \frac{1}{2}$, $I^{-1}$ has a continuous extension from $U^s$ to  $T^{s-1}$.
\end{Lem}
\noindent Before starting the proof, we introduce the Cesàro operator $C$ defined on $l^2(\N^{*})$ by
\[(Cu)_n = \frac{1}{n}\sum_{k=1}^n u_k\,.\]
As is well-known, this is a linear continuous operator on the Hilbert space $l^2(\N^*)$. Its adjoint
\[(C^* u)_n = \sum_{k = n}^{+ \infty} \frac{u_k}{k} \,,\]
is therefore also continuous on $l^2(\N^*)$. In other words, for all $(u_n)_n \in l^2(\N)$, 
\[ \sum_{n = 1}^{+ \infty} \left(\sum_{k = n}^{+ \infty} \frac{u_k}{k}\right)^2 \leq C \sum_{k = 1}^{+ \infty} u_k^2\, .\]
\begin{proof}
	The first result is immediate from the definition of $T^s$, $U^s$ and $I$. 
	When $u \in U^{s}$ for $s > 1/2$, the series $\sum \abs{\check{u}_n}$ is converging thus $I^{-1}u$ is well defined.
	Since $u \in U^s$, the sequence $\left((1+n^2)^{s/2} \abs{\check{u}_n}\right)_{n \geq 1}$ is in $l^2(\N^*)$. Thus, using the continuity of the adjoint of the Cesàro operator mentioned previously, the sequence $(r_n)_n$ defined by 
	\[\forall n \geq 0, \quad r_n \isdef \sum_{k=n}^{+ \infty} (1+k^2)^{\frac{s-1}{2}} \abs{\check{u}_k} \] is in $l^2(\N)$ with a $l^2$ norm bounded by $\norm{u}_{U^s}$. We now write
	\begin{eqnarray*}
		\norm{I^{-1} u}_{T^{s-1}}^2 &=& \sum_{n=0}^{+ \infty} (1 + n^2)^{s-1} \abs{\widehat{I^{-1} u}_n}^2\\ 
		&\leq& 4\sum_{n=0}^{+\infty}(1+n^2)^{s-1} \left(\sum_{k=n}^{+\infty} \abs{\check{u}_k}\right)^2 \\
		&\leq& 4\sum_{n=0}^{+ \infty}\left(\sum_{k=n}^{+\infty}(1+k^2)^{\frac{s-1}{2}} \abs{\check{u}_k})\right)^2.\\
		&=& 4\norm{(r_n)_n}^2_{l^2}
	\end{eqnarray*}	
	We saw that the last quantity is controlled by $\norm{u}_{U^s}^2$ so the result is proved.
\end{proof}
\noindent \toDo{Digression à enlever (mais garder dans le manuscrit).}
\begin{Lem}
	Let $s > 1/2$ and let $u \in U^{s}$. Then there exists $0 < \varepsilon < 1$ such that ${\omega^{-\frac{1 + \varepsilon}{2}}}u \in L^2_\omega$ with 
	\[\norm{\omega^{-\frac{1 + \varepsilon}{2}}u}_\omega \leq C \norm{u}_{U^s}\,.\]
	\begin{proof}
		We start by showing the following estimate
		\[\forall \varepsilon \in (0, 1),  \, \exists C_\varepsilon : \forall n \in \N, \quad I_n \isdef \int_{-1}^{1} U_n^2 \omega^{-\varepsilon} \leq C_\varepsilon (n+1)^{\varepsilon}\,.\]
		Fix $ \varepsilon \in (0,1)$. Using the variable change $x = \cos\theta$ and the symmetry of the integrand with respect to the change $\theta \to \pi - \theta$, we transform the quantity to be estimated to
		\[I_{n} = \int_{0}^{\frac{\pi}{2}} \frac{\sin((n+1)\theta)^2}{\abs{\sin\theta}^{1 + \varepsilon}}d\theta\,.\]
		We split $I_n$ into two parts. Let $I_{n,1} =  \int_{0}^{\frac{\pi}{n+1}} \frac{\sin((n+1)\theta)^2}{\abs{\sin\theta}^{1 + \varepsilon}}d\theta$. On this interval, we use $\sin((n+1)\theta) \leq (n+1)\theta$ and $\sin\theta \geq \frac{2}{\pi}\theta$ to find 
		\[I_{n,1} \leq C (n+1)^2\int_{0}^{\frac{\pi}{n+1}} \theta^{1 - \varepsilon} \leq C_{\varepsilon,1} (n+1)^{\varepsilon}\,.\]
		Let $I_{n,2} = I - I_{n,1}$. On this interval, we estimate the numerator by 
		\[\sin((n+1)\theta) \leq 1\] 
		and use the same estimate as before for the denominator. One can check that this leads to $I_{n,2} \leq C_{\varepsilon,2}n^{\varepsilon}$. The proof of the main result is now as follows. Let $u \in U^s$ where $s > \frac{1}{2}$ and let $s = \frac{1}{2} + \varepsilon$. Then the series 
		\[{\omega^{-\frac{1 + \varepsilon}{2}}}u = \sum_{n \in \N} \check{u}_n \frac{U_n}{\omega^{\frac{1 +\varepsilon}{2}}}\]
		converges in $L^2_\omega$ since 
		\[\begin{split}
		\sum_{n \in \N} \norm{\check{u}_n \frac{U_n}{\omega^{\frac{1+\varepsilon}{2}}}}_{L^2_\omega} &\leq C \sum_{n \in \N} \abs{\check{u}_n} (n+1)^{\frac{\varepsilon}{2}}\\
		&\leq C \sqrt{\sum_{n\in \N}(n+1)^{2s}\abs{\check{u}_n}^2} \sqrt{\sum_{n\in \N}(n+1)^{-1 - \varepsilon}}\\
		&\leq C \norm{u}_{U^s}\end{split}\,.\]
		Thus $\frac{u}{\omega^{\frac{1 + \varepsilon}{2}}} \in L^2_\omega$ by normal convergence and the result is proved. 
	\end{proof} 
\end{Lem}
\noindent Notice that for $\varphi \in \Cinf([-1,1])$, for all $\varepsilon > 0$, ${\omega^{-\frac{3-\varepsilon}{2}}} \varphi \in L^2_\omega$. 
\begin{Cor}
	Let $u \in T^{-\infty}$. Then $Iu \in U^{-\infty}$ is characterized by
	\[\forall \varphi\in \Cinf([-1,1]),\quad \duality{Iu}{\varphi}_\omega = \duality{u}{\omega^2 \varphi}_\frac{1}{\omega}\,.\]
	Let $u \in U^s$ with $s > \frac{1}{2}$. Let $\varepsilon$ such that $\omega^{-\frac{1+ \varepsilon}{2} }u \in L^2_\omega$. Then $I^{-1}u \in T^{-\infty}$ is characterized by 
	\[\forall \varphi\in \Cinf([-1,1]), \quad \duality{I^{-1}u}{\varphi}_\frac{1}{\omega}=\duality{{\omega^{-\frac{1+ \varepsilon}{2} }u}}{{\omega^{-\frac{3- \varepsilon}{2} } \varphi}}_\omega \]
\end{Cor}
\begin{proof}
	We shall only treat the second statement, the first one being similar and simpler. By density of $\Cinf([-1,1])$ in $U^s$, we can fix a sequence of $\Cinf$ functions $u_N$ converging to $u$ in $U^s$. Then, the sequence $\omega^{-\frac{1 + \varepsilon}{2}}u_N$ converges to $\omega^{-\frac{1 + \varepsilon}{2}}u$ in $L^2_\omega$ since, by the previous result,
	\[\norm{\omega^{-\frac{1+ \varepsilon}{2}}(u_N - u)}_{L^2_\omega} \leq C \norm{u - u_N}_{U^{s}}\,.\]
	Thus, there holds 
	\[\lim_{N \to \infty} \duality{{\omega^{-\frac{1+ \varepsilon}{2} }u_N}}{{\omega^{-\frac{3- \varepsilon}{2} }\overline \varphi}}_\omega = \duality{{\omega^{-\frac{1+ \varepsilon}{2} }u}}{{\omega^{-\frac{3- \varepsilon}{2} } \varphi}}_\omega\,.\]
	By continuity of $I^{-1}$ from $U^s$ to $T^{s - 1}$, we also have 
	\[\lim_{N \to \infty}\duality{I^{-1} u_N}{\varphi}_{\frac{1}{\omega}} = \duality{I^{-1} u}{\varphi}_{\frac{1}{\omega}}\,. \]
	For all $N$, $I^{-1}u_N = u_N \in \Cinf([-1,1])$. Therefore, we obviously have
	\[\duality{I^{-1}u_N}{\varphi}_{\frac{1}{\omega}} =  \duality{{\omega^{-\frac{1+ \varepsilon}{2} }u_N}}{{\omega^{-\frac{3- \varepsilon}{2} } \varphi}}_\omega\,,\] 
	from which the result follows.
\end{proof}
\noindent\toDo{Fin d'une digression potentiellement à enlever.}\\
\noindent Let
\[u = \sum_{n \in \N } \hat{u}_n T_n, \quad v = \sum_{n \in \N} \check{v}_n U_n\,.\]
When $Iu = v$, we identify $u$ and $v$. The previous results have shown that this identification is compatible with the equality of functions in $L^2_\frac{1}{\omega}$ or $L^2_\omega$. The mapping $I$ is then the identity mapping and its properties just established can be rephrased in the following continuous inclusions:
\begin{Cor}
	For all $s \in \R$, $T^s \subset U^s$ and for all $s > \frac{1}{2}$, $U^s \subset T^{s-1}$ with continuous inclusions.
	\label{inclusionsTsUs}
\end{Cor}
\noindent 
One immediate consequence of the previous result is that $T^{\infty} = U^{\infty}$. Moreover, there holds
\begin{Lem}
	\[T^{\infty} = C^{\infty}([-1,1])\,.\]
	\label{LemTinfCinf}
\end{Lem}
\begin{proof}
	If $u \in C^{\infty}([-1,1])$, then we can obtain by induction using integration by parts and \eqref{cheb1}, that for any $k \in \N$
	\[\hat{u}_n = \frac{(-1)^k}{n^{2k}} \int_{-1}^{1} \dfrac{(\omega\partial_x)^{2k} u(x) T_n(x)}{\omega(x)}dx.\]
	Noting that $(\omega \partial_x)^2 = (1-x^2)\partial_x^2 - x \partial_ x$, the function $(\omega \partial_x)^{2k}u$ is $C^{\infty}$, and since $\norm{T_n}_\infty = 1$, the integral is bounded independently of $n$. Thus, the coefficients $\hat{u}_n$ have a fast decay, proving that $C^{\infty}([-1,1]) \subset T^{\infty}$. 
	
	For the converse inclusion, if $u \in T^{\infty}$, the series
	\[ u(x) = \sum_{n=0} \hat{u}_n T_n(x)\]
	is normally converging since $\norm{T_n}_\infty = 1$, so $u$ is a continuous function. This proves $T^{\infty} \subset C^0([-1,1])$. It suffices to show that $\partial_x u \in T^{\infty}$ and apply an induction argument. Applying term by term differentiation, since $\partial_x T_n = n U_{n-1}$ for all $n$ (with the convention $U_{-1} = 0$),
	\[\partial_x u(x) = \sum_{n=1}^{+\infty} n \hat{u}_n U_{n-1}(x).\] 
	Therefore, $\partial_x u$ is in $U^{\infty} = T^{\infty}$ which proves the result.
\end{proof}
\begin{Lem}
	For $s \leq \frac{1}{2}$, the functions of $U^s$ cannot be identified to functions in $T^{-\infty}$. 	
\end{Lem}
\begin{proof}
	Let $s \leq \frac{1}{2}$, and let us assume by contradiction that the functions of $U^{s}$ can be identified to elements of $T^{-\infty}$. Then, there must exist a continuous map $I$ from $U^{s}$ to $T^{-\infty}$ with the property 
	\[\forall u \in C^{\infty}([-1,1]), \quad Iu = u.\]
	We introduce the function $u$ defined by $\check{u}_n = \frac{1}{n \ln(n)}$. One can check that $u \in U^{\frac{1}{2}} \subset U^s$, thus $Iu$ must be element of $T^{-\infty}$. For all $N$, the function 
	\[u_N = \sum_{n = 0}^{N} \check{u}_n U_n\]
	is in $U^{\infty}$ and $(u_N)_{N \in \N}$ converges to $u$ in $U^{s}$. By continuity of $I$, the sequence $(\duality{I u_N}{T_0}_\frac{1}{\omega})_{N\in \N}$ must converge with limit $\duality{Iu}{T_0}_\frac{1}{\omega}$. But since $Iu_N = u_N$, 
	\[\duality{Iu_N}{T_0}_\frac{1}{\omega} = \duality{u_N}{T_0}_\frac{1}{\omega} = \sum_{n=0}^{N} \check{u}_n\duality{U_n}{T_0}_\frac{1}{\omega} = \sum_{k = 0}^{\lfloor \frac{N}{2} \rfloor} \frac{1}{2k \ln(2k)}\,. \]
	This sum diverges to $+\infty$ when $N$ goes to infinity, giving the contradiction.
\end{proof}

\paragraph{Derivation operators.} We now extend the definition of the derivation operators $\partial_x$ and $\omega\partial_x\omega$ appearing in \cref{der1,der2}.

 
\begin{Lem}
	\label{derivations}
	For all real $s$, the operator $\partial_x$ can be extended into a continuous map from $T^{s+1}$ to $U^{s}$ defined by 
	\[\forall v \in \Cinf([-1,1]), \quad \duality{\partial_x u}{v}_{\omega} \isdef -\duality{u}{\omega \partial_x \omega v}_{\frac{1}{\omega}} \,.\] 
	In a similar fashion, the  operator $\omega \partial_x \omega$ can be extended into a continuous map from $U^{s+1}$ to $T^{s}$ defined by
	\[\forall v \in \Cinf([-1,1]), \quad \duality{\omega \partial_x \omega u}{v}_\frac{1}{\omega} \isdef -\duality{u}{\partial_x v}_\omega.\]
\end{Lem}
\begin{proof}
	Using \cref{der1,der2}, one can check that the formulas indeed extend the usual definition of the two operators for smooth functions. We now show that the map $\partial_x$ extended this way is continuous from $T^{s+1}$ to $U^s$. The definition 
	\[\forall v \in U^{\infty}, \duality{\partial_x u}{v}_\omega \isdef -\duality{u}{\omega \partial_x \omega v}_\frac{1}{\omega}\]
	gives a sense to $\partial_x u$ for all $u$ in $T^{-\infty}$, as a duality $T^{-\infty} \times T^{\infty}$ product, because if $v \in U^{\infty} (= C^{\infty}([-1,1])$, then $\omega \partial_x \omega v = (1-x^2)v' - xv$ also lies in $C^{\infty}([-1,1]) (= T^\infty)$. Letting $w = \partial_x u$, we have by definition for all $n$
	\[\check{w}_n = \duality{w}{U_n}_{\omega} = - \duality{u}{\omega \partial_x \omega U_n}_\frac{1}{\omega} = n \duality{u}{T_{n+1}}_\frac{1}{\omega} = n\hat{u}_{n+1}\,.\]
	Obviously, this implies the announced continuity with
	\[ \norm{w}_{U^s} \leq \norm{u}_{T^{s+1}}\,.\]
	The properties of $\omega \partial_x \omega$ on $T^s$ are established similarly. 
\end{proof}
\begin{Cor}
	\label{corDxT2T0}
	The operator $\partial_x$ is continuous from $T^{s+2}$ to $T^s$ for all $s > -1/2 $ and from $U^{s+2}$ to $U^s$ for all $s > - 3/2$. On the other hand, $\omega \partial_x \omega$ is continuous from $T^{s+1}$ to $T^s$ and from $U^{s+1}$ to $U^s$ for all $s \in \R$. 
\end{Cor}
\begin{proof}
	For the continuity of $\partial_x$ from $T^{s+2}$ to $T^s$, we use the continuity of $\partial_x$ from $T^{s+2}$ to $U^{s+1}$ and then of the identity from $U^{s+1}$ to $T^s$. For the continuity of $\partial_x$ from $U^{s+2}$ to $U^s$, we use the same arguments in reverse order. \\
	On the other hand, we have, for $n \geq 2$,
	\[\omega \partial_x \omega T_n = \omega\partial_x \omega \frac{U_n - U_{n-2}}{2} = \frac{(n+1)T_{n+1} - (n-1)T_{n-1}}{2}\,.\]
	Therefore $\omega \partial_x \omega$ is continuous from $T^{s+1}$ to $T^s$. Finally, $\omega \partial_x \omega$ is continuous from $U^{s+1}$ to $T^s$ and the inclusion $T^s \subset U^s$ is continuous thus $\omega \partial_x \omega$ is continuous from $U^{s+1}$ to $U^s$.  
\end{proof}
\begin{Lem}
	\label{LemInjectionsContinues}
	For all $\varepsilon >0$, if $u \in T^{\frac{1}{2} + \varepsilon}$, then $u$ is continuous and
	\[ \exists C : \forall x \in [-1,1], \quad \abs{u(x)} \leq C \norm{u}_{T^{1/2 + \varepsilon}}.\]	
	Similarly, if $u \in U^{3/2 + \varepsilon}$, then $u$ is continuous and 
	\[ \exists C : \forall x \in [-1,1], \quad \abs{u(x)} \leq C \norm{u}_{U^{3/2 + \varepsilon}}.\]
\end{Lem}
\begin{proof}
	Let $x \in [-1,1]$. Using triangular inequality,
	\[\abs{u(x)} \leq \sum_{n = 0}^{+ \infty} \abs{\hat{u}_n}\]
	since for all $n$, $\norm{T_n}_{L^\infty} = 1$. Applying Cauchy-Schwarz's inequality, one gets
	\[\abs{u(x)} \leq \sqrt{\sum_{n= 0}^{+ \infty} \frac{1}{(1+ n^2)^{\frac{1}{2}+ \varepsilon}}} \norm{u}_{T^{\frac{1}{2} + \varepsilon}}.\]
	The second statement is deduced from the first and the continuous inclusion $U^{s} \subset T^{s-1}$ stated in \autoref{inclusionsTsUs}. 
\end{proof}	

\subsection{Equivalent norms on $T^n$ and $U^n$}
We now provide a characterization of the spaces $T^n$ and $U^n$ in terms of weighted $L^2$ norms of the derivatives and give equivalent norms on those spaces when $n$ is an integer. 
\begin{Lem}
	\label{omegadxetdxomga}
	The operator $\omega$ is a bijective isometry from $U^0$ to $T^0$ with inverse $\frac{1}{\omega}$. 
\end{Lem}
\begin{proof}
	This result follows from
	\[\norm{\omega u}_\frac{1}{\omega}^2 = \frac{1}{\pi}\int_{-1}^1 \frac{\abs{(\omega u)}^2}{\omega} = \frac{1}{\pi} \int_{-1}^{1} \omega \abs{u}^2 = \norm{u}_\omega^2\,,\]
	valid for all $u \in L^2_\omega$.
\end{proof}
\begin{Def}
	For an even integer $n$, the operator $(\omega \partial_x)^n : T^{-\infty} \to T^{-\infty}$ is defined by
	\[(\omega \partial_x)^0 = I_d,\quad \forall k > 0,\,\,\, (\omega \partial_x)^{2k} \isdef (\omega \partial_x \omega) \partial_x (\omega \partial_x)^{2k -2}\,.\] The operator $(\partial_x \omega)^n : U^{-\infty} \to U^{-\infty}$ is defined in an analogous way. 
\end{Def}
\begin{Lem}
	\label{Lemnpair}
	Let $n$ an even integer. For all $s \in \R$, $(\omega \partial_x)^n$ is continuous from $T^s$ to $T^{s - n}$ and $(\partial_x \omega)^n$ is continuous from $U^s$ to $U^{s-n}$. 
\end{Lem}
\begin{proof}
	Those results follow from the definition of the operators and by induction using the mapping properties of $\partial_x$ and $\omega \partial_x \omega$ established in \autoref{derivations}. 
\end{proof}
\begin{Def}
	For an odd integer $n$, the operator $(\omega \partial_x)^n : T^n \to T^{0}$ is defined by
	\[(\omega \partial_x)^n \isdef \omega \partial_x (\omega \partial_x)^{n-1}\,.\] 
	The operator $( \partial_x \omega)^n : T^n \to T^{0}$ is defined in an analogous way. 
\end{Def}
\noindent From \autoref{omegadxetdxomga}, we deduce 
\begin{Cor}
	\label{Lemnimpair}
	The operators $(\omega \partial_x)^n$ and $(\partial_x \omega)^n$ are well defined and continuous respectively from $T^n$ to $T^0$ and from $U^n$ to $U^0$. 
\end{Cor}
\begin{Lem}
	Let $n \in \N$. If $n$ is even,
	\[T^n = \enstq{ u \in L^2_\frac{1}{\omega}}{(\omega \partial_x)^n u \in L^2_\frac{1}{\omega}}\,.\]
	If $n$ is odd, 
	\[T^n = \enstq{u \in L^2_\frac{1}{\omega}}{\partial_x(\omega \partial_x)^{n-1} u \in L^2_\omega}\,.\] 
	Moreover $u \mapsto \sqrt{\norm{u}_\frac{1}{\omega}^2 + \norm{(\omega \partial_x)^nu}^2_{\frac{1}{\omega}}}$ defines an equivalent norm on $T^n$, and for all $u \in T^n$, 
	\[\abs{u}_{T^n} = \norm{(\omega \partial_x)^n u}_{L^2_\frac{1}{\omega}}\,.\]
	\label{LemEquivalentNormsTn}
\end{Lem}
\begin{proof}
	The direct inclusions follow from the mapping properties established in \autoref{derivations}, \autoref{Lemnpair} and \autoref{Lemnimpair}. 
	For the converse inclusions, let $u$ in $L^2_\frac{1}{\omega}$. If $n$ is even, say $n=2k$, the assumption is that $(\omega \partial_x)^{n}u \in L^2_\frac{1}{\omega}$. The Fourier-Chebyshev coefficients of $a = (\omega \partial_x)^n u$ are given for $j > 0$ by
	\[\hat{a}_j = \frac{\inner{(\omega \partial_x)^{2k} u(x)}{T_j}_\frac{1}{\omega}}{(T_n,T_n)_\frac{1}{\omega}} =  \frac{\inner{ u(x)}{(\omega \partial_x)^{2k}T_j}_\frac{1}{\omega}}{(T_n,T_n)_\frac{1}{\omega}} = (-1)^k j^{2k} \hat{u_j}\,.\]
	while for $j = 0$, $\hat{a}_j = 0$. 
	Applying Parseval's equality to the function $a$, this gives
	\begin{equation}
	\label{tempp1}
	\frac{1}{2}\sum_{j > 0} j^{2n} \abs{\hat{u}_j}^2 = \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\,.
	\end{equation}
	On the other hand, if $n$ is odd, say $n = 2k+1$, let $b \isdef \partial_x (\omega \partial_x)^{2k} u$. The assumption is now that $b \in L^2_\omega$, and by \autoref{omegadxetdxomga}, $\omega b \, ( = (\omega \partial_x)^n u) \, \in T^0$ with
	\[\norm{\omega b}_{\frac{1}{\omega}} = \norm{(\omega \partial_x)^n u}_{\frac{1}{\omega}} =  \norm{b}_\omega\,.\]
	One can write
	\[\check{b}_j = 2\inner{\partial_x(\omega \partial_x)^{2k} u}{U_j} = -2 \inner{u}{(\omega \partial_x)^{2k}(\omega \partial_x \omega) U_j}\,.\]
	Using $-\omega \partial_x \omega U_j = (j+1)T_{j+1}$, we obtain
	\[\check{b}_j = (-1)^k(j+1)^{2k + 1} \hat{u}_{j+1}\,.\]
	Parseval's equality then implies that \eqref{tempp1} also hold for odd $n$.
	This establishes that $u \in T^n$ and $\abs{u}_{T^n} = \norm{(\omega \partial_x)^nu}_\frac{1}{\omega}$. For the norm equivalence, adding the Parseval equality for $u \in L^2_\frac{1}{\omega}$ to \cref{tempp1}, we get 
	\begin{equation}
	\abs{\hat{u}_0}^2 + \frac{1}{2}\sum_{j > 0}  (1 + j^{2n}) \abs{\hat{u}_j}^2 = \norm{u}_\frac{1}{\omega}^2 + \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\,.
	\label{tempp}
	\end{equation}
	There are two constants $c$ and $C$ such that $c (1 + j^2)^n \leq (1 + j^{2n}) \leq C(1 + j^2)^n$. Injecting this in \eqref{tempp}, we obtain
	\[ \frac{c}{2}\norm{u}_{T^n}^2 \leq  \norm{u}_\frac{1}{\omega}^2 + \norm{(\omega \partial_x)^n u}_\frac{1}{\omega}^2\leq C\norm{u}_{T^n}^2\,,\] 
	and the equivalence of the norms follows.
\end{proof}
\begin{Lem} 
	\label{LemEquivalentNormsUn}
	Let $n \in \N$. If $n$ is even, then
	\[U^n = \enstq{u \in L^2_\omega}{(\partial_x \omega)^n u \in L^2_\omega}\,.\]
	If $n$ is odd, then
	\[U^n = \enstq{u \in L^2_\omega}{\omega \partial_x\omega (\partial_x \omega)^{n-1} u \in L^2_\frac{1}{\omega}}\,.\]	
	Moreover, $u \mapsto \sqrt{\int_{-1}^{1} \omega {\abs{( \partial_x \omega )^nu}^2}}$ defines an equivalent norm on $U^n$. 
\end{Lem}
\begin{proof}
	The direct inclusions follow from the mapping properties established in \autoref{derivations}, \autoref{Lemnpair} and \autoref{Lemnimpair}. For the converse inclusion, if $n$ is even, let $a = (\partial_x \omega)^n u$, we assume that $a \in L^2_\omega$. One has 
	\[\check{a}_j = (-1)^k \left(1+j\right)^{n}\check{u}_j\] 
	so by Parseval's equality, 
	\begin{equation}
	\label{tempp2}
	\frac{1}{2}\sum_{j = 0 }^{+ \infty} (j+1)^{2n} \abs{\check{u}_j}^2 = \norm{(\partial_x \omega)^nu}^2_\omega\,.
	\end{equation}
	If $n$ is odd, the assumption is that $b = \omega \partial_x \omega(\partial_x \omega)^{n-1}u$ is in $L^2_\frac{1}{\omega}$. By calculations similar to those in the proof of the preceding lemma, we find that for $j > 0$,
	\[\hat{b}_j = j^{2n} \check{u}_{j-1}\,.\]
	while $\hat{b}_0 = 0$. By \autoref{omegadxetdxomga}, $\frac{b}{\omega} \,(= (\partial_x \omega)^n u)\, \in U^0$. Applying Parseval's equality to $b$ in $L^2_\frac{1}{\omega}$ and using $\norm{\frac{b}{\omega}}_\omega = \norm{b}_\frac{1}{\omega}$, we find that \eqref{tempp2} also holds when $n$ is odd, and thus the inclusion is proved. Finally, there exists two constants $c$ and $C$ such that for all $j \in \N$, 
	\[c(1 + (j + 1))^{2n} \leq (j + 1)^{2n}  \leq C(1 + (j+1))^{2n}.\]
	This implies the equivalence of the norms.
\end{proof}

\subsection{Link with Periodic Sobolev spaces}
We briefly recall here the definition of the periodic Sobolev spaces on the torus $\mathbb{T}_{2\pi} \isdef \R / 2\pi \Z$. A smooth function $u$ on $\mathbb{T}_{2\pi}$ can be decomposed in Fourier series 
\[u(\theta) = \sum_{n \in \Z} \mathcal{F}u(n) e^{in\theta}\]
with the Fourier coefficients defined by 
\[\mathcal{F}u(n) \isdef \frac{1}{2\pi}\int_{-\pi}^\pi u(\theta) e^{-in\theta}d\theta.\]
For $n\in \Z$, let $e_n : \theta \mapsto e^{in\theta}$. We define the Fourier coefficients of any periodic distribution $u$ on $\mathbb{T}_{2\pi}$, by $\mathcal{F}u(n) \isdef u(e_{-n})$. For all $s$, the space $H^s$ is the set of periodic distributions on $\mathbb{T}_{2\pi}$ for which 
\[\norm{u}_{H^s}^2 \isdef \sum_{n \in \Z} (1 + n^{2})^s\abs{\mathcal{F}u(n)}^2 < +\infty\,. \]
Introducing the duality product
\begin{equation}
\label{dualiteSobolevPer}
\duality{u}{v}_{\mathbb{T}_{2\pi}} = \sum_{n \in \Z} \mathcal{F}u(n) \mathcal{F}v(-n)\,,
\end{equation}
$H^s$ is identified to the dual of $H^{-s}$ and $H^0 = L^2(\mathbb{T}_{2\pi})$. For $u,v \in  H^0$, $\duality{u}{v}_{\mathbb{T}_{2\pi}} = \frac{1}{2\pi} \int_{-\pi}^{\pi} uv$. The space $H^s$ is the direct sum $H^s_e + H^s_o$ where 
\[H^s_e \isdef \enstq{u \in H^s}{\mathcal{F}u(n) = \mathcal{F}u(-n)}\,,\]
\[H^s_o \isdef \enstq{u \in H^s}{\mathcal{F}u(n) = -\mathcal{F}u(-n)}\,.\]
Note that when $u$ is continuous, 
\[u \in H^s_e \iff \forall \theta \in \mathbb{T}_{2\pi}, \quad u(-\theta) = u(\theta)\,,\]
\[u \in H^s_o \iff \forall \theta \in \mathbb{T}_{2\pi}, \quad u(-\theta) = -u(\theta)\,.\] 
%For $s = 0$, we denote $L^2_e \isdef H^0_e$ and $L^2_o \isdef H^0_o$. 

\begin{Def}
	We define the operators $\mathcal{C} : T^{-\infty} \to H^{-\infty}_e$ by 
	\[\forall n \in \Z, \quad \mathcal{F}(\mathcal{C}u)(n) = \begin{cases}
	\hat{u}_0 & \text{ if } n = 0,\\
	\frac{\hat{u}_{\abs{n}}}{2} & \text{ otherwise}	\end{cases}\,\]
	and $\mathcal{S} : U^{-\infty} \to H^{-\infty}_o$ by 
	\[\forall n \in \Z, \quad \mathcal{F}(\mathcal{S}u)(n) = \begin{cases}
	0 & \text{ if } n = 0,\\
	\textup{sign}(n)\frac{\hat{u}_{\abs{n}-1}}{2} & \text{ otherwise.}	\end{cases}\,\]
\end{Def}
\begin{Lem}
	\label{FormuleDualitesCetS}
	The operators $\mathcal{C}$ and $\mathcal{S}$ map smooth functions to smooth functions. For all $(u,v) \in T^{-\infty} \times T^{\infty}$, 
	\[\duality{u}{v}_{\frac{1}{\omega}} = \duality{\mathcal{C}u}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}\,.\]
	For all $(u,v) \in U^{-\infty} \times U^{\infty}$,
	\[\duality{u}{v}_{{\omega}} = \duality{\mathcal{S}u}{\mathcal{S}v}_{\mathbb{T}_{2\pi}}\]
\end{Lem}
\begin{proof}
	The first assertion is obvious from the definition of $\mathcal{C}$ and $\mathcal{S}$. Let $(u,v) \in T^{-\infty}\times T^{\infty}$. By definition of $\duality{\cdot}{\cdot}_\frac{1}{\omega}$  and $\duality{\cdot}{\cdot}_{\mathbb{T}_{2\pi}}$ \cref{dualiteTs,dualiteSobolevPer},
	\[\begin{split}
	\duality{\mathcal{C}u}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}&= \sum_{n \in \Z}\mathcal{F}(\mathcal{C}u)(n)\mathcal{F}(\mathcal{C}v)(-n)\\ 
	&= \hat{u}_0 \hat{v}_0 + \sum_{n \in \Z, n \neq 0} \frac{\hat{u}_{\abs{n}}}{2}\frac{\hat{v}_{\abs{n}}}{2}\\
	&= \hat{u}_0 \hat{v}_0 + \frac{1}{2}\sum_{n = 1}^{+ \infty} \hat{u}_{n} \hat{v}_{n} \\
	&= \duality{u}{v}_\frac{1}{\omega}\,.
	\end{split}\,. \]
	The second identity is proved similarly.
\end{proof}
\begin{Lem}
	\label{lemChar}
	For all $s \in \R$, the operators $\mathcal{C}$ and $\mathcal{S}$ induce bijective isometries respectively from $T^s$ to $H^s_e$ and from $U^s$ to $H^s_o$. For $u \in \Cinf([-1,1])$, 
	\begin{equation}
		\mathcal{C}u(\theta) = u(\cos\theta)
		\quad \text{ and } \quad \mathcal{S}u(\theta) = \sin\theta u(\cos\theta)\,.
		\label{CS}
	\end{equation}
	Let $v,w \in \Cinf(\mathbb{T}_{2\pi})$, an even and an odd function respectively. Then
	\begin{equation}
	\label{C-1S-1}
		\mathcal{C}^{-1}v(x) = v(\arccos x) \quad \text{ and } \quad \mathcal{S}^{-1}w(x) = \frac{w(\arccos x)}{\omega(x)}\,.
	\end{equation}
\end{Lem}
\begin{proof}
	Let $J_s^T$, $J_s^U$ and $\tilde{J}_s$ the linear continuous mappings defined respectively on $T^{-\infty}$, $U^{-\infty}$ and $H^{-\infty}$ by
	\[J_s^TT_n = (1 + n^2)^\frac{s}{2} T_n, \quad J_s^UU_{n-1} = (1 + n^2)^{\frac{s}{2}} U_{n-1}, \quad \tilde{J}_s e_n = (1 + n^2)^\frac{s}{2} e_n.\]
	We recall that $e_n$ is the function $\theta \mapsto e^{in\theta}$. One can check easily that for $u \in T^s$ and $v \in U^s$
	\[\norm{u}_{T^s}^2 = \duality{J_s^Tu}{\overline{J_s^T u}}_\frac{1}{\omega}\quad \text{and}\quad \norm{v}_{U^s}^2 = \duality{J_s^U v}{\overline{J_s^U v}}_\omega,\]
	while for $w \in H^s$, 
	\[\norm{w}_{H^s}^2 = \norm{u}_{T^s}^2 = \duality{\tilde{J}_su}{\overline{\tilde{J}_s u}}_{\mathbb{T}_{2\pi}}\,.\]
	Moreover, the following identities hold:
	\[\mathcal{C} J_s^T = \tilde{J}_s \mathcal{C}, \quad \mathcal{S} J_s^U = \tilde{J}_s \mathcal{S}\,.\]
	The isometric property of $\mathcal{C}$ may now be deduced from \autoref{FormuleDualitesCetS} as follows. Let $u_N = \sum_{n = 0}^N u_n T_n$. There holds 
	\[\begin{split}
	\duality{J_s^T u}{\overline{J_s^T u_N}}_{\frac{1}{\omega}} &= \duality{\mathcal{C} J_s^T u}{\overline{\mathcal{C} J_s^T u_N}}_{\mathbb{T}_{2\pi}}\\
	& = \duality{\tilde{J}_s \mathcal{C} u}{\overline{\tilde{J}_s \mathcal{C} u_N}}_{\mathbb{T}_{2\pi}}\,.
	\end{split}\] 
	Sending $N$ to infinity, by continuity of $J_s^T$, $\tilde{J}^s$ and $\mathcal{C}$, this yields
	\[\norm{u}_{T^s}^2 = \norm{\mathcal{C}u}_{H^s}^2\,.\]
	The isometric property of $\mathcal{S}$ is establish in a similar manner. Let us now prove \eqref{CS}. For the first identity, consider some smooth function $u$ on $[-1,1]$. Since $\mathcal{C}u$ is smooth, the Fourier series of $\mathcal{C}u$ converges pointwise to $\mathcal{C}u$. Thus, for all $\theta \in \mathbb{T}_{2\pi}$,
	\[\begin{split}
	\mathcal{C}u(\theta) &= \sum_{n \in \Z} \mathcal{F}(\mathcal{C}u)(n)e^{in\theta}\\
	&= \hat{u}_0 + \sum_{n \in \Z, n\neq 0} \frac{\hat{u}_{\abs{n}}}{2} e^{in\theta}\\
	&= \hat{u}_0 + \frac{1}{2}\sum_{n = 1}^{+\infty} \hat{u}_n \left(e^{in\theta} + e^{-in\theta} \right)\\
	& = \sum_{n = 0}^{+ \infty} \hat{u}_n \cos(n \theta)\\
	& = \sum_{n = 0}^{+ \infty} \hat{u}_n T_n(\cos\theta)
	\end{split}\]
	The last sum also converges pointwise to $u(\cos\theta)$ since $u \in T^\infty$. Similar calculations show that $\mathcal{S}u(\theta) = \sin\theta u(\cos\theta)$, using this time \[\sin((n+1)\theta) = \sin\theta U_n(\cos\theta)\,.\] 
	To prove the bijectivity of $\mathcal{S}$ and $\mathcal{C}$, one can check that they have the  explicit inverses $\mathcal{C}^{-1}$ and $\mathcal{S}^{-1}$ respectively defined on $H^s_e$ and $H^s_o$ as
	\[\forall n \in \N, \quad \widehat{(\mathcal{C}^{-1}u)}_n = \begin{cases}
	\mathcal{F}u(0) & \text{ if } n = 0,\\
	2\mathcal{F}u(n) & \text{ otherwise}	\end{cases}\,\]
	and
	\[\forall n \in \N, \quad \widehat{(\mathcal{S}^{-1}u)}_n = 2\mathcal{F}u(n+1)\,.\]
	Finally, identities \eqref{C-1S-1} are simply deduced by inverting \eqref{CS}. 
\end{proof}

	
\subsection{Generalization to a curve}

\label{TsUs(Gamma)}

\subsubsection*{Parametrization of the curve}
	We start by introducing some notation that will be extensively used throughout all the remainder of this work. Let $\Gamma$ a smooth open curve in $\mathbb{R}^2$ parametrized by a smooth $C^\infty$ diffeomorphism $r : [-1,1] \to \Gamma$. We assume that $\abs{r'(x)} = \frac{\abs{\Gamma}}{2}$ for all $x\in [-1,1]$, where $\abs{\Gamma}$ is the length of $\Gamma$. This parametrization is related to the curvilinear abscissa $M(s)$ through
\[r(x) = M\left( \frac{\abs{\Gamma}}{2}(1+x)\right)\,.\]
Let $\opFromTo{R}{\Cinf(\Gamma)}{\Cinf(-1,1)}$ defined by 
\[Ru(x) = u(r(x))\,.\]
The tangent and normal vectors on the curve, $\tau$ and $n$, are respectively defined by 
\[\tau(x) = \frac{\partial_x r(x)}{\abs{\partial_x r(x)}}, \quad n(x) = \frac{\partial_x \tau(x)}{\abs{\partial_x \tau'(x)}}\,.\]
Let $N : \Gamma \to \R^2$ such that $N(r(x)) = n(x)$, that is, $N = R^{-1} n$. Let $\kappa(x)$ the signed curvature of $\Gamma$ at the point $r(x)$. Frenet-Serret's formulas give
\begin{eqnarray*}r(y) & = & r(x) + (y-x) \frac{\abs{\Gamma}}{2} \tau(x) + \frac{(y-x)^2}{2} \frac{\abs{\Gamma}^2}{4} \kappa(x) n(x)\\ 
 && +\frac{(x-y)^3}{6} \frac{\abs{\Gamma}^3}{8} (\kappa'(x) n(x) - \kappa(x)^2 \tau(x)) + O\left((x-y)^4\right)\,,
\end{eqnarray*}
so that
\begin{equation}
\abs{r(x) - r(y)}^2 = \frac{\abs{\Gamma}^2}{4}(y-x)^2 - \frac{(y-x)^4}{192}\abs{\Gamma}^4 \kappa(x)^2 + O(x-y)^5\,. 
\label{expansion_r}
\end{equation}
For $u,v \in L^2(\Gamma)$, we have by change of variables in the integral
\[\duality{u}{v}_{L^2(\Gamma)} = \frac{\abs{\Gamma}}{2}\duality{Ru}{Rv}_{L^2(-1,1)} \,.\]
The tangential derivative $\partial_\tau$ on $\Gamma$ satisfies 
\begin{equation}
	\partial_\tau = \frac{2}{\abs{\Gamma}}R^{-1}\partial_x R\,.
	\label{param1}
\end{equation}
Moreover, we define 
\begin{equation}
	\omega_\Gamma \isdef \frac{\abs{\Gamma}}{2} R^{-1}  \omega R
	\label{param2}
\end{equation}
the "weight" on the curve $\Gamma$. Finally, the uniform measure on $\Gamma$ is denoted by $d\sigma$.

\subsubsection*{Spaces $T^s(\Gamma)$ and $U^s(\Gamma)$}

The definition of the spaces $T^s$ can be transported on the curve $\Gamma$, replacing the basis $(T_n)$ and $(U_n)$ by $(R^{-1}T_n)$ and $(R^{-1}U_n)$. The spaces $T^s(\Gamma)$ and $U^s(\Gamma)$ are thus defined as the sets of formal series respectively of the form 
\[u = \sum_{n \in \N} \hat{u}_n R^{-1}T_n\,, \quad v = \sum_{n \in \N} \check{v}_n R^{-1}T_n\,,\]
where $Ru = \sum\hat{u}_n T_n \in T^s$ and $Rv = \sum\check{v}_n U_n  \in U^s$. To $u$ and $v$ are associated the linear forms 
\[\forall \varphi \in \Cinf(\overline{\Gamma}), \quad \duality{u}{\varphi}_\frac{1}{\omega_\Gamma} \isdef \duality{Ru}{R\varphi}_\frac{1}{\omega}\,,\]
\[\forall \varphi \in \Cinf(\overline{\Gamma}), \quad \duality{v}{\varphi}_{\omega_\Gamma} \isdef \frac{\abs{\Gamma}^2}{4}\duality{Rv}{R\varphi}_{\omega}\,.\] 

 
\noindent From the results of the previous section we deduce
\begin{Lem} For all $s \in \R$, $T^s(\Gamma)$ and $U^s(\Gamma)$ are Hilbert spaces for the scalar products 
\[\inner{u}{v}_{T^s(\Gamma)} = \inner{Ru}{Rv}_{T^s}\,,\]
\[\inner{u}{v}_{U^s(\Gamma)} = \frac{\abs{\Gamma}^2}{2}\inner{Ru}{Rv}_{U^s}\,.\]
With these definitions, 
\[\inner{u}{v}_{T^0(\Gamma)} = \duality{u}{\overline{v}}_\frac{1}{\omega_\Gamma} = \int_{\Gamma} \frac{u(x) \overline{v(x)}}{ \omega_\Gamma(x)} dx\,,\]
\[\inner{u}{v}_{U^0(\Gamma)} = \duality{u}{\overline{v}}_{\omega_\Gamma}  = \int_{\Gamma} \omega_\Gamma(x) u(x) \overline{v(x)} dx\,.\]
In particular $T^0(\Gamma) = L^2_\frac{1}{\omega_\Gamma}$ and $U^0(\Gamma) = L^2_{\omega_\Gamma}$. For $s \in \R$, the dual of $T^s(\Gamma)$ is the set of linear forms $\duality{u}{\cdot}_\frac{1}{\omega_\Gamma}$ where $u\in T^{-s}(\Gamma)$, and the dual of $U^s(\Gamma)$ is the set of linear forms $\duality{u}{\cdot}_{\omega_\Gamma}$ where $u \in U^{-s}(\Gamma)$. 
For $s < t$, the injections $T^t(\Gamma) \subset T^s(\Gamma)$ and $U^t(\Gamma) \subset U^s(\Gamma)$ are compact. $(T^s(\Gamma))_{s\in \R}$ and $(U^s(\Gamma))_{s\in \R}$ are two Hilbert interpolation scales. For an integer $n$, equivalent scalar products on $T^n$ and $U^n$ are given respectively by
\[(u,v) \mapsto \int_{\Gamma} \frac{u(x)\overline{v(x)} + (\omega_\Gamma \partial_\tau)^n u(x) (\omega_\Gamma \partial_\tau)^n \overline{v(x)}}{\omega_\Gamma(x)}d\sigma(x)\,,\]
\[(u,v) \mapsto \int_{\Gamma}(\partial_\tau\omega_\Gamma )^n u(x) (\partial_\tau\omega_\Gamma \partial)^n \overline{v(x)}\omega_\Gamma(x)d\sigma(x)\,,\]
For all $s \in \R$, $T^s(\Gamma) \subset U^s(\Gamma)$ and for all $s > \frac{1}{2}$, $U^s(\Gamma) \subset T^{s-1}(\Gamma)$ with continuous inclusions, as well as for $\varepsilon > 0$, $T^{1/2 + \varepsilon}(\Gamma) \subset C^0(\Gamma)$ and $U^{3/2+\varepsilon} \subset C^0(\Gamma)$. Moreover, $T^\infty(\Gamma) = U^\infty(\Gamma) = C^\infty(\overline{\Gamma})$. 
\end{Lem}


\section{Application to Galerkin analysis}

In this section, we introduce the notations for the first-kind integral equations under consideration. We then apply the theory of the first section to this problem in the case of a zero wavenumber and flat geometry. 

\subsection{First-kind integral equations}

Recall the definition and parametrization of the curve $\Gamma$ detailed in section \ref{TsUs(Gamma)}. We consider the following boundary integral equations (BIEs)
\begin{equation}
	\label{BIEs}
	S_{k} \lambda = u_D, \quad N_k \mu = u_N
\end{equation}
where $S_k$ and $N_k$ are respectively the single-layer and hypersingular operators. We refer the reader to \cite{alouges2018new} and references therein for more details on the classical connection between eqs. \eqref{BIEs} and the problem of wave scattering by the curve $\Gamma$. The operators $S_k$ and $N_k$ admit the integral representations
\begin{equation}
\begin{split}
\quad (S_k \lambda)(x) &= \int_{\Gamma} G_k(x-y) \lambda(y) d\sigma(y)\,,\\ 
(N_k \mu) (x) &= \lim_{\varepsilon \to 0^+} \int_{\Gamma} N(y) \cdot \nabla G_k(x + \varepsilon N(x) - y) \mu(y) d\sigma_y.
\end{split}
\label{defNk}
\end{equation}
for $x \in \Gamma$, with the Green function $G_k$  defined by
\begin{equation}
\left\{
\begin{aligned}
G_0(z) &= -\dfrac{1}{2\pi} \ln \abs{z}, && \text{ if } k= 0,\\
G_k(z) &= \frac{i}{4}H_0(k|z|), && \text{ if } k > 0,
\end{aligned} 
\right.
\end{equation} 
where $H_0$ is the Hankel function of the first kind. It is known that $S_k$ maps continuously $\tilde{H}^{-1/2}(\Gamma)$ to $H^{1/2}(\Gamma)$ \cite[Theorem 1.8]{wendland1990hypersingular} and $N_k$ maps continuously $\tilde{H}^{1/2}(\Gamma)$ to $H^{-1/2}(\Gamma)$ \cite[Theorem 1.4]{wendland1990hypersingular}. In the case $k=0$, the Helmholtz scattering reduces to the Laplace problem. The kernel of the hypersingular operator has a non-integrable singularity, but computations are facilitated by the following formula, valid for smooth functions 
$\mu$ and $\nu$ that vanish at the extremities of $\Gamma$: 
\begin{eqnarray}
\label{NkenfonctiondeSk}
\duality{N_k \mu}{\nu} &=& \int_{\Gamma\times \Gamma} G_k(x-y) \mu'(x) \nu'(y) \nonumber\\
&& \quad - k^2 G_k(x,y) \mu(x) \nu(y) n(x) \cdot n(y) d\sigma_x d\sigma_y\,.
\end{eqnarray}
For the geometry under consideration, the solutions $\lambda$ and $\mu$ of the BIEs \eqref{BIEs} have singularities (even for $\Cinf$ data $u_D$ and $u_N$) due to the presence of edges on the scatterer. It is now classical to introduce weighted versions of the usual layer potentials, known to enjoy better mapping properties than $S_k$ and $N_k$. Namely, we define
\begin{equation}
\label{weightedBIOs}
S_{k,\omega_\Gamma} \isdef S_k \frac{1}{\omega_\Gamma}\,,\quad N_{k,\omega_\Gamma} \isdef N_k \omega_\Gamma\,,
\end{equation}
and recast the BIEs \eqref{BIEs} as 
\begin{equation}
\label{weightedBIEs}
S_{k,\omega_\Gamma}\alpha = u_D\,, \quad N_{k,\omega_\Gamma}\beta = u_N\,.
\end{equation}
where the unknowns $\alpha$ and $\beta$ are related to $\lambda$ and $\mu$ by 
\[\lambda = \frac{\alpha}{\omega_\Gamma}, \quad \mu = \omega_\Gamma \beta\,.\]
The relation between $N_k$ and $S_k$ can be rewritten in terms of $N_{k,\omega_\Gamma}$ and $S_{k,\omega_\Gamma}$:
\begin{Lem}
	\label{NkomegaSkomega}
	There holds 
	\[N_{k,\omega_\Gamma} = -\partial_\tau S_{k,\omega_\Gamma} \omega_\Gamma \partial_\tau \omega_\Gamma - k^2 V_k \omega_\Gamma^2\]
	where $V_k$ is the integral operator defined by 
	\[V_k u = \int_{\Gamma} \frac{G_k(x - y) N(x) \cdot N(y) u(y)}{\omega_\Gamma(y)} d\sigma(y)\,. \]
\end{Lem}
\begin{proof}
	Eq. \eqref{NkenfonctiondeSk} can be rewritten equivalently as 
	\[N_k u = -\partial_\tau S_k \partial_\tau u - k^2 \int_{\Gamma} G_k(x - y) N(x) \cdot N(y) u(y) d\sigma(y)\,. \]
	Using the definitions of $N_{k,\omega_\Gamma}$ and $S_{k,\omega_\Gamma}$, the results follow from simple manipulations on this expression. 
\end{proof}

\subsection{Weighted layer potentials on the flat segment}

In this section, we consider the case where the wavenumber $k$ is equal to $0$ and $\Gamma = [-1,1]\times{\{0\}}$. The parametrization $r$ is then the constant function equal to $1$, $\partial_\tau = \partial_x$ and $\omega_\Gamma = \omega$. In this simple context, the weighted potentials are thus denoted by $S_{0,\omega}$ and $N_{0,\omega}$. They have elementary properties that allow us to characterize $T^{s}$ and $U^s$ for $s = \pm \frac{1}{2}$. 

\paragraph{Single layer potential.} The operator $S_{0,\omega}$ takes the form 
\[S_{0,\omega} \alpha(x) = \int_{-1}^{1} \frac{\ln \abs{x - y} \alpha(y)}{\sqrt{1 - y^2}}dy \,.\]
There holds 
\begin{equation}
\label{explicitEigs}
S_{0,\omega} T_n = \sigma_n T_n
\end{equation}
where 
\[\sigma_n = \begin{cases}
\dfrac{\ln(2)}{2} & \text{if } n=0\\
\dfrac{1}{2n} & \text{otherwise}.
\end{cases}\]
Those identities are fundamental in our analysis. A proof can be found in \cite[Theorem 9.2]{mason2002chebyshev}. We deduce easily
\begin{Lem}
	The operator $S_{0,\omega}$ is a positive bicontinuous bijection from $T^s$ to $T^{s+1}$ for all $s \in \R$. 
	\label{SomegaMapProp}
\end{Lem}
In particular, $S_{0,\omega}$ maps $T^{\infty}$ to itself, so the image of a smooth function by $S_{0,\omega}$ is a smooth function. We now proceed to show the following characterization of $T^{-1/2}$ and $T^{1/2}$. The next result, and \autoref{LemU12} stated below are equivalent to results formulated in \cite{jerez2012explicit} (see equations (4.77-4.86), and Propositions 3.1 and 3.3 therein).
\begin{Lem}
	\label{LemmaT-1/2}
	We have $T^{-1/2} = \omega\tilde{H}^{-1/2}(-1,1)$ and for all $u \in \tilde{H}^{-1/2}(-1,1)$,
	\[\norm{u}_{\tilde{H}^{-1/2}} \sim \norm{\omega u}_{T^{-1/2}}.\] 
	Moreover, $T^{1/2} = H^{1/2}(-1,1)$ and 
	\[\norm{u}_{H^{1/2}} = \norm{u}_{T^{1/2}}\]
\end{Lem}
\begin{proof}
	Since the logarithmic capacity of the segment is $\frac{1}{4}$, the (unweighted) single-layer operator $S_0$ is positive and bounded from below on $\tilde{H}^{-1/2}(-1,1)$, (see \cite{mclean2000strongly} chap. 8). Therefore the norm on $\tilde{H}^{-1/2}(-1,1)$ is equivalent to 
	\[\norm{u}_{\tilde{H}^{-1/2}} \sim \sqrt{\duality{S_0u}{u}}.\]
	On the other hand, the explicit expression \eqref{explicitEigs} imply that if $\alpha\in T^{-1/2}$
	\[ \norm{\alpha}_{T^{-1/2}} \sim \sqrt{\duality{S_{0,\omega} \alpha}{\alpha}_\frac{1}{\omega}}.\]
	It remains to notice that, since $\alpha=\omega u$, $\duality{S_{0,\omega} \alpha}{\alpha}_\frac{1}{\omega} = \duality{S_0u}{u}$. This proves the first result. For the second result, we know that, $(H^{1/2}(-1,1))' =  \tilde{H}^{-1/2}(-1,1)$ (taking the identification with respect to the usual $L^2$ duality denoted by $\duality{\cdot}{\cdot}$, \cite{mclean1986spectral} chap. 3), and therefore
	\[\norm{u}_{H^{\frac{1}{2}}} = \sup_{ v\neq 0} \dfrac{\duality{u}{v}}{\norm{v}_{\tilde{H}^{-\frac{1}{2}}}}\,.\]
	According to the previous result, for all $v\in \tilde{H}^{-\frac{1}{2}}$, the function $\alpha = \omega v$ is in $T^{-1/2}$, and $\norm{ v}_{\tilde{H}^{-1/2}} \sim \norm{\alpha}_{T^{-1/2}}$, while $\duality{u}{v} = \duality{u}{\alpha}_\omega$. Thus 
	\[\norm{u}_{H^{1/2}} \sim \sup_{\alpha \neq 0} \dfrac{\duality{u}{\alpha}_\frac{1}{\omega}}{\norm{\alpha}_{T^{-1/2}}}\]
	The last quantity is the $T^{1/2}$ norm of $u$ since $T^{1/2}$ is identified to the dual of $T^{-1/2}$ for $\duality{\cdot}{\cdot}_\frac{1}{\omega}$, showing the result. 
\end{proof}


\paragraph{Hypersingular operator.}For $k = 0$ and when $\Gamma = [-1,1]\times \{0\}$, the identity \eqref{NkomegaSkomega} takes the form
\[\duality{N_{0,\omega} \beta}{\beta'}_\omega = \duality{S_{0,\omega}  (\omega \partial_x \omega) \beta}{ (\omega \partial_x \omega) \beta'}_\frac{1}{\omega}\,.\] 
Noticing that $(\omega \partial_x \omega) U_n = -(n+1) T_{n+1}$, we have, for all $n \neq m$,
\[\duality{N_{0,\omega }U_n}{U_m}_\omega = 0 \,.\]
Therefore, we have 
\[N_{0,\omega} U_n = \nu_n U_n\] 
with 
$\nu_n\norm{U_n}_{\omega}^2 = (n+1)^2 \sigma_{n+1} \norm{T_{n+1}}_\frac{1}{\omega}^2,$
that is, $\nu_n = \frac{(n+1)}{2}$.
We deduce 
\begin{Lem}
	The operator $N_{0,\omega}$ is a positive bicontinuous bijection from $U^s$ to $U^{s-1}$ for all $s \in \R$.
	\label{NomegaMapProp}
\end{Lem} 
\noindent In particular, $N_{0,\omega}$ maps smooth functions to smooth functions. 
As before, we obtain a characterization of $U^{s}$ for $s = \pm \frac{1}{2}$ from the previous formula.
\begin{Lem} 
	\label{LemU12}	
	We have $U^{1/2} =  \frac{1}{\omega} \tilde{H}^{1/2}(-1,1)$ and for all $u\in \tilde{H}^{1/2}(-1,1)$,
	\[\norm{u}_{\tilde{H}^{1/2}} \sim \norm{\frac{u}{\omega}}_{U^{1/2}}\,.\]
	Moreover, $U^{-1/2} = H^{1/2}(-1,1)$ and 
	\[\norm{u}_{H^{1/2}} = \norm{u}_{U^{1/2}}\,.\]
\end{Lem}

\subsection{Galerkin method}

\label{subsec:GalerkineSetting}
A Galerkin method based on a refined mesh and weighted $L^2$ scalar products is described in \cite{alouges2018new} to solve eqs. (\ref{weightedBIEs}) and orders of convergences are announced for the Laplace problem ($k = 0$) when $\Gamma = [-1,1] \times\{0\}$. In this section we provide the proofs for those statements. 
Let us consider the following discretization of the segment $[-1,1]$
\[-1 = x_0 < x_1 < \cdots < x_N = 1\]
where $x_i = \cos(i \frac{\pi}{N})$.  

\subsection{Dirichlet problem}

 Let $V_h$ the Galerkin space of (discontinuous) piecewise affine functions 
 on the mesh $(x_i)_{0\leq i \leq N}$ defined above, and $\alpha_h$ the unique solution in $V_h$ to the variational problem
 \begin{equation}
 \label{varProb}
 \inner{S_{0,\omega} \alpha_h}{\alpha_h'}_\frac{1}{\omega} = \inner{u_D}{\alpha_h'}_\frac{1}{\omega}, \quad \forall \alpha_h' \in V_h\,.
 \end{equation}
 Let $\lambda_h = \frac{\alpha_h}{\omega}$. We also write $\alpha_0 \isdef \omega \lambda$. 
 \begin{theorem}
 	If the data $u_D$ is in $T^{s+1}$ for some $-\frac{1}{2} \leq s \leq 2$, then there holds:
 	\[ \norm{\lambda - \lambda_h}_{\tilde{H}^{-1/2}} \leq C h^{s+1/2} \norm{\omega \lambda}_{T^{s}}\leq C h^{s+1/2} \norm{u_D}_{T^{s+1}}.\]
 	\label{theOrdreCVDirichlet}
 \end{theorem}
 Note that since $\mathcal{C} S_0 = S_{0,\omega} \mathcal{C}$, which is proved using the change of variables $\theta = \arccos(x)$, the variational problem \eqref{varProb} is equivalent, by \autoref{lemChar}, to 
 \begin{equation*}
 	\inner{S_{0}\varphi_h}{\varphi_h'}_{\mathbb{T}_{2\pi}} = \inner{\mathcal{C}u_D}{\varphi_h'}_{\mathbb{T}_{2\pi}}\,, \quad  \forall \alpha_h' \in \mathcal{C}V_h\,,
 \end{equation*}
where $\varphi_h = \mathcal{C}\alpha_h$ and $\inner{u}{v}_{\mathbb{T}_{2\pi}} = \int_{-\pi}^{\pi} u(\theta) \overline{v(\theta)}dx$ is the usual $L^2$ scalar product on $\mathbb{T}_{2\pi}$. If instead of affine functions, $V_h$ would contain affine functions of $\arccos(x)$, then $\varphi_h$ and the test functions $\varphi_h'$ would be piecewise affine (discontinuous) functions of $\theta$. The standard Galerkin theory then gives
\[\norm{\varphi_h - \varphi}_{H^{-1/2}} \leq Ch^{s + \frac{1}{2}}\norm{\mathcal{C}u_D}_{H^s}\,,\]
where $\varphi = \mathcal{C}\alpha$.   
This implies \autoref{theOrdreCVDirichlet} since
$\norm{\mathcal{C}u_D}_{H^s} = \norm{u_D}_{T^s}$ and \[{\norm{\lambda - \lambda_h}_{\tilde{H}^{-1/2}} = \norm{\varphi - \varphi_h}_{H^{-1/2}}}\,.\] 
Here instead, $\varphi'_h$ are piecewise affine functions of $\cos\theta$ and to the best knowledge of the author, no approximation theory is available for this kind of basis functions in $H^s_e$. This is the main difficulty in the proof of \autoref{theOrdreCVDirichlet}. 
\begin{proof}
Let us denote by $\Pi_h$ the operator that maps a function $\alpha \in T^{-1/2}$ to the element $\alpha_h \in V_h$ such that 
\[\inner{S_{0,\omega}\alpha_h}{\alpha_h'}_{\frac{1}{\omega}} = \inner{S_{0,\omega} \alpha}{\alpha_h'}_\frac{1}{\omega} \quad \forall \beta_h' \in W_h\,.\]	
Since $S_{0,\omega}$ is coercive in $T^{-1/2}$ by \autoref{SomegaMapProp}, we have an analog of Céa's lemma in our context: 
\begin{equation}
\forall \alpha \in T^{-1/2},\quad \norm{\alpha - \Pi_h \alpha}_{T^{-1/2}} \leq C \inf_{\alpha_h' \in V_h } \norm{\alpha - \alpha'_h}_{T^{-1/2}}\,.
\label{CeaAnalog}
\end{equation}
From this we deduce, taking $\alpha_h' = 0$ in the infimum 
\[\forall \alpha \in T^{-1/2}\quad \norm{(I_d - \Pi_h)\alpha}_{T^{-1/2}} \leq C \norm{\alpha}_{T^{-1/2}}\,.\]
In addition, we are going to show 
\begin{equation}
	\forall \alpha \in T^{2}, \quad \norm{(I_d - \Pi_h)\alpha}_{T^{-1/2}} \leq C h^{5/2} \norm{\alpha}_{T^{2}}\,.
	\label{estimT2}
\end{equation}
By interpolation, this implies for all $s \in \left[-\frac{1}{2},2\right]$
\[\forall \alpha \in T^s\,, \quad  \norm{(I_d - \Pi_h) \alpha}_{T^{-1/2}} \leq C h^{s + 1/2} \norm{\alpha}_{T^s}\,.\]
The result then follows from this, since, on the one hand
\[\norm{\lambda - \lambda_h}_{\tilde{H}^{-1/2}} \leq C \norm{\alpha_0 - \alpha_h}_{T^{-1/2}}\]
by \autoref{LemmaT-1/2}, with $\alpha_h = \Pi_h \alpha_0$ and, on the other hand, $\omega u = \alpha_0 = S_{0,\omega}^{-1} u_D$ which by \autoref{SomegaMapProp}, gives
\[\norm{\alpha_0}_{T^s} \leq C\norm{u_D}_{T^{s+1}}.\]
As it is classical with piecewise affine discontinuous basis functions, we prove \eqref{estimT2} by studying the properties of two particular operators: the $L^2_\frac{1}{\omega}$ orthonormal projection $\mathbbm{P}_h$ on $V_h$ and the interpolation operator $I_h$ which maps a continuous function $\alpha$ to the (continuous) function  of $V_h$ that matches $\alpha$ at the breakpoints $x_i$. Because of Céa's lemma, we have 
\[\forall \alpha \in T^{-1/2}, \quad \norm{(I_d - \Pi_h) \alpha}_{T^{-1/2}} \leq C \norm{(I_d - \mathbbm{P}_h) \alpha}_{T^{-1/2}} \,.\]
Therefore, it suffices to show \eqref{estimT2} where $\Pi_h$ is replaced by $\mathbbm{P}_h$ to establish the theorem. We shall first show that 
\begin{equation}
	\forall \alpha \in T^s, \quad \norm{(I_d - \mathbbm{P}_h)\alpha} \leq Ch^s \norm{\alpha}_{T^s}
	\label{WeshallFirstShow}
\end{equation}
for $s \in [0,2]$. The estimate in $T^{-1/2}$ norm is then deduced by the classical duality method:
\[\norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} = \inf_{\eta \in T^{1/2}, \eta \neq 0} \dfrac{(\alpha - \mathbbm{P}_h \alpha,\eta)_{\frac{1}{\omega}}}{\norm{\eta}_{T^{1/2}}}\,,\]
and since $\mathbbm{P}_h$ is an orthonormal projection on $L^2_\frac{1}{\omega}$, 
\[\norm{\alpha - \mathbbm{P}_h \alpha}_{T^{-1/2}} = \inf_{\eta \in T^{1/2}, \eta \neq 0} \dfrac{(\alpha - \mathbbm{P}_N \alpha,\eta -\mathbbm{P}_h \eta )_{\frac{1}{\omega}}}{\norm{\eta}_{T^{1/2}}}.\]
This, by Cauchy-Schwarz equality and \eqref{WeshallFirstShow}, gives 
\[\forall \alpha \in T^2, \quad \norm{\alpha- \mathbbm{P}_h\alpha}_{T^{-1/2}} \leq Ch^2 \norm{\alpha}_{T^2}\inf_{\eta \in T^{1/2}, \eta \neq 0}  \frac{h^{1/2} \norm{\eta}_{T^{1/2}}}{\norm{\eta}_{T^{1/2}}}\,,\] 
implying the desired etimate. The proof of \eqref{WeshallFirstShow} also follows the classical steps. First, it is obvious that 
\[\forall \alpha \in L^2_\frac{1}{\omega}, \quad \norm{(I_d - \mathbbm{P}_h)\alpha}_{L^2_\frac{1}{\omega}} \leq C \norm{\alpha}_{L^2_\frac{1}{\omega}}\,,\]
as $\mathbb{P}_h$ is an orthonormal projection on $L^2_\frac{1}{\omega}$. Using again an interpolation argument, it is sufficient to show
\begin{equation}
	\forall \alpha \in T^2, \quad \norm{(I_d - \mathbbm{P}_h)\alpha}_{L^2_\frac{1}{\omega}} \leq C h^2 \norm{\alpha}_{T^2}\,.
	\label{WeOnlyNeedToShow}
\end{equation}
To this aim, we establish the following estimate:
\begin{equation}
	\forall \alpha \in T^2, \quad \norm{(I_d - I_h)\alpha}_{L^2_\frac{1}{\omega}} \leq C h^2 \norm{\alpha}_{T^2}\,,
	\label{ToThisAim}
\end{equation}
and conclude with $\norm{(I_d - \mathbbm{P}_h)\alpha}_{L^2_\frac{1}{\omega}} \leq \norm{(I_d - I_h)\alpha}_{L^2_\frac{1}{\omega}}$ since $\mathbbm{P}_h$ minimizes the $L^2_\frac{1}{\omega}$ error. Any function $\alpha \in T^2$ is continuous by \autoref{LemInjectionsContinues}, thus $I_h \alpha$ is well-defined. To prove \eqref{ToThisAim}, let us fix $\alpha \in T^2$ and $i \in [0,N-1]$.
The function $\mathcal{C}\alpha$ belongs to $H^2$ by \autoref{lemChar} and thus its restriction on $[\theta_i,\theta_{i+1}]$ belongs to $H^2(\theta_{i},\theta_{i+1})$. The function $I_h\alpha$ being $C^{\infty}$ on $[x_i,x_{i+1}]$, the restriction of $\mathcal{C}I_h\alpha$ to $[\theta_i,\theta_{i+1}]$ also belongs to $H^2(\theta_i,\theta_{i+1})$. Moreover, $\mathcal{C}(I_h - I_d)\alpha$ vanishes on $\theta_i$ and $\theta_{i+1}$, and it is well-known that for a function $v$ in $H^2(a,b)$ which vanishes on $a$ and $b$, there holds 
\begin{equation}
	\int_{a}^b \abs{v(\theta)}^2d\theta \leq C (b-a)^4\int_{a}^b \abs{\partial_{\theta \theta} v(\theta)}^2 d\theta\,.
	\label{H2nulleaubord}
\end{equation}
	Thus, applying this result on $[\theta_i,\theta_{i+1}]$ to $v = (\mathcal{C}(I_d - I_h)u)_{|[\theta_i,\theta_{i+1}]}$ and summing those inequalities for $i = 0$ to $N-1$, we obtain
	\[\int_{0}^{\pi} \abs{\mathcal{C}(I_d - I_h)\alpha(\theta)}^2 d\theta \leq h^4\int_{0}^{\pi} \abs{\partial_{\theta\theta}\mathcal{C}(I_d - I_h)\alpha(\theta) }^2\,,\]
	in other words $\norm{\mathcal{C}(I_d - I_h)\alpha(\theta)}_{\mathbb{T}_{2\pi}} \leq Ch^2 \abs{\mathcal{C}(I_d - I_h)\alpha(\theta)}_{H^2_e}.$
	This, by \autoref{lemChar}, implies 
	\begin{equation}
		\norm{(I_d - I_h)\alpha}_{\frac{1}{\omega}} \leq Ch^2 \abs{(I_d - I_h)\alpha}_{T^2}\,.
		\label{ThisImplies}
	\end{equation}
	If $\mathcal{C}I_h \alpha$ were affine, the proof would end here since in this case $\abs{I_h \alpha}_{T^2} = \abs{\mathcal{C}I_h \alpha}_{H^2} = 0$. This does not hold in our case and this is the main difference with the standard proof. Nevertheless, if we show that 
	\[\abs{I_h \alpha}_{T^2} \leq C \norm{\alpha}_{T^2}\,,\]
 	then eq. \eqref{ToThisAim} follows from eq. \eqref{ThisImplies} by triangular inequality. The expression of $\mathcal{C}I_h \alpha$ on $[\theta_{i},\theta_{i+1}]$ is given by 
	\[\mathcal{C}{I_h \alpha}(\theta) = \alpha(x_i) + \frac{\alpha(x_i) - \alpha(x_{i+1})}{\cos(\theta_{i+1}) - \cos(\theta_i)} (\cos(\theta) - \cos(\theta_i)),\]
	thus
	\[\int_{\theta_i}^{\theta_{i+1}} \abs{\partial_{\theta\theta}\mathcal{C}{I_h\alpha}}^2 = \abs{\frac{\alpha(x_i) - \alpha(x_{i+1})}{\cos(\theta_{i+1}) - \cos(\theta_i)}}^2 \int_{\theta_i}^{\theta_{i+1}} \cos(\theta)^2 d\theta.\]
	We can rewrite 
	\[\abs{\alpha(x_{i+1}) - \alpha(x_i)}^2 = \abs{ \int_{x_i}^{x_{i+1}} \partial_x\alpha(x)dx}^2,\]
	and apply Cauchy-Schwarz's inequality and the variable change $t = \cos(\theta)$ to find 
	\[\abs{\alpha(x_{i+1}) - \alpha(x_i)}^2 \leq \int_{x_i}^{x_{i+1}} \frac{\abs{\partial_x \alpha(x)}^2}{\omega(x)} dx\int_{\theta_i}^{\theta_{i+1}} \sin(\theta)^2 d\theta.\]
	Notice that the quantity
	\[\frac{ \int_{\theta_i}^{\theta_{i+1}} \cos(\theta)^2\int_{\theta_i}^{\theta_{i+1}} \sin(\theta)^2}{(\cos(\theta_{i+1}) - \cos(\theta_i))^2}\]
	is bounded uniformly in $(\theta_i, \theta_{i+1})$. Indeed, since $\cos$ is injective on $[0,\pi]$, the only problematic case is the limit when $\theta_i = \theta_{i+1}$. It is easy to check that this limit is $\cos(\theta_i)^2$, which is indeed uniformly bounded in $\theta_i$. We deduce 
	\[ \int_{0}^{\pi} \abs{\partial_{\theta\theta}\mathcal{C}{I_h\alpha}}^2 \leq C \norm{\partial_x \alpha}^2_\frac{1}{\omega}\,,\]
	that is $\abs{I_h \alpha}_{T^2} \leq C \norm{\partial_x \alpha}_{\frac{1}{\omega}}$. By \autoref{corDxT2T0}, one has $\norm{\partial_x \alpha}_{\frac{1}{\omega}} \leq C \norm{\alpha}_{T^2}$, thus \eqref{ToThisAim} is established, concluding the proof.	
	\end{proof} 
	\begin{Cor}
		For all $(s,t) \in [-\frac{1}{2}, 2]$, if $\alpha_0\in T^t$, then
		\[\norm{\alpha_0 - \alpha_h}_{T^s} \leq C h^{t - s} \norm{\alpha_0}_{T^t}\,. \]
	\end{Cor}
	\begin{proof}
		Let us first establish the inverse estimate
		\[\forall \alpha'_h \in V_h, \, \quad  \forall s \in \N, \quad  \norm{\alpha'_h}_{T^s} \leq C h^{- s} \norm{\alpha'_h}_{\frac{1}{\omega}}\,.\]
		For this, we fix a function $\alpha'_h$ in $V_h$ and restrict our attention on a fixed segment $[x_i,x_{i+1}]$. Let us first assume that $s$ is an integer. Let $u_h(u) = \mathcal{C}\alpha'_h(\theta_i + u h)$ defined on $[0,1]$. Notice that 
		\[\partial_u^k u_h(u) = h^k \partial_\theta^k \mathcal{C} \alpha'_h(\theta_i + hu)\,.\] 
		Since $u_h$ belongs to a finite-dimensional space of dimension $2$, all norms are equivalent, in particular 
		\[\norm{u_h}_{H^s(0,1)} \leq C \norm{u_h}_{L^2(0,1)}^2\,.\]
		Therefore
		\[\begin{split}
			\abs{\mathcal{C}\alpha'_h}_{H^s(\theta_i,\theta_{i+1})}^2& = h\int_{0}^{1}h^{-2s}\abs{\partial_u^s u_h(u)}du \\
			 &\leq C h^{-2s} \int_{0}^1 \abs{\partial_u^t u_h(u)}h du\\
			&\leq C h^{-2s}\norm{\mathcal{C}\alpha'_h}_{L^2(\theta_i,\theta_{i+1})}\,.
		\end{split} \]
		as claimed. When $s$ is not an integer, the result is deduced by interpolation. To establish the announced result it suffices to show that $\norm{\alpha_0 - \alpha_h}_{T^2} \leq C \norm{\alpha_0}_{T^2}$, and conclude by interpolation with the estimate $\norm{\alpha_0 - \alpha_h}_{T^{-1/2}} \leq C \norm{\alpha_0}_{T^2}$
		obtained in the proof of the previous theorem. One can write
		\[\norm{\alpha_0 - \alpha_h}_{T^2} \leq \norm{\alpha_0}_{T^2} + \norm{I_h \alpha_0}_{T^2} + \norm{I_h \alpha_0 - \alpha_h}_{T^2}\,.\]
		We have seen in the previous proof that $\norm{I_h \alpha_0}_{T^2} \leq C \norm{\alpha_0}_{T^2}$. For the third term, we can use the inverse estimate:
		\[\norm{I_h \alpha_0 - \alpha_h} \leq Ch^{-2}\norm{I_h \alpha_0 - \alpha_h}_{\frac{1}{\omega}}\,.\]
		Using triangular inequality
		\[\norm{I_h \alpha_0 - \alpha_h} \leq Ch^{-2}\left(\norm{\alpha_0 - I_h \alpha_0}_{\frac{1}{\omega}} + \norm{\alpha_0 - \alpha_h}_\frac{1}{\omega}\right)\,.\]
		In the previous proof, we have shown that 
		\[\norm{\alpha_0 - \alpha_h}_{\frac{1}{\omega}} \leq C \norm{\alpha_0 - I_h \alpha_0}_{\frac{1}{\omega}} \leq Ch^2 \norm{\alpha_0}_{T^2}\]
		and the proof is concluded. 
	\end{proof}
	
\subsection{Neumann problem}


Let $W_h$ the Galerkin space of {\bf continuous} piecewise affine functions 
on the mesh $(x_i)_{0\leq i \leq N}$ defined above, and $\beta_h$ the unique solution in $W_h$ to
\begin{equation}
\label{NomegaBetaGalerk}
\inner{N_{0,\omega} \beta_h}{\beta_h'}_{\omega} = \inner{u_N}{\beta_h'}_{\omega}, \quad \forall \beta_h' \in W_h\,.
\end{equation}
Let $\mu_h = {\beta_h}{\omega}$. We also write $\beta_0 \isdef \frac{\mu}{\omega}$. 
\begin{theorem}
	If $u_N \in U^{s-1}$, for some $\frac{1}{2} \leq s \leq 2$, there holds 
	\[\norm{\mu - \mu_h}_{\tilde{H}^{1/2}} \leq Ch^{s - \frac{1}{2}}\norm{\frac{\mu}{\omega}}_{U^s} \leq C h^{s - \frac{1}{2}}\norm{u_N}_{U^{s-1}}.\]
	\label{theOrdreCVNeumann}
\end{theorem}
\begin{proof}
	Like before, let us denote by $\Pi_h$ the operator that maps a function $\beta \in U^{1/2}$ to the element $\beta_h \in W_h$ such that
	\[\inner{N_{0,\omega}\beta_h}{\beta_h'} = \inner{N_{0,\omega} \beta}{\beta'_h} \quad \forall \beta_h' \in W_h\,.\]
	 The operator $N_{0,\omega}$ being coercive on $U^{1/2}$ by \autoref{LemU12}, we have a Céa's lemma: 
	\[\forall \beta \in U^{\frac{1}{2}},\quad \norm{\beta - \Pi_h \beta}_{U^{1/2}} \leq C \inf_{\beta'_h \in W_h} \norm{\beta - \beta'_h}_{U^{1/2}}\,.\] 
	In particular taking $\beta_h' = 0$ in the infimum,
	\[\forall \beta \in U^{1/2}, \quad \norm{(I_d - \Pi_h)\beta}_{U^{1/2}} \leq C \norm{\beta}_{U^{1/2}}\,.\]
	Once we prove 
	\begin{equation}
		\forall \beta \in U^{2},\quad  \norm{(I_d - \Pi_h)\beta}_{U^{1/2}} \leq Ch^{\frac{3}{2}} \norm{\beta}_{U^{2}}\,,
		\label{estimPih}
	\end{equation}
	we get by interpolation 
	\[\forall \beta \in U^{s}, \quad  \norm{(I_d - \Pi_h)\beta}_{U^{1/2}} \leq Ch^{s - \frac{1}{2}} \norm{\beta}_{U^{s}}\,\]
	for all $s \in [\frac{1}{2},2]$. The result follows since on the one hand,
	\[\norm{\mu - \mu_h}_{\tilde{H}^{1/2}} = \norm{\beta_0 - \beta_h}_{U^{1/2}},\]
	by \autoref{LemU12}, with $\Pi_h \beta_0 = \beta_h$ and, on the other hand, $\frac{\mu}{\omega} = \beta = N_{0,\omega}^{-1}u_N$ which, by \autoref{NomegaMapProp}, implies
	\[\norm{\beta}_{U^s} \leq C \norm{u_N}_{U^{s-1}}\,.\]
	Like before, the proof of \eqref{estimPih} involves the study of the interpolation operator $I_h$. Namely, if we have
	\begin{equation}
		\forall \beta \in U^2, \quad \norm{ (I_d - I_h) \beta}_{\omega} \leq Ch^2\norm{\beta}_{U^2}, \quad 
		\norm{(I_d -I_h) \beta}_{U^1} \leq Ch \norm{\beta}_{U^2}\,,
		\label{estimatesU0U1}
	\end{equation}
	then, by interpolation, we obtain 
	\[\norm{(I_d - I_h) \beta}_{U^{1/2}} \leq C h^{3/2}\norm{u}_{U^2}\,,\]
	which gives \eqref{estimPih} after applying Céa's lemma. 
	Let us show the first estimate in \eqref{estimatesU0U1}. Applying \autoref{lemChar} and using again the property of $H^2$ functions vanishing at the boundary \eqref{H2nulleaubord} one can write
	\begin{eqnarray*}
		\int_{x_i}^{x_{i+1}} \omega \abs{(I_d - I_h) \beta}^2 &\leq& C  (\theta_{i+1} - \theta_i)^4 \int_{\theta_i}^{\theta_{i+1}} \abs{\partial_{\theta\theta}(\mathcal{S}\beta- \mathcal{S}I_h \beta)}^2 \\
		&\leq& C h^4 \left(2\int_{\theta_i}^{\theta_{i+1}} \abs{\partial_{\theta\theta}\mathcal{S}\beta}^2 + 2\int_{\theta_i}^{\theta_{i+1}}\abs{\partial_{\theta\theta}\mathcal{S}I_h \beta}^2\right).
	\end{eqnarray*}
	Summing for $i = 0, \cdots, N-1$, by \autoref{lemChar}, we get
	\begin{equation}
		\norm{(I_d - I_h)\beta}_{\omega} \leq Ch^2\left(\norm{\beta}_{U^2} + \abs{\mathcal{S}I_h \beta}_{H^2}\right)
		\label{SummingFor}
	\end{equation}
	As for the Dirichlet conditions, the proof would end here with another choice of basis functions, namely functions of the form
	\[\phi_i(x) = \frac{a_i + b_i \arccos(x)}{\omega(x)}\,,\]
	because in this case, $\mathcal{S}I_h u$ would be affine and thus the second term in the right hand side would be $0$. Here, we need to show that the second term is controlled by $\norm{\beta}_{U^2}$. Using the expression of $I_h$, one can write
	\begin{multline}
	\int_{\theta_i}^{\theta_{i+1}} \abs{\partial_{\theta\theta}\mathcal{S} I_h\beta}^2\leq C\left(\abs{ \beta(x_i)}^2 \int_{\theta_i}^{\theta_{i+1}} \sin^2\theta d\theta \right.\\
	\left.+ \abs{\frac{\beta(x_{i+1}) -  \beta(x_{i})}{\cos\theta_{i+1} - \cos\theta_i}}^2 \int_{\theta_i}^{\theta_{i+1}} \sin^2\theta(1 + \cos^2\theta)d\theta\right)\,.
	\label{CalculIntermediaire}
	\end{multline}
	We can estimate the first term, thanks to \autoref{LemInjectionsContinues}:
	\[\abs{ \beta(x_i)} \leq C \norm{\beta}_{U^2},\]
	while for the second term, the numerator of the fraction is estimated as follows: 
	\begin{eqnarray*}
		\abs{\beta(x_{i+1}) - \beta(x_i)}^2 &=& \abs{ \int_{x_i}^{x_{i+1}} \partial_x  \beta}^2 \\
		& \leq & \int_{x_i}^{x_{i+1}} \omega \abs{\partial_x \beta}^2 \int_{x_i}^{x_{i+1}} \frac{1}{\omega} \\
		&  = & \abs{\theta_{i+1} - \theta_i}\int_{x_i}^{x_{i+1}} \omega \abs{\partial_x \beta}^2.
	\end{eqnarray*}
	Observe that the quantity 
	\[\frac{\abs{\theta_{i+1} - \theta_i} \int_{\theta_i}^{\theta_{i+1}}{\sin^2\theta(1 + \cos^2\theta)d\theta}}{(\cos\theta_{i} - \cos\theta_{i+1})^2}\]
	is bounded by a constant independent of $\theta_i$ and $\theta_{i+1}$. Indeed, in the limit $\theta_{i+1} \to \theta_{i}$, the fraction has the value $1 + \cos^2\theta_i$. Therefore, \eqref{SummingFor} becomes
	\[\norm{(I_d - I_h)\beta}_{\omega} \leq C h^2\left(\norm{\beta}_{U^2} + \norm{\partial_x \beta}_{\omega}\right).\]
	Recalling \autoref{corDxT2T0}, the second term in this estimate is controlled by $\norm{\beta}_{U^2}$ and the first estimate of \eqref{estimatesU0U1} is established. 
	The second estimate of \eqref{estimatesU0U1} can be shown in a similar manner, concluding the proof.  
\end{proof}
\noindent Using Aubin-Nitsche's duality technique and inverse estimates as in the previous paragraph, one can check that the following result holds.
\begin{Cor}
	For all $(s,t) \in [0,2]$, 
	\[\norm{\beta - \beta_h}_{U^s} \leq C h^{t - s}\norm{\beta}_{U^s}\,.\]
\end{Cor}


\section{Pseudo-differential operators}


In this section, we introduce two classes of pseudo-differential operators on $T^s(\Gamma)$ and $U^s(\Gamma)$, which are based on a class of periodic pseudo-differential operators on the torus. We will see in the next section that the weighted layer potentials $S_{k,\omega_{\Gamma}}$ and $N_{k,\omega_{\Gamma}}$ are elements of those classes, of order $-1$ and $1$ respectively. The symbolic calculus that we establish here will enable us to build parametrix for the aforementioned operators. 


\subsection{Periodic pseudo-differential operators}

On the family of periodic Sobolev spaces $H^s$, a class of periodic pseudo differential operators (PPDO) is studied in \cite{thrunen1998symbol}. We quickly review here the definitions and properties needed for our purposes. A PPDO of order $\alpha$ on $H^s$ is an operator of the form 
\[Au(\theta) =  \sum_{n \in \Z} \sigma_A(\theta,n) \hat{u}_n e^{in\theta}\,.\]
for a "prolongated symbol" $\sigma_A \in C^{\infty}(\mathbb{T}_T \times \R)$ satisfying 
\begin{equation}
\label{SymbolsCond}
	\forall j,k \in \N, \quad \exists C_{j,k} >0 : \quad \abs{D^j_\theta D_\xi^k \sigma_A(\theta,\xi)} \leq C_{j,k}(1 + \abs{\xi})^{\alpha - k}\,.
\end{equation}
Here, $\hat{u}_n = \frac{1}{2\pi}\int_{-\pi}^{\pi}u(t) e^{-in\theta}d\theta$ are the usual Fourier coefficients of $u$ and 
$${D_\theta \isdef \frac{1}{i}\frac{\partial}{\partial \theta}}, \quad  D_\xi \isdef \frac{1}{i}\frac{\partial}{\partial \xi},$$ 
with for $j \geq 1$, $D_\theta^{j+1} = D_\theta D_\theta^j$, and $D_\xi^{j+1} = D_\xi D_\xi^j$. 
The class of symbols that satisfy \eqref{SymbolsCond} is denoted by $\Sigma^\alpha$, and $\Sigma^{-\infty} \isdef \cup_{\alpha \in \Z} \Sigma^\alpha$. The operator defined by a symbol $\sigma$ is denoted by $\textit{Op}(\sigma)$ and the set of PPDOs of order $\alpha$ is denoted by $\textit{Op}(\Sigma^\alpha)$. 

The prolongated symbol is not unique but determined uniquely at the integer values of $\xi$ by 
\begin{equation}
	\label{symbolUniqueDetermine}
	\sigma_A(\theta,n) =  e_{-n}(\theta)Ae_n(\theta)\,,
\end{equation}
where we recall the notation $e_n(\theta) = e^{in\theta}$, as shown in \cite{thrunen1998symbol}. This justifies the terminology of "prolongated symbol". The operator $A$ is in $\textit{Op}(\Sigma^\alpha)$ if and only if
\[\forall j,k \in \N, \quad  \exists C_{j,k} > 0 :\quad  \abs{D_\theta^j \Delta_n^k \sigma_A(\theta,n)} \leq C_{j,k}(1 + \abs{n})^{\alpha - k}\,,\] 
where $\Delta_n \phi(\theta,n) = \phi(\theta,n+1) - \phi(\theta,n)$ and for $k \geq 1$, $\Delta^{k+1}_n\phi = \Delta_n (\Delta^k_n \phi)$. That is, if the symbol defined in \eqref{symbolUniqueDetermine} satisfies this condition, then there exists a prolongated symbol satisfying \eqref{SymbolsCond}. Because of this, we write $\sigma \in \Sigma^p$ for a symbol $\sigma(\theta,n)$ that can be prolongated to a symbol ${\sigma}(\theta,\xi) \in \Sigma^p$. An operator in $\textit{Op}(\Sigma^\alpha)$ maps continuously $H^s$ to $H^{s + \alpha}$ for all $s \in \R$. The composition of two operators in $\textit{Op}(\Sigma^\alpha)$ and $\textit{Op}(\Sigma^\beta)$ gives rise to an operator in $\textit{Op}(\Sigma^{\alpha+\beta})$. 
If two symbols $a$ and $b$ in $\Sigma^{- \infty}$ satisfy $a - b  \in \Sigma^{\alpha}$, we write $a = b + \Sigma^\alpha$. 
\begin{Def}
	Let $a \in \Sigma^{- \infty}$. If there exists a sequence of reals $(p_j)_{j \in \N}$ such that $p_j < p_{j+1}$ and a sequence of symbols $a_j \in \Sigma^{p_j}$ such that for all $N$, $a = \sum_{i = 0}^{N}a_i + \Sigma^{p_j + 1}$, we write 
	\[a = \sum_{i = 0}^{+ \infty} a_j \,.\]
	This is called an asymptotic expansion of the symbol $a$. 
\end{Def}

The symbol of the composition of two PPDOs $A$ and $B$ is denoted by $\sigma_A \# \sigma_B$ and satisfies the asymptotic expansion
\begin{equation}
	\label{a_diese_b}
	\sigma_A \# \sigma_B(t,\xi) = \sum_{j = 0}^{+\infty}\frac{1}{j!} \left(\frac{\partial}{\partial \xi}\right)^j \sigma_A(\theta,\xi) D_\theta^j \sigma_B(\theta,\xi)\,.
\end{equation}
We will also use the following result, proved in \cite{thrunen1998symbol}:
\begin{Prop}
	\label{thrunen}
	Consider an integral operator $K$ of the form 
	\[K : u \mapsto \frac{1}{2\pi}\int_{-\pi}^\pi a(\theta,\theta') h(\theta-\theta') u(\theta') d\theta'.\]
	where $a$ is $2\pi$-periodic and $C^{\infty}$ in both arguments and $h$ is a $2\pi$-periodic distribution. Assume that the Fourier coefficients $\hat{h}(n)$ of $h$ can be prolonged to a function $\hat{h}(\xi)$ on $\R$ such that
	\[\forall k \in \N, \quad \exists C_k > 0: \quad \abs{\partial^k_\xi \hat{h}(\xi)} \leq C_k (1 + \abs{\xi})^{\alpha - k}\,.\]
	for some $\alpha$. Then $K$ is in $\textit{Op}(\Sigma^\alpha)$ with a symbol satisfying the asymptotic expansion
	\begin{equation}
	\label{FormuleIntegralOperatorSymbol}
		\sigma_K(\theta, \xi) = \sum_{j = 0}^{+ \infty} \frac{1}{j!} \left(\frac{\partial}{\partial \xi}\right)^j \hat{h}(\xi) D_{t}^ja(t,\theta)_{| t= \theta}\,.
	\end{equation}
\end{Prop}
\noindent In particular, taking $h \equiv 1$, we see that for all functions $a \in C^{\infty}(\mathbb{T}_T^2)$
\[K : u \mapsto \frac{1}{2\pi}\int_{-\pi}^{\pi} a(\theta,\theta') u(\theta') d\theta'\]
is in $Op\left(\Sigma^{-\infty}\right)$.

\subsection{Pseudo-differential operators on $T^s(\Gamma)$}

\begin{Lem}
	\label{TransportPPDO_T}
	Let $A$ a PPDO that stabilizes the set of smooth even functions. Then $A$ coincides on this set with the operator $B$ defined by the symbol
	\[\sigma_B(\theta,n) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}\,.\]
	Moreover, $\sigma_B$ admits the following decomposition:
	\[ \sigma_B(\theta,n) = a_1(\cos\theta,n) + i \sin(\theta)a_2(\cos\theta,n) \]
	with 
	\[a_1(x,n) = \frac{\sigma_B(\arccos(x),n) + \sigma_B(\arccos(x),-n)}{2}\]
	\[a_2(x,n) = \frac{\sigma_B(\arccos(x),n) - \sigma_B(\arccos(x),-n)}{2i\sqrt{1-x^2}}\] 
	and $a_1$ and $a_2$ are $\Cinf$ in $x$. The functions $a_1$ and $a_2$ thus defined are denoted by $a_1^T(A)$ and $a_2^T(A)$. 
\end{Lem}
\begin{proof}
For a smooth even function $u$, one has
\[Au(\theta) = \frac{Au(\theta) + Au(-\theta)}{2}\,,\]
thus
\[Au(\theta) = \frac{1}{2}\sum_{n \in \Z} \sigma_A(\theta,n) \hat{u}_n e^{in\theta} + \frac{1}{2}\sum_{n \in \Z} \sigma_A(-\theta,n)\hat{u}_n e^{-in\theta}\,.\]
Since $u$ is even, $\hat{u}_n = \hat{u}_{-n}$, so that $Au(\theta) = Bu(\theta)$ where $B$ is the operator with symbol $\sigma_B(\theta,n) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}$. In particular, it satisfies the following symmetry:
\[\sigma_B(-\theta,-n) = \sigma_B(\theta,n)\,.\] 
We write $\sigma_B(\theta,n) = f_B(\theta,n) + g_B(\theta,n)$ where $f_B(\theta,n) = \frac{\sigma_B(\theta,n) + \sigma_B(\theta,-n)}{2}$ and $g_B(\theta,n) = \frac{\sigma_B(\theta,n) - \sigma_B(\theta,-n)}{2}$. Notice that $f_B$ (resp. $g_B$) is even (resp. odd) in both $\theta$ and $n$.
The functions $a_1$ and $a_2$ defined in the statement of the Lemma satisfy
\[a_1(x,n) = f_B(\arccos(x),n),\quad a_2(x,n) = \frac{g_B(\arccos(x),n)}{i\sqrt{1-x^2}}\,,\]
thus 
\[\sigma_B(\theta,n) = a_1(\cos\theta,n) + i \sin\theta a_2(\cos\theta,n)\,. \]
For fixed $n$, there holds $a_1(\cdot,n) = \mathcal{C}^{-1}f_B(\cdot,n)$ and $a_2(\cdot,n) = -i\mathcal{S}^{-1}g_B$. By \autoref{lemChar}, $a_1$ and $a_2$ are thus $C^\infty$ in $x$ since $f_B$ (resp. $g_B$) is a smooth even (resp. odd) function.  
\end{proof}
We use this result to transport the notion of periodic pseudo-differential operators to the segment $[-1,1]$ by the change of variable $x = \cos\theta$. 

\begin{Def}
	Let $A$ an operator on $T^{-\infty}$ and assume that there exists a couple of smooth functions $a_1$ and $a_2$ in $\Cinf([-1,1]\times \N)$ such that for all $n \in \N$,
	\begin{equation}
	AT_n = a_1(x,n) T_n - \omega^2 a_2(x,n) U_{n-1}\,,
	\label{defOpTs}
	\end{equation}
	with, by convention, $U_{-1} = 0$. Such a (non-unique) couple of functions is called a pair of symbols of $A$. For $n\in \Z$ and $\theta \in [0,2\pi]$, define the symbol $\tilde{\sigma}_T(a_1,a_2)$ by
	\[\tilde{\sigma}_T(a_1,a_2)(\theta,n) \isdef a_1(\cos\theta,\abs{n}) + i \sin\theta\,\text{sign}(n) a_2(\cos\theta,\abs{n})\,.\]
	We say that $(a_1,a_2) \in S^\alpha_T$ if $\tilde{\sigma}_T(a_1,a_2) \in \Sigma^\alpha$. We also take the notation $S^{\infty}_T \isdef \cup_{\alpha \in \R} S^\alpha_T$. The operator defined by a pair of symbols $(a_1,a_2)$ is denoted by $\textit{Op}_T(a_1,a_2)$ and the set of pseudo-differential operators (of order $\alpha$) in $T^{-\infty}$ by $\textit{Op}(S^\infty_T)$ (by $\textit{Op}(S^\alpha_T)$).
\end{Def} 
\noindent Recall the definition of the isometric mapping $\mathcal{C}$ from \autoref{lemChar}.
\begin{The}
	\label{PDOTs}
	Let $(a_1,a_2) \in S^\alpha_T$ and $A = \textit{Op}_T(a_1,a_2)$.  There holds
	\[\mathcal{C}A = \tilde{A}\mathcal{C}\,\]
	where $\tilde{A} = \textit{Op}(\tilde{\sigma}_T(a_1,a_2))$. 
	Reciprocally, let $A : T^{\infty} \to T^{-\infty}$ and assume that there exists a PPDO $\tilde{A}$ of order $\alpha$ such that
	\[\forall u \in T^{\infty},\quad \mathcal{C}Au = \tilde{A}\mathcal{C}u\,.\]
	Then $A$ has a unique linear continuous extension on $T^{-\infty}$ satisfying $\mathcal{C}A = \tilde{A} \mathcal{C}$ and this extension belongs to $\textit{Op}(S^\alpha_T)$. Moreover, $A$ admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$.
\end{The}
\begin{proof}
	For the direct result, we start by showing the equality for $u = T_n$ for all $n \in \N$. One has $\mathcal{C}T_n(\theta) = T_n(\cos(\theta)) = \cos(n\theta)$. Consequently,
	\begin{equation}
	\label{debut}
		\tilde{A}\left(\mathcal{C}T_n\right)(\theta) = \frac{\tilde{A}e^{in\theta}+\tilde{A}e^{-in\theta}}{2}\,
	\end{equation}
	which, using the determination of the symbol \eqref{symbolUniqueDetermine}, yields
	\[\tilde{A}\left(\mathcal{C}T_n\right)(\theta) = \frac{ \sigma(\theta,n)e^{in\theta} + \sigma(\theta,-n)e^{-in\theta}}{2}\,,\]
	where $\sigma = \tilde{\sigma}_T(a_1,a_2)$. Replacing this definition in the former equation, one gets
	\[\tilde{A}\left(\mathcal{C}u\right)(\theta) = a_1(\cos\theta,n)\cos(n\theta) - \sin\theta a_2(\cos\theta,n)\sin(n\theta).\]
	Since $\cos(n\theta) = T_n(\cos\theta)$ and $\sin(n\theta) = \sin\theta U_{n-1}(\cos\theta)$,
	\begin{equation}
		\begin{split}
		\tilde{A}\left(\mathcal{C}T_n\right)(\theta) &= a_1(\cos\theta,n)T_n(\cos\theta) - (1-\cos^2 \theta) a_2(\cos\theta,n) U_{n-1}(\cos\theta)\,,\\
		& = \mathcal{C}(AT_n)
		\end{split}
		\label{fin}
	\end{equation}
	as claimed. To show the general case, fix $u\in T^{-\infty}$ and $\tilde{v} \in H^{-\infty}$. One has, by linearity and continuity of $A$, $\tilde{A}$ and $\mathcal{C}$:
	\[\begin{split}
	\duality{\mathcal{C}A u}{\tilde{v}}_{\mathbb{T}_{2\pi}} &= \sum_{n = 0}^{+ \infty} \hat{u}_n \duality{\mathcal{C}AT_n}{\tilde{v}}_{\mathbb{T}_{2\pi}}\\
	& =  \sum_{n = 0}^{+ \infty} \hat{u}_n \duality{\tilde{A} \mathcal{C} T_n}{\tilde{v}}_{\mathbb{T}_{2\pi}}\\
	&= \duality{\tilde{A} \mathcal{C}u}{\tilde{v}}_{\mathbb{T}_{2\pi}}\,.
	\end{split}\]
	The last identity shows that $\mathcal{C}A u = \tilde{A} \mathcal{C} u$ for all $u \in T^{-\infty}$, in other words, $\mathcal{C}A = \tilde{A} \mathcal{C}$. For the converse result, we now assume that for any $u \in T^{\infty}$, $\mathcal{C}Au = \tilde{A}\mathcal{C}u$ where $\tilde{A}$ is some PPDO of order $\alpha$ with a symbol $\sigma_{\tilde{A}}$. The previous computations show that any linear continuous extension of $A$ satisfies 
	\begin{equation}
	\mathcal{C}A = \tilde{A}\mathcal{C}\,.
	\label{temp4}
	\end{equation}
	This in turn defines uniquely the operator $A$ on $T^{-\infty}$ since for $u \in T^{-\infty}$ and $v \in T^{\infty}$, one has, by \autoref{FormuleDualitesCetS},
	\[\duality{Au}{v}_\frac{1}{\omega} = \duality{\mathcal{C}Au}{\mathcal{C}v}_{\mathbb{T}_{2\pi}}\,.\]
	Let us show that $A$ sends $T^{\infty}$ to $T^{\infty}$. Let $u \in T^{\infty}$ and $s\in \R$. Using \eqref{temp4}, the continuity of $\tilde{A}$ from $H^{s+\alpha}$ to $H^{s}$ and the isometric property of $\mathcal{C}$,  
	\[\begin{split}
		\norm{Au}_{T^s} &= \norm{\mathcal{C}Au}_{H^s}\\
		&= \norm{\tilde{A}\mathcal{C}u}_{H^s}\\
		& \leq C \norm{\mathcal{C}u}_{H^{s + \alpha}}\\
		& \leq C \norm{u}_{T^{s + \alpha}}.
	\end{split}\]
	The last quantity is finite since $u \in T^{\infty} \subset T^{s+\alpha}$. This proves that $A$ sends $T^\infty$ to $T^\infty$. \\
	Eq (\ref{temp4}) implies in particular that $\tilde{A}$ stabilizes the set of smooth even functions since $\mathcal{C}Au(\theta) = Au(\cos\theta)$ is even and $A$ maps smooth functions to smooth functions. \autoref{TransportPPDO_T} can thus be applied. Let $a_1 = a_1^T(\tilde{A})$ and $a_2 = a_2^T(\tilde{A})$. Starting from eq. \eqref{temp4}, the computations from eqs. \eqref{debut} to \eqref{fin} can be performed in reverse order to show
	\[AT_n(\cos \theta) = a_1(n,\cos\theta) T_n(\cos\theta) -(1 - \cos^2\theta) a_2(n,\cos\theta) U_{n-1}(\cos\theta)\,,\]
	which, taking $x = \cos\theta$, leads to $A = \textit{Op}_T(a_1,a_2)$. To establish that $A$ is in $\textit{Op}(S^\alpha_T)$, we have to show $\tilde{\sigma}(a_1,a_2) \in  \Sigma^\alpha$. By \autoref{TransportPPDO_T}, $\tilde{\sigma}(a_1,a_2) $ is exactly the symbol $\sigma_B$ defined by 
	\[\sigma_B(\theta,n) = \frac{\sigma_{\tilde{A}}(\theta,n) + \sigma_{\tilde{A}}(-\theta,-n)}{2}\,.\] 
	This is indeed in $\Sigma^\alpha$ since it is the case for $\sigma_{\tilde{A}}$ by assumption. 
\end{proof}
\begin{Rem}
	When $A \in \textit{Op}(S^\alpha_T)$, there is an infinity of operators $\tilde{A}$ satisfying $\mathcal{C}A = \tilde{A} \mathcal{C}$. Indeed, if this holds for some $\tilde{A}$, it also holds for $\tilde{A} + B$ where $B$ is any PPDO of order $\alpha$ with the property that $Bu = 0$ when $u$ is even. This non-uniqueness is also reflected by the fact that the couple of symbols of an operator $A$ in $\textit{Op}(S^\alpha_T)$ is not unique, or in other words, the null operator has non-trivial pair of symbols in $S^{-\infty}_T$. For example take $a_1$ and $a_2$ as follows: fix $n_0 \in \N$ and let 
	\[a_1(x,n_0) = -\omega^2 U_{n_0-1}(x)\,, \quad a_2(x,n_0) = T_{n_0}(x)\]
	while $a_1(x,n) = a_2(x,n) = 0$ for $n \neq 0$. Obviously, $(a_1,a_2) \in S^{-\infty}_T$ and $\textit{Op}_T(a_1,a_2) \equiv 0$. 
	One idea to enforce uniqueness would be to take for $\tilde{A}$ the operator $\tilde{A}^*$ satisfying $\tilde{A}^*u = 0$ whenever $u$ is odd. Such a condition would demand the following symmetry on the symbol $\sigma_{\tilde{A}^*}:$
	\[\sigma_{\tilde{A}^*}(\theta,-n) = e^{2in\theta}\sigma_{\tilde{A}^*}(\theta,n)\,.\]
	One can show that if $\mathcal{C}A = \tilde{A} \mathcal{C}$ for some operator $\tilde{A}$, then the symbol of $\tilde{A}^*$ must be given by
	\[\sigma_{\tilde{A}^*}(\theta,n) = \sigma_{\tilde{A}}(\theta,n) + e^{-2in\theta}\sigma_{\tilde{A}}(\theta,-n)\,.\] 
	However, in general, this symbol is not in $\Sigma^\alpha$ because of the oscillatory term $e^{-2in\theta}$. In other words, one cannot always construct an operator $\tilde{A}^*$  satisfying the following three conditions 
	\begin{itemize}
		\item[-] $\tilde{A}^*$ coincides on the set of even functions with some given PPDO $\tilde{A}$ of order $\alpha$,
		\item[-] $\tilde{A}^*$ vanishes on the set of odd functions,
		\item[-] $\tilde{A}^*$ is a PPDO of order $\alpha$. 
	\end{itemize}
	As a conclusion, it is not clear how to fix a natural representative in the class of pairs $(a_1,a_2)$ that define the same operator $A$. 
\end{Rem}
\begin{Def}
	Let $A : T^{-\infty}(\Gamma) \to T^{-\infty}(\Gamma)$. We say that $A$ is a pseudo-differential operator (of order $\alpha$) on $T^{-\infty}(\Gamma)$ if $R A R^{-1} \in Op(S^{\infty}_T)$ ($\in Op(S_T^{\alpha})$). The set of pseudo-differential operators of order $\alpha$ on $T^{-\infty}(\Gamma)$ is denoted by $\textit{Op}(S^{\alpha}_T(\Gamma))$. We say that $(a_1,a_2)$ is a pair of symbols of $A$ if it is a pair of symbols of $RAR^{-1}$.  
\end{Def}
\noindent As a corollary of \autoref{PDOTs}, we have he following properties
\begin{Cor}
	\label{CorContinuitePDOTs}
	Let $A \in \textit{Op}(S^\alpha_T(\Gamma))$. Then for all $s$, $A$ is continuous from $T^s(\Gamma)$ to $T^{s - \alpha}(\Gamma)$. If $B$ and $C$ respectively belong to $\textit{Op}(S^{\alpha_1}_T(\Gamma))$ and $\textit{Op}(S^{\alpha_2}_T(\Gamma))$, with pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2}_T(\Gamma))$ and admits the pair of symbols $\left(a_1^T(\tilde{A}),a_2^T(\tilde{A})\right)$ where
	\[\tilde{A} = \textit{Op}(\tilde{\sigma}_T(b_1,b_2)) \textit{Op}(\tilde{\sigma}_T(c_1,c_2)) = \textit{Op}(\tilde{\sigma}_T(b_1,b_2)\#\tilde{\sigma}_T(c_1,c_2))\,.\]
\end{Cor}
\begin{proof}
	Let $A \in \textit{Op}(S^\alpha_T(\Gamma)$ and $s \in \R$. By \autoref{PDOTs}, there exists $\tilde{A} \in \textit{Op}(\Sigma^\alpha)$ such that 
	\[\mathcal{C}RAR^{-1} = \tilde{A}\mathcal{C}\,.\]
	Using the definition of the norm on $T^s(\Gamma)$, the isometric property of $\mathcal{C}$ and the continuity of $\tilde{A}$ from $H^s$ to $H^{s - \alpha}$, we have for all $u \in T^s(\Gamma)$,  
	\[\begin{split}
	\norm{Au}_{T^{s-\alpha}(\Gamma)} &= \norm{RA u}_{T^{s-\alpha}}
	=\norm{\mathcal{C}RA u}_{H^{s-\alpha}}
	=\norm{\tilde{A}\mathcal{C}Ru}_{H^{s-\alpha}}\\
	&\leq C \norm{\mathcal{C}Ru}_{H^s} = C\norm{Ru}_{T^s} = C\norm{u}_{T^s(\Gamma)}\,.
	\end{split}\]
	Let $B,C \in \textit{Op}(S^{\alpha_1}_T(\Gamma))\times\textit{Op}(S^{\alpha_2}_T(\Gamma))$, with respective pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$. Let $\tilde{B} = \textit{Op}(\tilde{\sigma}{(b_1,b_2)})$ and $\tilde{C} = \textit{Op}(\tilde{\sigma}{(c_1,c_2)})$. We have 
	\[\mathcal{C} RBR^{-1} = \tilde{B} \mathcal{C}, \quad \text{ and } \quad  \mathcal{C} RCR^{-1} = \tilde{C} \mathcal{C}\,.\]
	Therefore, 
	\[\mathcal{C} RBCR^{-1} = \tilde{A} \mathcal{C}\]
	where $\tilde{A} = \tilde{B}\tilde{C}$. One has $\tilde{A} \in \textit{Op}(\Sigma^{\alpha_1 + \alpha_2})$. By \autoref{PDOTs}, $RBCR^{-1}$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2})$ and admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$. By definition, this means that $BC \in \textit{Op}(S^{\alpha_1 + \alpha_2}(\Gamma))$ and admits the pair of symbols $(a_1^T(\tilde{A}),a_2^T(\tilde{A}))$. 
\end{proof}
\begin{Rem}
	\label{RemSymb}
	The previous result gives a method for a symbolic calculus on the class $S^\alpha_T(\Gamma)$ as follows. If $B$ and $C$ respectively admit the pair of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ admits the pair of symbols 
	\[(b_1,b_2) \#_T (c_1,c_2) \isdef \left(a_1^T(\tilde{A}),a_2^T(\tilde{A})\right)\,\]
	with $\tilde{A} = \textit{Op}\left(\tilde{\sigma}(b_1,b_2) \# \tilde{\sigma}(c_1,c_2) \right)$.
	One can use \eqref{a_diese_b} to compute an asymptotic expansion of $\tilde{\sigma}(b_1,b_2) \# \tilde{\sigma}(c_1,c_2)$ which, in turn, gives an asymptotic expansion of $(b_1,b_2) \#_T (c_1,c_2)$. The proofs of \autoref{TheSkomega} and \autoref{TheNkomega} rely on this method, but the details of the computation are omitted as they are quite heavy. In compensation, a Maple code giving procedures for the symbolic calculus is provided in \cite{aversengSymbolicCalculus}.
\end{Rem}
\subsection{Pseudo-differential operators on $U^s(\Gamma)$}

We define similarly a class of pseudo-differential operators on the spaces $U^s(\Gamma)$. One can show the following result:
\begin{Lem}
	\label{TransportPPDO_U}
	Let $A$ a PPDO that stabilizes the set of smooth odd functions. Then $A$ coincides on this set with the operator $B$ with symbol given by 
	\[\sigma_B(n,\theta) = \frac{\sigma_A(\theta,n) + \sigma_A(-\theta,-n)}{2}\,.\]
	Moreover, $\sigma_B$ admits the following decomposition
	\[\sigma_B(n,\theta) = i a_1(\cos\theta,n) + \sin\theta a_2(\cos\theta,n)\]
	with
	\[a_1(x,n) = \frac{\sigma_B(\arccos(x),n) + \sigma_B(\arccos(x),-n)}{2i}\]
	\[a_2(n,x) = \frac{\sigma_B(\arccos(x),n) - \sigma_B(\arccos(x),-n)}{2\sqrt{1-x^2}}\] 
	and $a_1$ and $a_2$ are $\Cinf$. The functions $a_1$ and $a_2$ thus defined are denoted by $a_1^U(A)$ and $a_2^U(A)$. 
\end{Lem}
Let $A$ an operator on $U^{-\infty}$ and assume that there exists a couple of smooth functions $a_1$ and $a_2$ in $\Cinf([-1,1]\times \N)$ such that for all $n \in \N$,
\[AU_n = a_1(x,n) U_n + a_2(x,n) T_{n+1}\,.\]
Such a (non-unique) couple of functions is called a pair of symbols of $A$. For $n\in \Z$ and $\theta \in [0,2\pi]$, define the symbol $\tilde{\sigma}_U(a_1,a_2)$ by
\[\tilde{\sigma}_U(a_1,a_2)(\theta,n) = i a_1(\cos\theta,\abs{n}) + \sin\theta\,\text{sign}(n) a_2(\cos\theta,\abs{n})\,.\]
We say that $(a_1,a_2) \in S^\alpha_U$ if $\tilde{\sigma}_U(a_1,a_2) \in \Sigma^\alpha$, and $S^{\infty}_U \isdef \cup_{\alpha \in \Z} S^\alpha_U$. The operator defined by a pair of symbols $(a_1,a_2)$ is denoted by $\textit{Op}_U(a_1,a_2)$ and the set of pseudo-differential operatos (of order $\alpha$) in $U^{-\infty}$  by $\textit{Op}(S^\infty_U)$ ($\textit{Op}(S^\alpha_U)$). 
Recall the definition of the isometric mapping $\mathcal{S}$ from \autoref{lemChar}. Adapting the proof of \autoref{PDOTs}, one can show
\begin{The}
	\label{PDOUs}
	Let $(a_1,a_2) \in S^\alpha_U$ and $A = \textit{Op}_U(a_1,a_2)$.  There holds
	\[\mathcal{S}A = \tilde{A}\mathcal{S}\,\]
	where $\tilde{A} = \textit{Op}(\tilde{\sigma}_U(a_1,a_2))$. 
	Reciprocally, let $A : U^{\infty} \to U^{-\infty}$ a linear operator such that there exist a PPDO $\tilde{A}$ of order $\alpha$ satisfying
	\[\forall u \in U^{\infty},\quad \mathcal{S}Au = \tilde{A}\mathcal{S}u\,.\] 
	Then $A$ has a unique linear continuous extension on $U^{-\infty}$ satisfying $\mathcal{S}A = \tilde{A} \mathcal{S}$. This extension is in $\textit{Op}(S^\alpha_U)$ and $A$ admits the pair of symbols $\left(a_1^U(\tilde{A}),a_2^U(\tilde{A})\right)$.
\end{The}
\begin{Def}
	Let $A : U^{-\infty}(\Gamma) \to U^{-\infty}(\Gamma)$. We say that $A$ is a pseudo-differential operator (of order $\alpha$) on $U^{-\infty}(\Gamma)$ if $R A R^{-1} \in Op(S^{\infty}_U)$ ($\in Op(S_U^{\alpha})$). The set of pseudo-differential operators of order $\alpha$ on $U^{-\infty}(\Gamma)$ is denoted by $\textit{Op}(S^{\alpha}_U(\Gamma))$. We say that $(a_1,a_2)$ is a pair of symbols of $A$ if it is a pair of symbols of $RAR^{-1}$.  
\end{Def}
\begin{Cor}
	Let $A \in \textit{Op}(S^\alpha_U(\Gamma))$. Then for all $s$, $A$ is continuous from $U^s$ to $U^{s - \alpha}$. If $B$ and $C$ respectively belong to $\textit{Op}(S^{\alpha_1}_U(\Gamma))$ and $\textit{Op}(S^{\alpha_2}_U(\Gamma))$, with pairs of symbols $(b_1,b_2)$ and $(c_1,c_2)$, then $BC$ is in $\textit{Op}(S^{\alpha_1 + \alpha_2}_U(\Gamma))$ and admits the pair of symbols $(a_1^U(\tilde{A}),a_2^U(\tilde{A}))$ where
	\[\tilde{A} = \textit{Op}(\tilde{\sigma}_U(b_1,b_2)) \textit{Op}(\tilde{\sigma}_U(c_1,c_2)) = \textit{Op}(\tilde{\sigma}_U(b_1,b_2)\#\tilde{\sigma}_U(c_1,c_2))\,.\]
\end{Cor}
\begin{Lem}
	Let $A \in \textit{Op}(S_T^{\alpha}(\Gamma))$ and $B = -\partial_\tau A \omega_\Gamma \partial_\tau \omega_\Gamma$. Then $B \in \textit{Op}(S_U^{\alpha+2}(\Gamma))$ and if $\tilde{A}$ is a PPDO such that $\mathcal{C}RAR^{-1} = \tilde{A} \mathcal{C}$, then $\mathcal{S}RBR^{-1} = -\partial_\theta \tilde{A} \partial_\theta \mathcal{S}$.
	\label{LemdxAomegadeomega}
\end{Lem}
\begin{proof}
	On can check the following identities:
	\begin{align*}
	\partial_\theta \mathcal{S} &= - \mathcal{C} \omega \partial_x \omega \,,\\
	\partial_\theta \mathcal{C} &= - \mathcal{S} \partial_x\,.
	\end{align*}
	Let $A' = RAR^{-1}$ and $B' = RBR^{-1}$. Assuming that $\mathcal{C} A' = \tilde{A} \mathcal{C}$, there holds
	\begin{align*}
	\mathcal{S}B' &= -\mathcal{S}R \partial_\Gamma A \omega_\Gamma \partial_\Gamma \omega_\Gamma R^{-1}\\
	&= -\mathcal{S}\partial_x A' \omega \partial_x \omega\\
	&=\partial_\theta \mathcal{C}A'\omega \partial_x \omega\\
	&=\partial_\theta \tilde{A} \mathcal{C} \omega \partial_x\omega\\
	&= -\partial_\theta \tilde{A} \partial_\theta \mathcal{S}\,.
	\end{align*}
	Since $\tilde{A}$ can be chosen as a PPDO of order $\alpha$ by \autoref{PDOTs}, $\partial_\theta \tilde{A} \partial_\theta$ is then a PPDO of order $\alpha +2 $ and by \autoref{PDOUs}, we conclude that $B \in \textit{Op}(S_U^{\alpha + 2}(\Gamma))$.  
\end{proof}
\begin{Lem}
	Let $A \in \textit{Op}(S_T^{\alpha}(\Gamma))$ and $B = A \omega_\Gamma^2$. Then $B \in \textit{Op}(S_U^{\alpha}(\Gamma))$ and if $\tilde{A}$ is a PPDO such that $\mathcal{C}RAR^{-1} = \tilde{A} \mathcal{C}$, then $\mathcal{S}RBR^{-1} = \sin\tilde{A} \sin \mathcal{S}$ where $\sin$ denotes the operator $f(\theta) \mapsto \sin(\theta) f(\theta)$. 
	\label{LemAomega2}
\end{Lem}
\begin{proof}
	This follows from the identities
	\[\mathcal{S} = \sin \mathcal{C}, \quad \mathcal{C}\omega^2 = \sin \mathcal{S}\]
	and the same arguments as in the proof of \autoref{LemdxAomegadeomega}. 
\end{proof}
\begin{Def}
	Let $A$ and $B$ in $\textit{Op}(S^{\infty}_T(\Gamma))$ (resp. $\textit{Op}(S^{\infty}_U(\Gamma))$). If $A - B \in \textit{Op}(S^\alpha_T(\Gamma))$ (resp. $\textit{Op}(S^\alpha_U(\Gamma))$), we write 
	$A = B + T_\alpha \,$ (resp. $A = B + U_\alpha \,$). 
\end{Def}
	
%
%\subsubsection{Classes of operators}
%
%We shall now introduce a class of pseudo-differential operators on the open segment. Essentially, they are, up to a change of variables, the periodic pseudo-differential operators on the torus $\mathbb{T}_{1} = \mathbb{R} / \Z$ that preserve the space of 1-periodic even functions, that is, that map $H^n_e(0,1)$ to itself. A particular property of these pseudo-differential operators is that their symbol is not defined uniquely. We show that a symbolic calculus is still available within this restricted class. 
%
%\begin{Def}
%	Let $p\in \R$. If  $A : T^{\infty} \to T^{-\infty}$ can be extended into a continuous operator from $T^{s}$ to $T^{s + p}$ for any $s \in \R$, we shall say that it is of order $p$ in the scale $T^s$. When an operator is of order $p$ for all $p \in \N$, we call it a smoothing operator. 
%	
%	An operator $A : U^{\infty} \to U^{-\infty}$ which maps continuously $U^s$ to $U^{s+p}$ for all real $s$ is said to be of order $p$ in the scale $U^s$. When the family ($U^s$ or $T^s$) is clear from the context, we simply say that $A$ is of order $p$. 
%\end{Def}
%
%\begin{Def}
%	\label{DefEquivModTp}
%	Let $A$ and $B$ two operators of order $s$ in the scale $T^s$. When the operator 
%	$A - B$ is of order $p \in (0,+\infty]$, we shall write 
%	\[A = B + T_{p}.\]
%	When the scale is $U^s$ instead of $T^s$, we write 
%	\[A = B + U_{p}.\]
%\end{Def}
%
%\label{subsec:classesOfOp}
%
%To ease the computations, we define $T_n = T_{\abs{n}}$ for $n \in \Z$. 
%
%
%\begin{Def}
%	An operator $A \in \mathcal{L}(T^{-\infty})$ belongs to the class $S^{-\infty}$ if there exists a "discrete symbol" $\sigma_A : \N \times \Z$ of $A$ such that, for all $n \in \N$,
%	\[AT_n = \sum_{i \in \Z} \sigma_A(n,i) T_{n-i}\,,\]
%	with furthermore the property that there exists an integer $N$ for which 
%	\[ \abs{i} \geq N \implies \forall n \in \N, \quad \sigma_A(n,i) = 0\,.\]
%\end{Def}
%A single operator $A$ admits infinitely many discrete symbols as shown by the following example. Given $n_0$, let $\sigma$ the symbol defined by 
%\[ \sigma(n,i) = \begin{cases}
%0 & \text{ if } n \neq n_0, i \neq 0 \text{ or } i \neq 2n_0\\
%1 & \text{ if } n = n_0 \text{ and } i = 0\\
%-1 & \text{ if } n = n_0 \text{ and } i = 2 n_0\,.
%\end{cases}\]
%Then, $\sigma$ is a non-trivial discrete symbol of the null operator. Nevertheless, the next result ensures that two symbols of the same operator agree for $n$ large enough. 
%\begin{Lem}
%	\label{NonUniqueness}
%	Let $\sigma$ a discrete symbol of the null operator. Then there exists an integer $N$ such that 
%	\[n \geq N \implies \forall i \in \Z, \quad \sigma(n,i) = 0\,.\]
%	\begin{proof}
%		 By definition of $S^{-\infty}$, there exists an integer $N$ such that 
%		\[ \abs{i} \geq N \implies \forall n \in \N, \quad \sigma_A(n,i) = 0\,.\]
%		Let $n \geq N$, we can write 
%		\[0 = \sum_{i = -N+1}^{N-1} \sigma(n,i) T_{n-i} \,.\]
%		Two Chebyshev polynomials of the same order do not arise in the summation since $\forall i \in [-N +1,N-1]$, $n - i \geq 1$. Orthogonal projection against each $T_{n-i}$ thus yields 
%		\[\forall i \in [-N+1,N-1], \quad \sigma(n,i) = 0\,,\]
%		and by definition of $N$,
%		\[\forall i \in \Z, \quad \sigma(n,i) = 0\,.\]
%		This has been shown for all $n \geq N$ so the claim is proved. 
%	\end{proof}
%\end{Lem}
%
%An alternative definition is given as follows 
%\begin{Def}
%	An operator $A$ belongs to $S^{-\infty}$ if there exists two functions $a_1, a_2 : \R \times \N \to \R$ and an integer $N$ such that for all $n$, $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are polynomials of order at most $N$, and such that, for $n \geq 1$, 
%	\[AT_n(x) = a_1(n,x)T_n(x) + a_2(n,x) \omega^2 U_{n-1}(x),\]
%	while 
%	\[A T_0(x) = a_1(0,x) T_0 \,.\]
% 	We say that $(a_1,a_2)$ is a couple of semi-discrete symbols of $A$. 
%\end{Def}
%Let us prove the equivalence betwwen the two definitions.
%\begin{proof}
%	We prove that the first definition implies the second one. The calculations can also be made in the reverse order to prove the converse. Let $A\in S^{-\infty}$ and let $\sigma_A$ a discrete symbol of $A$. For $(n,i) \in \N \times \Z$, let 
%	\[f_A(n,i) = \frac{\sigma_A(n,i) + \sigma_A(n,-i)}{2}\,,\]
%	\[g_A(n,i) = \frac{\sigma_A(n,i) - \sigma_A(n,-i)}{2}\,.\]
%	We then have
%	\[\begin{split}
%	AT_n = f_A(n,0) T_n &+ \sum_{i = 1}^{+\infty} f_A(n,i) \left(T_{n+i} + T_{n-i}\right)\\
%	& + \sum_{i = 1}^{+\infty} g_A(n,i) \left(T_{n-i} - T_{n+i}\right)\,.
%	\end{split}\]
%	We use the trigonometric identities
%	\[T_iT_n = \frac{T_{n+i} + T_{n-i}}{2}\,.\]
%	\[\omega^2U_{i-1}U_{n-1} = \frac{T_{n-i} - T_{n+i}}{2}\,,\]
%	to get
%	\[AT_n = a_1(n,x) T_n + \omega^2 a_2(n,x) U_{n-1}\]
%	with 
%	\[a_1(n,x) = f_A(n,0) + 2\sum_{i = 1}^{+\infty}f_A(n,i) T_i(x)\,,\]
%	\[a_2(n,x) = 2\sum_{i = 1}^{+\infty}g_A(n,i) U_{i-1 }(x)\,.\]
%	There exists $N$ such that for each $n$, $f_A(n,i)$ and $g_A(n,i)$ are null for $ \abs{i} \geq N$. This implies that $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are polynomials of degree at most $N$. 
%\end{proof}
%As before, there are non-trivial couple of semi-discrete symbols for the null operator. For example, let $a_1$ and $a_2$ be defined as follows. Fix $n_0$ and take $a_1(x,n) = a_2(x,n) = 0$ for $n \neq n_0$, while 
%\[a_1(n_0,x) = -\omega^2 U_{n_0-1}(x) \,,\] 
%\[a_2(n_0,x) = T_{n_0}(x)\,. \]
%Nevertheless, two couple of semi-discrete symbols of the same operator agree for $n$ large enough:
%\begin{Lem}
%	\label{NonUniqueness2}
%	Let $(a_1,a_2)$ a couple of semi-discrete symbols for the null operator. Then there exists $N$ such that $n \geq N$ implies $a_1(n,x) = a_2(n,x) = 0$. 
%\end{Lem}
%\begin{proof}
%	By definition, there exists an integer $N$ such that for all $n$, $a_1(n,\cdot)$ is a polynomial of order less than $N$. Fix $n \geq N$. We have 
%	\[0 = a_1(n,x) T_n(x) + a_2(n,x)\omega^2 U_{n-1}(x)\]
%	and let $(z_i)$ the $(n+1)$ distinct roots of $\omega^2 U_{n-1}$. Note that $T_n(z_i)$ is non-zero for all $i$, thus, for 
%	\[\forall 1 \leq i \leq n+1, \quad a_1(n,z_i) = 0 \,.\]
%	Thus, $a_1(n,\cdot)$ has $n+1$ distinct roots while being a polynomial of order less than $n$. Therefore, $a_1(n,\cdot) = 0$. This in turn implies that $a_2(n,\cdot) = 0$. 
%\end{proof}
%As $a_1(n,\cdot)$ and $a_2(n,\cdot)$ are required to be polynomials, it is in fact possible to ensure uniqueness of the couple by Euclidean division. We may for example ask that $a_1(n,x)$ has a degree less than $n$. If there exists an admissible couple, then we can change $a_1$ such that this condition be satisfied by writing 
%\[a_1(n,\cdot) = b_1(n,\cdot) + Q(x)\omega^2 U_{n-1}(x)\]
%where $b_1(n,\cdot)$ has a degree less than $n$. Then, letting $b_2(n,x) = a_2(n,x) + Q(x)$, we have exhibited such a couple. Of course, with this condition, the null operator only has trivial semi-discrete symbols, by the same arguments as in the proof of the previous lemma. In practice, this uniqueness condition does no seem to bear any special interest. 
%
%Notice that the action of $A$ on a function $u$ is given in terms of a couple of semi-discrete symbols $(a_1, a_2)$ by 
%\[Au(x) = \sum_{n = 0}^{+ \infty} a_1(n,x) \hat{u}_n T_n(x) + \omega^2 \sum_{n = 1}^{+ \infty} a_2(n,x) \hat{u}_n U_{n-1}(x)\, .\]
%Letting $x = \cos(\theta)$ we have 
%\[\begin{split}
%Au (\cos(\theta)) =  &\sum_{n = 0}^{+ \infty} a_1(n,\cos(\theta)) \hat{u}_n \cos(n\theta)\\ 
%&+ \sum_{n = 1}^{+ \infty} \sin(\theta) a_2(n,\cos(\theta)) \hat{u}_n \sin(n\theta)\,.
%\end{split}\]
%Let $\tilde{A}$ the operator defined on $H^n_e(0,1)$ by  
%\[\tilde{A} f (t) = A u (\cos(2\pi t))\]
%where $f(\theta) = u(\cos(2\pi t))$. The Fourier coefficients of $f$ defined by 
%\[\hat{f}_n = \int_{0}^{1}e^{-2i \pi t \cdot n} f(t) dt\]
%satisfy $\hat{f}_n = \frac{\hat{u}_n}{2}$ 
%for $n \neq 0$, and $\hat{f}_0 = \hat{u}_0$. Thus
%\[\begin{split}
%\tilde{A}f (t) =  a(0,x) \hat{f}_0 + &2\sum_{n = 1}^{+ \infty} a_1(n,\cos(2\pi t)) \hat{f}_n \cos(2n \pi t)\\ 
%+&2\sum_{n = 1}^{+ \infty} \sin(2 \pi t) a_2(n,\cos(2 \pi t)) \hat{f}_n \sin(2n \pi t)\,.
%\end{split}\,.\]
%This coincides with a discrete pseudo-differential operator, as defined in \cite{thrunen1998symbol}, with a symbol $\sigma_A$ equal, for $n \neq 0$, to
%\[\sigma_A(n,t) = a_1(\abs{n},\cos(2\pi t)) + i \text{sign}(n) \sin(2\pi t)a_2(\abs{n},\cos(2\pi t))\,.\]
%and for $n= 0$ to
%\[\sigma_A(0,t) = a_1(0,\cos(2\pi t))\,.\]
%Contrary to \cite{thrunen1998symbol}, the resulting symbol $\sigma_A$ is restricted to the class of trigonometric polynomials of bounded degree in the second variable as would result here of our hypothesis for $a_1$ and $a_2$. We need this assumption in order to have a form of uniqueness in our symbols, but consequently, this prevents us from directly applying the results of the previous work. We thus need to prove that our class is still an algebra. 
%
%\begin{Def}
%	\label{defClassSk2}
%	For any real $p$, an operator $A$ belongs to the class $S^{p}$ if one of its discrete symbols $\sigma_A$ satisfies:  \begin{equation}
%		\label{Condition2}
%		\forall (\alpha,i) \in \N \times \Z \,,\exists C_{i,k} >0 : \forall k  \in \Z, \quad  \abs{\Delta_k^\alpha \sigma_A(k,i)} \leq C_{\alpha,i} (1 + k)^{-p - \alpha}\,.
%	\end{equation}
%	Here $\Delta_k$ is the difference operator in the variable $k$ (denoted simply by $\Delta$ when there is only one variable), defined by
%	\[\Delta_k a(k,i) = a(k+1,i) - a(k,i),\]
%	and $\Delta^\alpha_k$ is the $\alpha$-th iterate of $\Delta_k$.
%\end{Def}
%By \autoref{NonUniqueness}, if $A \in S^p$, then any symbol of $A$ satisfies the previous condition. 
%We state an equivalent definition using this time a couple of semi-discrete symbols.
%\begin{Lem}
%	The following conditions are equivalent:
%	\begin{itemize}
%		\item[-] $A \in S^p$
%		\item[-] There exists a couple of semi-discrete symbols $(a_1,a_2)$ of $A$ such that, for $i = 1,2$,
%		\begin{equation}
%		\label{Condition2bis}
%		\forall (\alpha,x) \in \N\,,\exists C_{\alpha} >0 : \forall (k,x)  \in \Z\times[-1,1], \quad  \abs{\Delta_k^\alpha a_i(k,x)} \leq C_{\alpha} (1 + k)^{-p - \alpha}\,.
%		\end{equation}
%	\end{itemize}
%If one of those conditions hold, then the condition \eqref{Condition2bis} holds for any couple of semi-discrete symbols of $A$. 
%\end{Lem}
%\begin{proof}
%	Given a discrete symbol $\sigma_A$ of $A$, $A$ admits the couple of semi-discrete symbols $(a_1,a_2)$ given by 
%	\[a_1(n,x) = f_A(n,0) + 2\sum_{i = 1}^{+\infty}f_A(n,i) T_i(x)\,,\]
%	\[a_2(n,x) = 2\sum_{i = 1}^{+\infty}g_A(n,i) U_{i-1 }(x)\,.\]
%	with $f_A$ and $g_A$ defined as
%	\[f_A(n,i) = \frac{\sigma_A(n,i) + \sigma_A(n,-i)}{2}\,,\]
%	\[g_A(n,i) = \frac{\sigma_A(n,i) - \sigma_A(n,-i)}{2}\,.\]
%	We have by linearity
%	\[\Delta_k^\alpha a_1(k,x) = \Delta_k^\alpha \sigma_A(n,0) + \sum_{i = 1}^{+\infty}\left(\Delta_k^\alpha \sigma_A(n,i)+\Delta_k^\alpha \sigma_A(n,-i) \right) T_i(x)\,.\]
%	We now apply condition \eqref{Condition2} to each term in the sum and with triangular inequality, 
%	\[\abs{\Delta^\alpha_na_1(k,x)} \leq C_\alpha (1 + k)^{-p-\alpha}\]
%	with $C_\alpha = \sum_{i = 0}^{+ \infty}C_{\alpha,i}$, where $C_{\alpha,i}$ are the constant from condition \eqref{Condition2} (recall the sum is actually finite). The same kind of computations gives a similar estimate for $a_2$ and the direct implication is proved. Conversely, let $(a_1,a_2)$ a couple of semi-discrete symbols of $A$ satisfying the condition \eqref{Condition2bis}. Then, reversing the computations, $A$ admits the discrete symbol $\sigma_A$ defined for $n \in \N$ and $i \in \Z$ by
%	\begin{equation}
%		\sigma_A(n,i) = f_A(n,\abs{i}) + \text{ sign} (i) g_A(n,\abs{i})
%		\label{combiner}
%	\end{equation}
%	with, for $i \in \N$, (by orthonormal projection),
%	\[f_A(n,i) = \begin{cases}\frac{1}{2 \norm{T_i}^2_\frac{1}{\omega}}\duality{a_1(n,x)}{T_i}_\frac{1}{\omega}& \text{ if } i \neq 0\\
%	\frac{1}{ \norm{T_0}^2_\frac{1}{\omega}}\duality{a_1(n,x)}{T_0}_\frac{1}{\omega} & \text{ if } i = 0\,.
%	\end{cases}\]
%	and 
%	\[g_A(n,i) = \begin{cases}\frac{1}{2 \norm{U_{i-1}}^2_{\omega}}\duality{a_2(n,x)}{U_{i-1}}_{\omega}& \text{ if } i \neq 0\\
%	0 & \text{ if } i = 0\,.
%	\end{cases}\]
%	Fix $i \in \N^*$. We have for all $k$, by linearity,
%	\[\Delta_k^\alpha f_A(k,i) = \frac{1}{2 \norm{T_i}^2_\frac{1}{\omega}}\duality{\Delta^\alpha_k a_1(k,x)}{T_i}_\frac{1}{\omega}\,.\]
%	Using Cauchy-Schwarz inequality and assumption \eqref{Condition2bis} for $a_1$, we get 
%	\[\abs{\Delta_k^\alpha f_A(k,i)} \leq C_{i}C_\alpha(1+k)^{-p - \alpha}\,,\]
%	with $C_i = \frac{1}{\norm{T_i}}_\frac{1}{\omega}$. Similar estimates can be shown in the same way for $i = 0$ and also for $g_A$. We finally combine them with \eqref{combiner} to conclude for the reverse implication. 
%	The last statement is obvious in view of \autoref{NonUniqueness2}. 
%\end{proof}
%An interpolation procedure gives the following result:
%\begin{Lem}
%	The following propositions are equivalent:
%	\begin{itemize}
%		\item[-] $A \in S^p$
%		\item[-] There exists a couple of functions $(\nu_1(\xi,x),\nu_2(\xi,x))$ defined for $(\xi,x) \in \R^+ \times [-1,1]$, and an integer $N$ such that $a_1$ and $a_2$ are $C^{\infty}$ in $\xi$ and $(\nu_{1|\N \times[-1,1]},\nu_{2|\N \times[-1,1]})$ is a couple of symbols for $A$, with furthermore the property
%		\[\forall \alpha, \exists C_\alpha > 0 : \forall (\xi,x) \in \R+ \times [-1,1], \quad \abs{\partial_\xi^\alpha \nu_i(x,\xi)} \leq C_\alpha (1 + \xi)^{-p - \alpha}\,.\]
%	\end{itemize}
%	We call $(\nu_1,\nu_2)$ a couple of continuous symbols of $A$. 
%\end{Lem}
%\begin{proof}
%	\toDo{Utiliser la procédure d'interpolation du papier PDO discrets.}
%\end{proof}
%
%
%\subsubsection{Symbols that are rational functions of $n$.}
%
%\toDo{Il va peut-être falloir enlever cette section à cause de l'équivalence du lemme précédent.}
%
%Given a discrete symbol $\sigma(n,i)$, is not straightforward to check that the condition \eqref{Condition2} holds for this symbol. We now show that this is the case when $\sigma(n,i)$ is a rational function of $n$. We will repeatedly make use the following forms of Peetre's inequality: for any real $a,b$ and $s$, 
%\begin{equation}
%\label{Peetre1}
%	(1 + \abs{a + b})^s \leq \left(1 + \abs{a}\right)^{\abs{s}} \left(1 + \abs{b}\right)^{s}
%\end{equation} 
%and
%\begin{equation}
%\label{Peetre2}
%\left(1 + \abs{a + b}^2\right)^s \leq 2^{\abs{s}}\left(1 + \abs{a}^2\right)^{\abs{s}} \left(1 + \abs{b}^2\right)^{s}\,.
%\end{equation} 
%\begin{Lem}
%	\label{lemDeltaDerivees}
%	Let $f$ a $C^{\alpha}$ function on $[k,k+\alpha]$. Then for all $k$, 
%	\begin{equation}
%	\label{formule1}
%		\Delta^{\alpha} f(k) =  \int_{x_1 =k}^{k+1}\int_{x_2 = x_{1}}^{x_{1}+1} \cdots \int_{x_\alpha = x_{\alpha-1}}^{x_{\alpha-1}+1} f^{(\alpha)}(x_\alpha)dx_1dx_2 \cdots dx_{\alpha}
%	\end{equation}
%\end{Lem}
%\begin{proof}
%	We show by induction that for all $1 \leq \beta \leq \alpha$, 
%	\begin{equation}
%	\label{hypRec1}
%		\Delta^{\alpha} f(x) = \int_{x}^{x+1} \int_{x_{1}}^{x_{1}+1} \int_{x_{\beta-1}}^{x_{\beta-1}+1} \Delta^{\alpha - \beta} f^{(\beta)}(x_\beta)dx_1dx_2 \cdots  dx_\beta.
%	\end{equation}
%	For $\beta = 1$, we write 
%	\[\Delta^{\alpha}f(x) = \Delta^{\alpha-1}f(x+1) - \Delta^{\alpha-1}f(x),\]
%	therefore,
%	\[\Delta^{\alpha}f(x) = \int_{x}^{x+1} \frac{d}{dx_1}\left(\Delta^{\alpha-1}f\right)dx_1.\]
%	This proves the property for $\beta = 1$. 
%	Let $ 1 \leq \beta < \alpha$ and assume that \eqref{hypRec1} holds for this $\beta$. Then we write
%	\[\Delta^{\alpha - \beta} f^{\beta}(x_\beta) = \int_{x_\beta}^{x_\beta+1} \frac{d}{dx_{\beta}}\Delta^{\alpha - \beta} f^{(\beta)}(x_{\beta+1})dx_{\beta+1}.\]
%	Of course, $\Delta$ and $\frac{d}{dx}$ commute, thus 
%	\[\Delta^{\alpha - \beta} f^{\beta}(x_\beta) = \int_{x_\beta}^{x_\beta+1} \Delta^{\alpha - \beta} f^{(\beta+1)}(x_{\beta+1})dx_{\beta+1}.\]
%	Replacing in \eqref{hypRec1}, this proves the heredity of the property. Finally, taking $\beta = \alpha$ in \eqref{hypRec1} gives the announced result. 
%\end{proof}
%\begin{Cor}
%	\label{lemFracRat}
%	If $f$ is a rational function of degree $p$ which poles are contained in $\mathbb{C} \setminus \N$, then there exists a constant $C_\alpha$ such that for all $k \in \N$, \[\abs{\Delta^{\alpha} f(k)} \leq C_\alpha (1+k)^{p - \alpha}\,.\]
%\end{Cor}
%\begin{proof}
%	Fix a rational fraction $F$ of degree $p$, with poles in $\mathbb{C} \setminus \N$. $F$ is of the form 
%	\[F = P + R\]
%	where $P$ is zero if $p < 0$ and a polynomial of degree $p$ otherwise, and $R$ is a finite linear combination of quantities of the form 
%	\[Q_i(X) = \frac{1}{(X - x_i)^{q}}\]
%	with $x_i \in \mathbb{C} \setminus \N$ and $q \geq -p$. The claimed result is an easy consequence of the following two fact:
%	\begin{itemize}
%		\item[-] If the polynomial $P$ is of degree $p \geq 0$, there holds
%		\[\abs{\Delta^{\alpha} P}(k)  \leq C (1+k)^{p - \alpha},\]
%		\item[-] For the terms $Q_i(X) = \frac{1}{(X - x_i)^{q}},$ there holds
%		\begin{equation}
%		\label{termeQi}
%			\abs{\Delta^{\alpha} Q_i}(k)  \leq C (1+k)^{-q - \alpha}\,.
%		\end{equation}
%	\end{itemize}
%	We first treat the polynomial case. If $\alpha > p$, we have $P^{(\alpha)} = 0$, and thus, by \autoref{lemDeltaDerivees}, $\Delta^{\alpha} P(k) = 0$, and the result is obvious. If $\alpha \leq p$, there exists a constant $C$ such that
%	\[\abs{P^{(\alpha)}(x)} \leq C (1 + x)^{p - \alpha}.\]
%	We inject this in \eqref{formule1}. In the domain of integration, $x_\alpha \leq k + \alpha$, thus
%	\[\abs{\Delta^{q} P}(k) \leq C (1 + (k + \alpha))^{p - \alpha} \leq C (1 + \alpha)^{p-\alpha}(1+k)^{p - \alpha}\]
%	by Peetre's inequality \eqref{Peetre1}. This proves the claim for the polynomial term. 
%	
%	\noindent For $Q_i$, we write:
%	\[Q_i^{(\alpha)}(x) = \frac{(-1)^k p(p+1) \cdots (p+\alpha)}{(x - x_i)^{p+\alpha}}.\]
%	For $x \geq \max \left(1,2 \abs{x_i}\right)$, using Peetre's inequaliy \eqref{Peetre1}, we get
%	\[\abs{Q^{(\alpha)}(x)} \leq \frac{p(p+1) \cdots (p+\alpha)}{(1+x)^{p + \alpha}}.\]
%	We then proceed with the same arguments as for $P$ and conclude that \eqref{termeQi} holds with some constant $C_1$ for all $k  \geq k_0$ where $k_0$ is an integer greater than $\max \left(1,2 \abs{x_i}\right)$. Then \eqref{termeQi} holds for all $k$ with 
%	\[C = \max(C_1,\Delta^{\alpha} Q_i(0), \cdots, \Delta^\alpha Q_i(k_0))\,.\]
%\end{proof}
%
%\subsubsection{Algebraic properties of $S^p$}
%\begin{Lem}
%	If $A\in S^p$, then $A$ is of order $p$ in the scale $T^s$. 
%\end{Lem}
%\begin{proof}
%	Since the sum in the condition (i) is finite, by linearity, showing that the operator $A$ is of order $p$ amounts to proving that the operator $A_i$ defined by
%	\[ \forall k \in \Z, \quad  A_i T_k = a(k,i) T_{k-i} \]
%	is of order $p$. We treat the case $i > 0$, the opposite case being analogous. Let $u \in T^s$ for some $s$, there holds 
%	\[ A_i u = \sum_{k = 0}^{+ \infty} a(i+k,i)\hat{u}_{k + i}T_k + \sum_{k = 0}^{i} a(i - k,i) \hat{u}_{i - k}T_k.\]
%	Let $Vu$ and $Ru$ respectively the two terms of the rhs. Obviously, $R$ is a smoothing operator. Now, for all $k \in \N$ let
%	\[\hat{v}_k \isdef a(i + k,i) \hat{u}_{i + k}.\]
%	Applying Peetre's inequality \eqref{Peetre2},
%	\[(1 + k^2)^{n + s}\abs{\hat{v}_k}^2 \leq 2^{\abs{p+s}}\left(1 + i^2\right)^{\abs{p + s}}\left(1 + (i + k)^2\right)^{p + s} \abs{a(k + i,i)}^2 \abs{\hat{u}_{k+i}}^2.\]
%	Condition (ii) with $\alpha = 0$ yields
%	\[\abs{a(k+i,i)}^2 \leq C\left(1 + (k+i)\right)^{-2p} \leq 2^{\abs{p}}C \left(1 + (k+i)^2\right)^{-p}.\]
%	Therefore, $\norm{V u}_{T^{s + p}} \leq C(1 + i)^{\abs{n + s}} \norm{u}_{T^s}$ which shows that $A$ is of order $p$.
%\end{proof}
%\begin{Lem}
%	\label{LemCompo}
%	If $A \in S^{p}$, $B \in S^{q}$, then $AB$ is in $S^{p + q}$, 
%\end{Lem}
%\begin{proof}
%	A symbol of $AB$ is given by
%	\[c(k,i) = \sum_{j = - \infty}^{+ \infty} a(k - j, i - j) b(k,j).\]
%	This formula is obtained writing the expression of $AB T_n$ using a symbol of $A$ and $B$ and using the identity $T_i T_j = T_{i + j} + T_{i -j}$. 
%	Let $N_a$ such that $\abs{i} \geq N_a \implies a(k,i) = 0$ and let $N_b$ defined in a similar way. Then, it is easy to check that $\abs{i} \geq N_a + N_b \implies c(k,i) = 0$. It remains to check the requirement (ii). Since the sum defining $c$ only has a finite number of non-zero terms, we just have to show that for any $j \in \Z$, the function $c_{j}(k,i) \isdef a(k-j,i-j) b(k,j)$ satisfies
%	\[\forall \alpha \in \N, \forall i,k, \in \Z, \quad  \abs{\Delta_k^\alpha c_{j}(k,i)} \leq C_{i,j,\alpha} (1 + k^2)^{p + q - \alpha}.\]
%	The announced result then follows by linearity. 
%	To prove this, one can check by induction that for any $\alpha \in \N$, $\Delta^\alpha c_j(k,i)$ is of the form 
%	\[\Delta^\alpha_k c_j(k,i) = \sum_{l = 1}^L \lambda_l \Delta_k^{\beta_l}a(k_{l,1},i-j) \Delta_k^{\alpha - \beta_l} b(k_{l,2},j)\]
%	for some coefficients $\lambda_l$, where $L$ is a finite number, and where, for all $l$, $\beta_l \leq \alpha$ while $k_{l,1}$ and $k_{l,2}$ respectively lie in the interval $[k-j,k-j + \beta_l]$ and $[k,k+\alpha - \beta_l]$. Let us fix $l \in [1,L]$. We have
%	\[\abs{\Delta_k^{\beta_l} a(k_{l,1},i-j)} \leq C_{i,j,\alpha,l}(1 + k_1)^{p - \beta_l}\]
%	and by Peetre's inequality
%	\[(1+k_1)^{p - \beta_l} \leq C(1+k)^{p - \beta}(1 + \alpha + \abs{j})^{\abs{p - \beta_l}}.\]
%	The same arguments applied to $b$ lead to 
%	\[\abs{\Delta_k^{\beta} a(k_1,i-j)\Delta_k^{\alpha - \beta} b(k_2,j)} \leq C_{i,j,\alpha,l} (1+k)^{p + q}\]
%	which implies our claim. 
%\end{proof}
%\begin{The}
%	If $A \in S^{p}$ and $B \in S^q$, then $AB - BA$ is in $S^{p + q + 1}$. 
%	\label{CommutPDO}
%\end{The}
%\begin{proof}
%	A symbol of $C= AB - BA$ is given by
%	\[\sigma_{C}(k,i) = \sum_{j = -\infty}^{+\infty} a(k-j,i-j)b(k,j) - \sum_{j = - \infty}^{+\infty} b(k-j,i-j) a(k,j).\]
%	In the second sum, we change the index to $j' = i -j$, yielding 
%	\begin{eqnarray*}
%		\sigma_{C}(k,i) &=& \sum_{j = -\infty}^{+\infty} a(k-j,i-j)b(k,j) - \sum_{j = - \infty}^{+\infty} b(k-i +j',j') a(k,i-j').\\
%		&=& \sum_{j = -\infty}^{+\infty} \left[a(k-j,i-j) - a(k,i-j)\right]b(k,j) \\
%		&& - \sum_{j = - \infty}^{+\infty} a(k,i-j) \left[b(k - i + j') -b(k,j)\right].\\
%	\end{eqnarray*}
% 	Let us consider one of the terms of the first sum when $j$ is positive. We can write 
%\begin{eqnarray*}
%	\left[ a(k-j,i-j) - a(k,i-j)\right]b(k,j) = - \sum_{l = 0}^{j-1} \Delta_k a(k-j + l+1,i-j)b(k,j).
%\end{eqnarray*}
%The estimation (ii) required for the symbol $\sigma_C$ can be established for this individual term from the same considerations as in the proof of the previous result. The other terms are treated in an analogous way.  
%\end{proof}
%\subsubsection{Symbolic calculus}
%
%For a couple of (semi-discrete or continuous) symbols $a_1,a_2$, let $H$ the operator defined by 
%\[H(a_1,a_2) = (-\omega \partial_x \omega a_2, \partial_x a_1)\]
%and let the multiplication of couples of symbols be defined by 
%\[(a_1,a_2) \times (b_1,b_2) = (a_1b_1 - \omega^2 a_2b_2, a_1b_2 + a_2 b_1)\,.\]
%
%Let $\nu = (\nu_1,\nu_2)$ a couple of continuous symbols of an operator in $S^p$. For all $\alpha \in \N$, we write $\partial_n^\alpha \nu \isdef (\partial_\xi^\alpha \nu_1, \partial_\xi^\alpha \nu_2)$. This is of course a couple of continuous symbols for an operator in $S^{p + \alpha}$. 
%\begin{Lem}
%	Let $(a_1,a_2)$ and $(b_1,b_2)$ two couple of symbols of two operators $A \in S^p$ and $B \in S^q$. Then $H(a_1,a_2)$ is a couple of symbols for an operator in $S^p$ and $(a_1,a_2) \times (b_1,b_2)$ is a couple of symbols for an operator in $S^{p+q}$. 
%\end{Lem}
%\toDo{Preuve pédestre de ça.}
%\toDo{Definition of Asymptotic expansion}
%
%\begin{The}
%	Let $A \in S^p$ and $B \in S^q$ with respctive couples of continuous symbols $a = (a_1,a_2)$ and $b = (b_1,b_2)$. Then a couple of continuous symbols $c = (c_1,c_2)$ of $C = AB$ is given by 
%	\[c = \sum_{\alpha = 0}^{+ \infty} \frac{1}{\alpha!}\partial_\xi^\alpha a \times H^k(b) \]
%\end{The}
%\begin{proof}
%	\toDo{Appliquer les résultats connus pour les opérateurs discrets, ou simplement reproduire la preuve qui est tout simple ici.}
%\end{proof}
%
%\begin{Lem}
%	\label{lem:multPolyOrdre0}
%	If $P$ is a polynomial, the multiplication by $P$ defines an operator of $S^0$. 
%\end{Lem}
%\begin{proof}
%	For all $n$, we have $xT_n = \frac{T_{n+1} + T_{n-1}}{2}$, thus $x$ is in the class $S^0$. By \autoref{LemCompo}, the same is true for $x^n$ for any $n$, and by linearity, for any polynomial. 
%\end{proof}
%The next two lemmas enlarge the class of operators for which we can assess the order. \autoref{ordreNoyauxMultipl} allows us to treat a rather general class of operators and will allow us to evaluate the order of the remainders in Taylor expansions of the kernels. 
%\begin{Lem}
%	\label{lem:multByPsiOrdre0}
%	If $\psi$ is a $C^{\infty}$ function on $[-1,1]$, then the operator
%	\[ u(x) \mapsto \psi(x) u(x)\]
%	is of order $0$, and for any $s \in \R$, 
%	\[ \norm{\psi u}_{T^s} \leq C2^{\abs{s}/2}\norm{u}_{T^s} \norm{\psi}_{T^{\abs{s}+1}}.\]
%	where $C$ is independent of $\psi$ and $s$. 
%\end{Lem}
%\begin{proof}
%	Let $u \in T^s$, we rewrite $u$ as 
%	\[ u = \sum_{n = -\infty}^{+ \infty}u_n'T_n\]
%	where for $n< 0$ we define $T_{n} = T_{\abs{n}}$, and with 
%	\[u_n' = \begin{cases}
%	u_0 & \text{ if } n = 0\\
%	\frac{u_{\abs{n}}}{2} & \text{ otherwise.}
%	\end{cases}\]
%	We apply the same idea to $\psi$, and using $T_m T_n = T_{m+n} + T_{m-n}$, 
%	\[\psi u = \sum_{m,n} u'_n \psi'_m (T_{m+n} + T_{m-n}) = \sum_{m} \left(\sum_{n}u'_n(\psi'_{n + m} + \psi'_{n - m})\right) T_m\]
%	that is,
%	\[\psi u = 2\sum_{m,n} u'_m \psi'_{m-n} T_{n}\]
%	Using Peetre's inequality, we have 
%	\[(1 + n^2)^{s/2}\abs{(\psi u)_n} \leq 2^{\abs{s}/2+1}\sum_{m}(1 + m^2)^{s/2} \abs{u'_m}  (1 + |n-m|^2)^{\abs{s/2}} \abs{\psi'_{n-m}} \]
%	and by Young's inequality with $r = 2, p = 2, q = 1$, 
%	\[\norm{\psi u}_s^2 \leq 2^{\abs{s}+2}\norm{u}_s^2 \sum_{m=-\infty}^{+\infty} (1 + m^2)^{\abs{s}/2}\abs{\psi'_m} \]		
%	The last sum is finite because $\psi \in T^{\infty}$ and
%	\[\sum_{m=-\infty}^{\infty}(1 + m^2)^{\abs{s}/2} \abs{\psi'_m} \leq \left(\sum_{m = -\infty}^{+ \infty} \frac{1}{1 + m^2} \right)\sum_{m=-\infty}^{+\infty} (1 + m^2)^{\abs{s}+1}\abs{\psi'}_m^2.\]
%\end{proof}
%\begin{Lem}
%	\label{ordreNoyauxMultipl}
%	Let $G$ an integral operator with kernel $g$, that is
%	\[G : u \mapsto \int_{-1}^{1} \frac{g(x,y) u(y)}{\omega(y)}dy\,.\]
%	We assume that $G$ is of order $p$. Let $r(x,y)$ a $C^{\infty}$ function. Then the operator 
%	\[K : \int_{-1}^{1} \frac{g(x,y) r(x,y) u(y)}{\omega(y)}dy\]
%	is of order $p$. 
%\end{Lem}
%\begin{proof}
%	Since $r$ is in $C^{\infty}$, one can show that $r$ admits the following expression:
%	\begin{equation}
%	r(x,y) = \sum_{m,n} r_{m,n} T_m(x) T_n(y)
%	\label{sommenormalementcv}
%	\end{equation}
%	Moreover, the regularity of $R$ ensures $r_{m,n}$ satisfies for all $s,t \in \R$, 
%	\[\sum_{m,n} (1 + m^2)^s (1 + n^2)^t\abs{r_{m,n}}^2 < +\infty.\] 
%	To prove this property, one can for example apply the operator $(\omega \partial_x)^2$ repeatedly in the two variables. The resulting function is $C^\infty$, and in particular, square integrable on $[0,1] \times [0,1]$. We then write the Parseval's identity and the result follows. We can write 
%	\[Ku = \sum_{m,n} r_{m,n} T_m G T_n u  \]
%	where for each $m,n$, the operator $T_m G T_n$ is defined by 
%	\[ T_m G T_n u (x)= T_m(x) \int_{-1}^{1} \dfrac{G(x,y) T_n(y)u(y)}{\omega(y)}dy.\]
%	Fix $s \in \R$, this operator is in $L(T^s,T^{s+p})$ by the previous lemma, with 	
%	\[\norm{T_m G T_n}_{T^s \to T^{s+p}} \leq \norm{G}_{T^s \to T^{s + p}} 2^{\abs{s} + \abs{s + p}}(1 + n^2)^{\abs{s}+1}(1 + m^2)^{\abs{s+ p} + 1}.\]
%	thus, the series in \eqref{sommenormalementcv} is normally convergent in $L(T^s, T^{s + p})$, which proves the claim. 
%\end{proof}
%As a consequence, since the operator $G$ with kernel $g \equiv 1$ is a smoothing operator, we have the following result:
%\begin{Cor}
%	\label{lemSmoothingOp}
%	Let $r \in C^{\infty}([-1,1]^2)$. Then
%	\[ u \mapsto \int_{-1}^{1} \frac{r(x,y)u(y)}{\omega(y)}dy\]
%	is a smoothing operator. 
%\end{Cor}


\section{Paramatrix for the layer potentials}

We now apply the pseudo-differential theory on $T^s(\Gamma)$ and $U^s(\Gamma)$ to build parametrix for the weighted layer potentials introduced at the beginning of the second section. 

\subsection{Dirichlet problem}

\begin{Lem}
	\label{LemsymbolSk}
	The operator $S_{k,\omega_\Gamma}$ belongs to $\textit{Op}(S^{-1}_T(\Gamma))$, and satisfies	
	\[\mathcal{C}RS_{k,\omega_\Gamma}R^{-1} = \tilde{S}_k \mathcal{C}\]
	where the symbol of $\tilde{S}_k \in \textit{Op}(\Sigma^{-1})$ has the asymptotic expansion
	\begin{equation}
		\begin{split}
		\sigma_{\tilde{S}_k}(\theta,\xi)&=\displaystyle \frac{1}{2\xi}+\frac{k^2\abs{\Gamma}^2\sin(\theta)^2}{16\xi^3}+{\frac {3i{k}^{2}{\abs{\Gamma}}^{2}\sin \theta \cos \theta }{16{\xi}^{4}}}\\
		+ &\frac{-768 k^2 \kappa(\theta)^2 \sin^4\theta + 64k^2\abs{\Gamma}^2 \sin^2 \theta - 48k^2\abs{\Gamma}^2 \cos^2\theta + 3k^4 \abs{\Gamma}^4 \sin^4\theta}{128 \xi^5}\\
		+ & \Sigma^{-6}\,.
		\end{split}
		\label{symboleSk}
	\end{equation}
\end{Lem}
\begin{proof}
	The Hankel function admits the following expansion
	\begin{equation}
	\label{decompHankel}
	H_0(z) = \frac{-1}{2\pi}\ln|z| J_0(z) + F_1(z^2)
	\end{equation}
	where $J_0$ is the Bessel function of first kind and order $0$ and where $F_1$ is analytic. Let us define 
	\[S_{k,\omega} \isdef R S_{k,\omega_{\Gamma}} R^{-1}\,.\] 
	We fix a smooth function $u \in T^{\infty}$. One has
	\[\left(S_{k,\omega} u\right)(x) = \int_{-1}^1 H_0\left(k\abs{r(x) - r(y)}\right)\frac{u(y)}{\omega(y)}dy\,.\]
	Using the variable changes $x = \cos\theta$, $y = \cos \theta'$, we get 
	\[ S_{k,\omega} u(\cos \theta) = \int_{0}^\pi H_0(k \abs{r(\cos \theta) - r(\cos \theta')}) u(\cos(\theta)) d\theta\,,\]
	which, in view of \eqref{decompHankel}, can be rewritten as
	\[\begin{split}
	S_{k,\omega} u(\cos \theta) = &\frac{-1}{2\pi}\int_{0}^\pi \ln \abs{\cos \theta - \cos \theta'} J_0(k \abs{r(\cos \theta) - r(\cos \theta')})\mathcal{C}u(\theta) d\theta \\
	&+ \int_{0}^\pi F_2(\cos\theta,\cos\theta') \mathcal{C}u(\theta) d\theta'
	\end{split}\]
	where 
	\[F_2(x,y) = \ln \frac{\abs{r(x)-r(y)}}{\abs{x-y}} + F_1(k^2(x - y)^2)\,\]
	is a $C^\infty$ function. 
	By parity, the second integral defines an operator 
	\[Ku(\theta) = \frac{1}{2} \int_{-\pi}^{\pi} F_2(\cos\theta,\cos\theta') \mathcal{C}u(\theta) d\theta.\]
	There holds $K = \tilde{R}_1\mathcal{C}$ where, by \autoref{thrunen}, $R_1 \in \textit{Op}(\Sigma^{-\infty})$. For the first integral, we make the following classical manipulations. We first write $\cos \theta - \cos\theta' = - 2 \sin \frac{\theta + \theta'}{2}\sin \frac{\theta - \theta'}{2}$. Thus $\ln\abs{\cos \theta - \cos\theta'}= \ln \abs{\sqrt{2} \sin \frac{\theta + \theta'}{2}} + \ln \abs{\sqrt{2}\sin \frac{\theta - \theta'}{2}}$. We then integrate and apply the change of variables $\theta \to - \theta$ for the second term, yielding
	\[S_{k,\omega}u(\cos\theta) = \left(\tilde{S}_{k,1} + \tilde{R}_1 \right)\mathcal{C}u(\theta)\]
	where
	\[\begin{split}
	\tilde{S}_{k,1}u(\theta) = &\frac{-1}{2\pi} \int_{-\pi}^\pi \ln \abs{\sqrt{2} \sin \frac{\theta - \theta'}{2}}J_0(k\abs{r(\cos\theta) - r(\cos \theta')})u(\theta')d\theta'\,.
	\end{split}\]
	Let $g : \theta \mapsto -\frac{1}{2\pi}\ln \abs{\sqrt{2} \sin \frac{\theta}{2}}$. It is well-known that $\hat{g}(n) = \frac{1}{2n}$ for $n \neq 0$. We may prolong this by $g(\xi) = \frac{1}{2\xi}$ away from $\xi = 0$. Let $a(\theta,\theta') = J_0(k\abs{r(\cos \theta ) - r(\cos \theta')})$, which is a smooth function. By \autoref{thrunen}, the operator
	\[\tilde{S}_{k,1} u(\theta) \isdef \int_{-\pi}^\pi g(\theta-\theta') a(\theta,\theta')u(\theta')d\theta'\]
	is in $\textit{Op}(\Sigma^{-1})$. In particular, $\tilde{S}_{k,1}u$ is a smooth function, from which we deduce that $\theta \mapsto S_{k,\omega}u(\cos\theta)$ is a smooth (even) function. \autoref{lemChar} then ensures 
	\[S_{k,\omega}u(\cos\theta) = \mathcal{C} S_{k,\omega}u(\theta)\,.\] 
	This establishes that $\mathcal{C} S_{k,\omega}u = \tilde{S}_k \mathcal{C}u$ for any smooth function $u$. By \autoref{PDOTs}, this implies that $S_{k,\omega} \in \textit{Op}\left(S_T^{-1}\right)$. We can compute the symbol of $\tilde{S}_{k,1}$ using the asymptotic expansion \eqref{FormuleIntegralOperatorSymbol}. The terms $\partial_s^ja(t,s)_{|t=s}$, can be related to the geometric characteristics of $\Gamma$ through expansion \eqref{expansion_r}. Using a computer calculator, we find that the the rhs of \eqref{symboleSk} is an asymptotic expansion of $\tilde{S}_{k,1}$. Obviously, this expansion also holds for $\tilde{S}_k \isdef \tilde{S}_{k,1} + \tilde{R}_1$, which proves the results.
\end{proof}
\noindent In particular, by \autoref{CorContinuitePDOTs},
\begin{Cor}
	$S_{k,\omega_\Gamma}$ is continuous from $T^s(\Gamma)$ to $T^{s+1}(\Gamma)$ for all $s\in \R$ and thus maps $\Cinf(\Gamma)$ to itself. 
\end{Cor}
\begin{Lem}
	\label{LemsymbolDk}
	The operator $-(\omega_\tau \partial_\tau)^2 - k^2 \omega_\Gamma^2$ is in $\textit{Op}(S_{T}^2(\Gamma))$ and satisfies 
	\[\mathcal{C}R\left[-(\omega_\tau \partial_\tau)^2 - k^2 \omega_\Gamma^2\right]R^{-1} = \tilde{D}_k\mathcal{C}\] 
	where $\tilde{D}_k \in \textit{Op}(\Sigma^2)$ has the following symbol
	\begin{equation}
		\sigma_{\tilde{D}_k}(\theta,\xi) = \abs{\xi}^2 - k^2 \abs{\Gamma}^2 \sin^2(\theta)\,.
		\label{symbolDk}
	\end{equation}
\end{Lem}
\begin{proof}
	Recalling \cref{param1,param2}, one has 
	\[-(\omega_\Gamma)^2 - k^2 \omega_\Gamma^2 = R^{-1} \left[-(\omega \partial_x)^2 - k^2 \omega^2\right]R\,.\]
	Letting $D_k = -(\omega \partial_x)^2 - k^2 \omega^2$,
	\[D_k T_n = (n^2 - k^2\abs{\Gamma}^2\omega^2)T_n\,.\]
	The result is then a consequence of \autoref{PDOTs}.
\end{proof}
\begin{The}
	\label{TheSkomega}
	The operators $\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]$ and  $S_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_T(\Gamma))$ and $\textit{Op}(S^{-1}_T(\Gamma))$ and satisfy
	\[\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right] S_{k,\omega_\Gamma}^2 = \frac{I_d}{4} + T_{-4}.\]
\end{The}
%\begin{proof}
%	Let 
%	\[J_1 =R \left(\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right] S_{k,\omega_\Gamma}^2 - \frac{I_d}{4}\right) R^{-1}\]
%	Combining \autoref{LemsymbolSk} and and \autoref{LemsymbolDk}, we have $\mathcal{C} J_1 = \tilde{J}_1\mathcal{C}$ where 
%	\[\tilde{J}_1 = \left(\tilde{D_k} \tilde{S}_k^2  - \frac{I_d}{4}\right)\]
%	Using symbolic calculus, one can check that the symbol of $\tilde{J}_1$ is in $\Sigma^{-4}$, thus $J_1 \in \textit{Op}(S^{-4}_T)$. By definition, this means that $R^{-1}J_1 R \in \textit{Op}(S_T^{-4}(\Gamma))$, which implies the result.  
%\end{proof}
%\toDo{Ou bien pour utiliser le calcul symbolique directement dans les $T^s(\Gamma)$} 
\begin{proof}
	We have shown that $\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]$ and  $S_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_T(\Gamma))$ and $\textit{Op}(S^{-1}_T(\Gamma))$ in the previous two lemmas. Using the method described in \autoref{RemSymb}, we can compute an asymptotic expansion of the symbol of the pseudo-differential operator \[\left[-(\omega_\Gamma \partial_\tau)^2 - k^2\omega_\Gamma^2\right]S_{k,\omega_\Gamma}^2 - \frac{I_d}{4}\,.\] 
	The symbol of this operator is found to be in $S^{-4}_T(\Gamma)$, from which the result follows.  
\end{proof}
\begin{Rem}
	The previous theorem implies the following fact
	\[-(\omega_\Gamma \partial_\tau)^2 S_{k,\omega_\Gamma}^2 = \frac{I_d}{4} + R\]
	where $R$ is in $\textit{Op}(S^2_T(\Gamma))$. This is also a compact perturbation of the identity. Nevertheless, since $R = k^2 \omega_\Gamma^2 S_{k,\omega_\Gamma}^2 + T_{-4}$ the term $k^2 \omega^2S_{k,\omega}^2$ can be viewed as the leading first order correction accounting for the wavenumber. The inclusion of this term in the preconditioner leads to a drastic reduction of the number of GMRES iterations in numerical applications, as demonstrated in \cite{alouges2018new}. 
\end{Rem}


%Using the power series definition of $J_0$, this gives
%\begin{align}
%	\begin{split}
%	\frac{i}{4}H_0(k \abs{x - y}) &= \frac{-1}{2\pi}\ln |x-y| \label{decompHankel}\\ 
%	&\quad + \frac{1}{2\pi} \frac{k^2}{4} (x- y)^2 \ln |x-y|\\
%	&\quad + (x-y)^4 \ln|x-y|F_2(x,y) + F_3(x,y)
%	\end{split}
%\end{align}
%\noindent where $F_2$ and $F_3$ are $C^{\infty}$. Let us study the operators $O_n$ defined for $n \geq 1$ as 
%\[O_n : \alpha \mapsto -\frac{1}{2\pi}\int_{-1}^{1}(x-y)^{n-1} \ln\abs{x - y} \frac{\alpha(y)}{\omega(y)}\,.\]
%\begin{Lem}
%	\label{orderOfOn}
%	For every $n$, $O_n$ is in the class $S^n$. 
%\end{Lem}
%\begin{proof}
%	This can be shown by a simple induction. $O_1$ is just $S_\omega$, which is indeed in $S^1$. Let $n \geq 2$, and assume $O_{n-1} \in S^{n-1}$. We have
%	\[ O_n = x O_{n-1} - O_{n-1} x.\]
%	As shown in \autoref{lem:multPolyOrdre0}, the multiplication by $x$ defines an operator of $S^0$. By assumption, $O_{n-1}$ is in $S^{n-1}$, thus \autoref{CommutPDO} implies that $O_{n} \in S^n$, which concludes the proof. 
%\end{proof}
%We define a new operator $y$ defined for $n \geq 1$ by 
%\[y T_n = \frac{T_{n+1} - T_{n-1}}{2}\,.\]
%and $y T_0 = 0$. 
%It is easy to check that $y$ is in $S^0$ and $y^2 = -\omega^2 + T_\infty$. Moreover, $y$ commutes with the multiplication by $x$, and the adjoint of $y$ (in the $L^2_\frac{1}{\omega}$ duality) is $-y$. Since, for $n\geq 0$, $(x+y)T_n = T_{n+1}$ and $(x-y)T_n = T_{n-1}$, we see that any operator in $A \in S^p$ can be expressed as 
%\[ A u = \sum_{n = 0}^{+ \infty} a(x,y,n) \hat{u}_n T_n(x)\]
%where for each $n$, $(x,y) \mapsto a(x,y,n)$ is a polynomial in $x$ and $y$. \toDo{A déplacer probablement.}
%We show an intermediary result:
%\begin{Lem}
%	\label{resultInterm}
%	For all $n \geq 0$, there exists an operator $R_{n+3} \in S^{n+3}$ such that
%	\begin{equation}
%		x S_\omega^n - S_\omega^n x = 2 ny S_{\omega}^{n+1} - 2n(n+1) x S_\omega^{n+2} + R_{n+3}\,.
%	\end{equation}
%\end{Lem}
%\begin{proof}
%	We must show that
%	\[R_{n+2} \isdef x S_\omega^n - S_\omega^n x -2ny S_\omega^{k+1} + 2n(n+1)x S_\omega^{n+2} \]
%	belongs to the class $S^{n+3}$ for all $n \in \N$. For $n = 0$ this is obvious. Let us fix $n \geq 1$. We check the three requirements of \autoref{defClassSk}.
%	Using $x T_k = \frac{T_{k+1} + T_{k-1}}{2}$ and $S_\omega T_k = \sigma_k T_k$, we have
%	\[R_{n+2}T_k = a(k,-1) T_{k-1} + a(k,1) T_{k+1}\]
%	with 
%	\begin{eqnarray*}
%		a(k,1) &=& \frac{\sigma_k^n - \sigma_{k+1}^{n} - 2n \sigma_k^{n+1} + 2n(n+1)\sigma_k^{n+2}}{2}\\
%		a(k,-1) &=& \frac{\sigma_k^n - \sigma_{k-1}^{n} + 2n \sigma_k^{n+1} + 2n(n+1) \sigma_{k}^{n+2}}{2}
%	\end{eqnarray*}
%	The symbol $a$ thus satisfies the requirements (i) and (iii). It remains to show the estimate (ii). We do this for $a(k,1)$, the other case being similar. Of course, it suffices to establish the estimate for $k \geq 1$. In this case, we have $\sigma_k = \frac{1}{2k}$, thus 
%	\[a(k,1) = g(k+1) - g(k) - g'(k) - \frac{g''(k)}{2}\]
%	where 
%	\[g(x) = -\frac{1}{2\times(2x)^{n}}\,.\]
%	Applying $\Delta_k^\alpha$, on both sides and using the commutation of $\frac{d}{dx}$ and $\Delta_k$, we obtain
%	\[a(k,1) = \Delta^\alpha_k g(k+1) - \Delta_k^\alpha g(k) - (\Delta^{\alpha}_k g)'(k) - \frac{\left(\Delta_k^\alpha g\right)''(k)}{2}\,.\]
%	This can be rewritten using Taylor's formula
%	\[a(k,1) = \int_{k}^{k+1}\frac{(k+1 - \xi)^2}{2} \left(\Delta^{\alpha}_k g^{(3)}\right)(\xi) d\xi\,.\]
%	Using \autoref{lemDeltaDerivees} and the explicit derivatives of $g$, for $\xi \geq 1$, there holds
%	\[ \abs{\left(\Delta^{\alpha}_k g^{(3)}\right)(\xi)} \leq \frac{C}{(1 + \xi)^{k + 3+ \alpha }}\]
%	and thus, for $k \geq 1$, 
%	\[\abs{\Delta_k^\alpha a(k,1)} \leq \frac{C}{(1+n)^{n+\alpha+3}}\,,\]
%	as needed. 
%\end{proof}
%With the same method, we obtain:
%\begin{Lem}
%	For all $n \in \N$, 
%	\[y S_\omega^n  - S_\omega^ny = 2nxS_\omega^{n+1} - 2n(n+1)y S_\omega^{n+2} + R_n+2\,.\]
%	with $R_{n+2} \in S^{n+2}$.
%\end{Lem}
%\begin{Lem}
%	For all $n \geq 1$, the operator $O_n$ satisfies 
%	\begin{equation}
%		\label{announced}
%		O_n = 2^{n-1}(n-1)! y^{n-1} S_\omega^{n} + 2^n (n-1) n! xy^{n-1} S_\omega^{n+1} + R_{n+2}
%	\end{equation}
%	where $R_{n+2} \in S^{n+2}$. 
%\end{Lem}
%\begin{proof}
%	We show this by induction. For $n=1$, the formula is obvious, with $R_{n+2} = 0$. Assume that the formula is true for $n \geq 1$. Then by definition, 
%	\[O_{n+1} = x O_n - O_n x\]
%	and using the commutation of $x$ and $y$:
%	\[\begin{split}
%	O_{n+1} =& 2^{n-1}(n-1)! y^{n-1} \left(xS_\omega^{n} - S_\omega^{n}x \right)\\
%	& + 2^n (n-1) n! xy^{n-1}\left(xS_\omega^{n+1} - S_\omega^{n+1}x\right) \\
%	& + \left(xR_{n+2} - R_{n+2}x\right)\,. 
%	\end{split}\]
%	The operator on the last line is in $S^{n+3}$ by \autoref{CommutPDO}. By \autoref{resultInterm}, there exists an operator $R_{n+3} \in S^{n+3}$ such that 
%	\[\begin{split}
%	O_{n+1} = \quad & 2^{n-1}(n-1)! y^{n-1} \left(2ny S_\omega^{n+1} - 2n(n+1)x S_\omega^{n+2}\right)\\
%	& + 2^n (n-1) n! xy^{n-1}\left( 2(n+1)y S_\omega^{n+2} \right) \\
%	& + R_{n+3}\,. 
%	\end{split}\]
%	And we obtain the expected formula for $O_{n+1}$. 
%\end{proof}
%Using the notation introduced in \autoref{DefEquivModTp}, we have the following result:
%\begin{Lem}
%	The operator $S_{k,\omega}$ admits the following expansion 
%	\[ S_{k, \omega} = S_\omega - \frac{k^2}{4} O_3 +  T_5.\]
%	\label{developpementHankel}
%\end{Lem}
%\begin{proof}
%	From equation \eqref{decompHankel}, it suffices to show that the operator 
%	\[R_5 : \alpha \mapsto \int_{-1}^{1} (x-y)^4 \ln|x - y|F_2(x,y)\frac{\alpha(y)}{\omega(y)}\]
%	is of order $5$. Since $O_5$ is of order $5$, this is true in view of \autoref{ordreNoyauxMultipl}.
%\end{proof}
%In particular, the operator $S_{k,\omega}$ is well defined on $T^{-\infty}$, and is of order $1$. 
%\begin{Lem}
%	\label{LemSwDeltaO3}
%	There holds
%	\[S_\omega (\omega \partial_x)^2 O_3 + O_3(\omega \partial_x)^2 S_\omega = 4S_\omega\omega^2S_\omega + T_4.\]
%\end{Lem}
%\begin{proof}
%	We have $S_\omega \in S^1$, $O_3 \in S^3$ and $(\omega \partial_x)^2 \in S^{-2}$. 
%\end{proof}
%\begin{The} There holds
%	\label{TheHelmholtz}
%	\[\left[-(\omega \partial_x)^2 - k^2\omega^2\right]S_{k,\omega}^2 = \frac{I_d}{4} + T_4.\]
%	\begin{proof}
%		Using the expansion of \autoref{developpementHankel}, we can write 
%		\begin{eqnarray*}
%			-S_{k,\omega}(\omega \partial_x)^2 S_{k,\omega} &=& -S_\omega (\omega \partial_x)^2 S_\omega \\
%			&& + \frac{k^2}{4}\left(S_\omega (\omega \partial_x)^2 O_3 + O_3 (\omega \partial_x)^2 S_\omega\right) + T_4
%		\end{eqnarray*}
%		By \autoref{TheSdx2S}, the first term is $\frac{Id}{4} + T_\infty$ and by \autoref{LemSwDeltaO3} the second term is $k^2 \omega^2 + T_ 4$
%		Finally, using \autoref{developpementHankel}, on can check that
%		\[S_\omega \omega^2 S_\omega =  S_{k,\omega} \omega^2 S_{k,\omega} + T_4\]
%		We have thus proved 
%		\[-S_{k,\omega} (\omega \partial_x)^2 S_{k,\omega} = \frac{I_d}{4} + k^2S_{k,\omega} \omega^2 S_{k,\omega} + T_4.\]
%		If we substract the term $k^2 S_{k,\omega} \omega^2 S_{k,\omega}$ of each side, and use the first commutation proved in \autoref{Commutations}, we finally get 
%		\[ \left[-(\omega \partial_x)^2 - k^2 \omega^2\right]S_{k,\omega}^2  = \frac{I_d}{4} + T_4,\]
%		and the result is proved. 
%	\end{proof}
%\end{The}
%Recall that $\lambda_{n,k}^2$ are the eigenvalues of $-(\omega \partial_x) - k^2\omega^2$. Let $s_{n,k}$ the eigenvalues of $S_{k,\omega}$ on the basis of Mathieu cosines, that is
%\[S_{k,\omega}T_{n}^k = s_{n,k}T_n^k.\]
%The previous theorem has the following consequence:
%\begin{Cor}
%	One has
%	\[s_{n,k} \lambda_{n,k} = \frac{1}{4} + r_{n,k}\]
%	where $r_{n,k}$ satisfies 
%	\[\sum_{n = 0}^{+ \infty}(1 + n^2)^4 \abs{r_{n,k}}^2  < + \infty\]
%\end{Cor}
%
%The results of this section prompt us to use $\sqrt{-(\omega \partial_x)^2 - k^2\omega^2}$ as a preconditioner for $S_{k,\omega}$. 
%\toDo{Problème d'inversibilité possible pour certaines valeurs de $k$. Je n'arrive pas à l'écarter.}



\subsection{Neumann problem}

We saw in \autoref{NkomegaSkomega} that $N_{k,\omega_\Gamma} = N_1 - k^2N_2$ where 
\[N_1 = -\partial_\tau S_{k,\omega} \omega_\Gamma \partial_\tau \omega_\Gamma\]
and $N_2 = V_k\omega_\Gamma^2$ with
\[V_ku(x) = \int_{\Gamma} \frac{G_k(x-y)N(x)\cdot N(y) u(y)}{\omega_\Gamma(y)}d\sigma(y)\,.\]
\begin{Lem}
	\label{LemsymbolN1}
	The operator $N_1$ is in $\textit{Op}(S_U^2(\Gamma))$ and  
	\[\mathcal{S}RN_1R^{-1} = \tilde{N}_1 \mathcal{S}\]
	where $\tilde{N}_1$ is a PPDO with a symbol $\sigma_{\tilde{N}_1}$ satisfying
	\begin{equation}
		\sigma_{\tilde{N}_1}(\theta,\xi) = \frac{\xi}{2} + \frac{1}{16}\frac{k^2 \abs{\Gamma}^2 \sin^2(\theta)}{\xi} + i\frac{k^2 L^2 \sin\theta\cos\theta}{16\xi^2} + \Sigma^{-3}
		\label{symboleN1}
	\end{equation}
\end{Lem}
\begin{proof}
%	Using \autoref{Lem:dthetaAdtheta} and \autoref{LemsymbolSk}, we find that $N_1$ is in $\textit{Op}(S_U^1)$ and satisfies 
%	\[\mathcal{S}N_1 = \tilde{N}_1 \mathcal{S}\]
%	where $\tilde{N}_1 = -\partial_\theta \tilde{S}_{k} \partial_\theta$. The announced formula can then be checked using symbolic calculus. 
%	\toDo{Ou bien}
This result is obtained by symbolic calculus combining \autoref{LemsymbolSk} and \autoref{LemdxAomegadeomega}.
\end{proof}
\noindent A small adaptation of the proof of \autoref{LemsymbolSk} yields the following result:
\begin{Lem}
	\label{LemsymbolVk}
	The operator $V_k$ is in $\textit{Op}(S_T^{-1}(\Gamma))$ and 
	\[\mathcal{C}RV_kR^{-1} = \tilde{V}_k \mathcal{C}\]
	where $\tilde{V}_k$ is a PPDO with a symbol $\sigma_{\tilde{N}_2}$ satisfying
	\[\sigma_{\tilde{V}_k} = \frac{1}{2\xi} + \Sigma^{-3}\]

\end{Lem}
%\begin{proof}
%	The symbol 
%	Let $u$ a smooth function. Using the variable change $y = \cos\theta'$, one has
%	\[\begin{split}
%	\sin\theta N_2u(\cos\theta) = \tilde{N}_2 \mathcal{S}u\,, 
%	\end{split}\]
%	where $\tilde{N}_2$ is the integral operator defined by
%	\[\tilde{N}_2u(\theta) = \int_{0}^{\pi}K(\theta,\theta')u(\theta')d\theta\]
%	with 
%	\[K(\theta, \theta') = G_k(\cos\theta - \sin\theta)\sin\theta \sin \theta' n(\cos\theta) \cdot n(\cos\theta')\,.\]
%	The same arguments as in \autoref{LemsymbolSk} show that 
%	\[\tilde{N}_2 u = \int_{-\pi}^{\pi} g(\theta - \theta') b(\theta,\theta')u(\theta')d\theta' + R_2 u\]
%	where $R_2 \in \textit{Op}(\Sigma^{-\infty})$ and 
%	\[b(\theta,\theta') = a(\theta,\theta')\sin\theta \sin \theta' n(\cos\theta) \cdot n(\cos\theta')\,.\] 
%	This implies that $\tilde{N}_2$ is a PPDO of order $-1$. In particular, $\tilde{N}_2 u$ is smooth, therefore by \autoref{lemChar}, $N_2 u$ is smooth and
%	\[\sin\theta N_2u(\cos\theta) = \mathcal{S} N_2u(\theta)\,.\]
%	We have established that $\mathcal{S}N_2u = \tilde{N}_2\mathcal{S}u$ for any smooth function $u$. By \autoref{PDOUs}, this implies that $N_2 \in \textit{Op}(S_U^{-1})$. We can compute the symbol of $\tilde{N}_2$ using the asymptotic expansion \eqref{FormuleIntegralOperatorSymbol}. Like in \autoref{LemsymbolSk}, the derivatives of $b$ can be computed in terms of the geometric characteristics of $\Gamma$ using the expansion \eqref{expansion_r} and \[n(x)\cdot n(y) = 1 - \kappa^2(x) (x-y)^2 + O\left((x-y)^3\right)\,.\] 
%	One can then compute an asymptotic expansion of the symbol of $\tilde{N}_2$ using \autoref{thrunen}, which results in expression \eqref{symboleN2}.
%\end{proof}
\noindent Applying \autoref{LemAomega2}, we deduce
\begin{Cor}
	The operator $N_2$ is in $\textit{Op}(S^{-1}_U(\Gamma))$ and satisfies
	\[\mathcal{S} RN_2R^{-1} = \tilde{N}_2 \mathcal{S}\]
	where the symbol of $\tilde{N}_2$ has the asymptotic expansion
	\begin{equation}
		\sigma_{\tilde{N}_2} = \frac{\sin^2\theta}{2\xi} + i\frac{\sin\theta \cos \theta}{2 \xi^2} + \Sigma^{-3}\,.
		\label{symboleN2}
	\end{equation}
\end{Cor}
\noindent It is also easy to check that
\begin{Lem}
	\label{LemsymbolDkBis}
	The operator $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$ is in $\textit{Op}(S_U^2(\Gamma))$ and satisfies 
	\[\mathcal{S} R\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]R^{-1}  = \tilde{D}_k \mathcal{S}\]
	where $\tilde{D}_k$ is the operator defined in \autoref{LemsymbolDk}.
\end{Lem}
\begin{The}
	\label{TheNkomega}
	The operators $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$ and  $N_{k,\omega_\Gamma}$ are respectively in $\textit{Op}(S^{2}_U(\Gamma))$ and $\textit{Op}(S^{1}_U(\Gamma))$and satisfy
	\[N_{k,\omega_\Gamma}^2 = \left[-(\partial_\tau \omega_\Gamma)^2 - k^2 \omega_\Gamma^2\right] + U_{-2}. \]
\end{The}
\begin{proof}
%	Let 
%	\[J_2 = R\left( N_{k,\omega_\Gamma}^2 - \left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]\right)R^{-1}\,,\]
%	The results of this section imply $\mathcal{S}J_2 = \tilde{J}_2 \mathcal{S}$
%	with
%	\[\tilde{J}_2 = \left( \tilde{N}_1 - \frac{k^2\abs{\Gamma}^2}{4} \tilde{N_2}\right)^2 - \tilde{D}_k\]
%	Using symbolic calculus and \cref{symboleN1,symboleN2,symbolDk} one can check that the symbol of $\tilde{J}_2$ is in $\Sigma^{-2}$, thus $J_2 \in \textit{Op}(S_U^{-2})$. By definition, $R^{-1}J_2 R$ is thus in $\textit{Op}(S_U^{-2}(\Gamma))$ and the result is proved. 
%	\toDo{Ou bien}
	Gathering the previous lemmas, we have asymptotic expansions available for the symbols of the operators $N_{k,\omega_\Gamma}$ and $\left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$. We can thus, using the method of \autoref{RemSymb}, compute an asymptotic expansion of the symbol of the operator $N_{k,\omega_\Gamma}^2 - \left[-(\partial_\tau \omega_\Gamma )^2 - k^2\omega_\Gamma^2\right]$
	which turns out to be in $S^{-2}_U(\Gamma)$, giving the result. 
\end{proof}

\section{Conclusion}

This work gives a complete mathematical analysis of the matters exposed in \cite{alouges2018new}, where it is explained how the parametrix built for the layer potentials can be exploited to get efficient preconditioners in the resolution of the first kind integral equations by the Galerkin method of the second section. One could also derive expressions of parametrix to further orders, to include corrective terms accounting for the curvature of the curve. Moreover, it should be possible to extend the pseudo-differential theory exposed here to three space dimensions by using pseudo-differential operators on the sphere rather than the PPDOs considered here. 

\toDo{J'ai fait cette conclusion à la va vite, je me demande s'il faut en mettre une.}

%\section{Proof of \autoref{the:ParametrixNkomega}}
%\label{ParametrixNkomega}
%From equation \eqref{NkenfonctiondeSk}, we can deduce the following formula for the weighted operator:
%\begin{equation}
%\label{developNkomega}
%N_{k,\omega} = - \partial_x S_{k,\omega} \omega \partial_x \omega - k^2 S_{k,\omega} \omega^2
%\end{equation}
%If we define $L_n \isdef - \partial_x O_{n+2} \omega \partial_x \omega$, then using the mapping properties of $\partial_x$ and $\omega\partial_x\omega$ given by \autoref{derivations}, and since, by \autoref{orderOfOn}, $O_{n+2}$ is of order $n+2$ in the scale $T^s$, we deduce that $L_n$ is of order $n$ in the scale $U^s$. 
%The expansion obtained for the weighted single-layer operator in \autoref{developpementHankel} yields the following expansion for $N_{k,\omega}$. 
%\begin{Lem}
%	\[N_{k,\omega} = N_\omega + k^2 \left( -\frac{L_1}{4}- S_\omega \omega^2 \right) + U_3\]
%\end{Lem}
%\noindent As a consequence, $N_{k,\omega}$ is an operator of order $-1$ in the scale $U^s$. 
%Using equation \eqref{developNkomega}, we have the following expression:
%\[N_{k,\omega}^2 = N_\omega^2 - k^2\left( \frac{L_1 N_\omega + N_\omega L_1}{4} + N_\omega S_\omega \omega^2 + S_\omega \omega^2 N_\omega\right) + U_2.\]
%We have proved in
%By definition, $L_1 = -\partial_x O_3 \omega \partial_x \omega$, while $N_\omega = - \partial_x S_\omega \omega \partial_x \omega$, thus
%\[L_1 N_\omega = \partial_x (O_3 (\omega \partial_x)^2 S_\omega ) \omega \partial_x \omega.\]
%Moreover, 
%\[N_\omega L_1 =  \partial_x (S_\omega (\omega \partial_x)^2 O_3  ) \omega \partial_x \omega.\]
%Adding these two inequalities and using \autoref{LemSwDeltaO3}, we get 
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} =\partial_x ( S_\omega \omega^2 S_\omega ) \omega \partial_x \omega + U_2.\]
%Here again, we use the formula $\partial_x S_\omega \omega^2 = S_\omega \omega \partial_x \omega$, which yields
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} = S_\omega \omega \partial_x \omega \partial_x S_\omega \omega^2 = \left(-\frac{I_d}{4} + T_\infty\right)\omega^2 .\]
%Since $\omega^2$ is continuous from $U^s$ to $T^s$ by \autoref{omega2continuUsTs} and using the injections $T^s\subset U^s$, any operator of the form $R \omega^2$ is smoothing in the scale $U^s$ as soon as $R$ is smoothing in the scale $T^s$. Therefore, 
%\[\frac{L_1 N_\omega + N_\omega L_1}{4} = -\frac{\omega^2}{4} + U_\infty.\]
%Moreover, we have
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega &=& -S_\omega \omega^2 \partial_x S_\omega \omega \partial_x \omega\\
%	&=& -S_\omega \omega^2 \partial_x^2 S_\omega \omega^2
%\end{eqnarray*}
%using again \autoref{dxSomega2=Somegadxomega}. Since $\omega^2 \partial_x ^2 = (\omega \partial_x)^2 + x \partial_x$, we get
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega &=& \frac{\omega^2}{4} - S_\omega x \partial_x S_\omega \omega^2 + U_\infty
%\end{eqnarray*}
%Futhermore, 
%\begin{eqnarray*}
%	N_\omega S_\omega \omega^2 &=& -\partial_x S_\omega \omega \partial_x \omega S_\omega \omega^2.
%\end{eqnarray*}
%We use $\omega \partial_x \omega = \omega^2 \partial_x - x$:
%\begin{eqnarray*}
%	N_\omega S_\omega \omega^2 &=& -\partial_x S_\omega \omega^2 \partial_x S_\omega \omega^2 + \partial_x S_\omega x S_\omega \omega^2\\
%	&=& \frac{\omega^2}{4} + \partial_x S_\omega x S_\omega \omega^2 
%\end{eqnarray*}
%Thus, 
%\begin{eqnarray*}
%	S_\omega \omega^2 N_\omega + N_\omega S_\omega \omega^2 &=& \frac{\omega^2}{2} + \left(\partial_x S_\omega xS_\omega \omega^2  - S_\omega x \partial_x  S_\omega \omega^2 \right)+ U_\infty.
%\end{eqnarray*}
%We are done if we prove that the operator in parenthesis is of order $2$ in the scale $U^s$. For this, we may compute the action of each one of them on $U_n$. Using the various identities at our disposal, we obtain on the one hand for $n\geq 2$ 
%\[\partial_x S_\omega x S_\omega \omega^2 U_n = -\frac{T_{n+2}}{8(n+2)} -\frac{T_n}{8(n+2)} +  \frac{U_{n} + U_{n-2}}{8n(n+2)}. \]
%and on the other hand for $n>0$ 
%\[S_\omega x \partial_x S_\omega \omega^2 U_n = -\frac{T_{n+2}}{8(n+2)} - \frac{T_n}{8n}.\]
%After substracting, this gives the rather surprising identity identity for $n \geq 2$
%\[\left(\partial_x S_\omega xS_\omega \omega^2  - S_\omega x \partial_x  S_\omega \omega^2 \right)U_n = \frac{U_n}{4n(n+2)}\]
%which of course proves our claim.
%
%\section{Suggestion de découpage}
%
%J'y ai un tout petit peu réfléchi : 
%\begin{itemize}
%	\item[-] Les analyses pseudo-diffs des espaces $T^s$, bien qu'intéressantes, sont trop longues et ne se justifient pas vraiment dans le simple but de faire une méthode numérique. 
%	\item[-] La méthode de Galerkine est bien analysée et nouvelle (à ma connaissance) mais n'est pas vraiment essentielle pour le message. 
%\end{itemize}
%Je pense qu'on pourrait envisager 3 articles. 
%Un très concis sur la méthode numérique en elle-même. Utiliser le minimum d'info pour k=0, donner les inverses exacts, prouver la commutation des opérateurs pour k non nul, puis balancer les préconditionneurs, et mettre les figures. 
%
%Un article un peu à part sur la méthode de Galerkine, et tous les aspects numériques (bcp moins d'impact)
%
%Un article (peut-être juste sur arxiv ?) sur les espaces $T^s$ et $U^s$, qui donne toutes les justifications théoriques. (une sorte de version étendue de cet article.)


%	\section{Order of the operators $O_n$}
%	\label{orderOn}
%	
%	\begin{Lem}
%		\label{lemPseudoDiffOn}
%		For all $n \geq 1$, there exists a function $o_n : \N^2 \to \R$ satisfying the following conditions 
%		\begin{itemize} \item[(i)]\itemequation[sumDefiningOn]{}{$	\forall k \in \Z, \quad O_n T_k = \displaystyle\sum_{i = -\infty}^{+\infty} o_n(k,i)T_{k-i}$}{}
%			\item[(ii)] \itemequation[conditionon]{}{$	\forall \alpha, \in \N, \forall  i,k  \in \Z, \quad  \abs{\Delta_k^\alpha o_n(k,i)} \leq C_{n,\alpha,\beta} (1 + k^2)^{-n - \alpha}$}{} 
%			\item[(iii)]\itemequation[conditionon]{}{$\forall i,k \in \Z, \quad \abs{i} \geq  n \implies o_n(k,i) = 0$}{}
%		\end{itemize}
%		where $\Delta_i$ and $\Delta_k$ represent the discrete derivation operator in the variables $i$ and $k$ respectively, e.g. 
%		\[ \Delta_i o_n(k,i) = o_n(k,i+1) - o_n(k,i),\]
%		and $\Delta_i^\alpha$ denotes the $\alpha$-th iterate of $\Delta_i$. We use the convention $T_k \isdef T_{\abs{k}}$ for $k \in \Z$. 
%	\end{Lem}
%	\begin{proof}
%		We shall prove this by induction. First for $n = 1$, $O_1 = 2\pi S_\omega$, and we simply have $o_1(k,i) = \delta_{i = 0} s_k$ where $s_k$ are the eigenvalues of $S_\omega$ defined in \autoref{STn}. Obviously, $o_1$ satisfies all the requirements. Second, notice that for $n \geq 1$, 
%		\[O_{n+1} = x O_n - O_n x,\]
%		which combined with the identity 
%		\[x T_n = \dfrac{T_{n-1} + T_{n+1}}{2}\]
%		valid for all $n \in \Z$, implies
%		\[O_{n+1}T_k = \sum_{i= -\infty}^{+\infty} o_n(k,i) \dfrac{T_{k - i + 1} + T_{k _-i- 1}}{2} - \frac{1}{2} O_n T_{k+1} - \frac{1}{2} O_n T_{k - 1}.\]
%		By the recurrence assumption (i), this implies 
%		\begin{eqnarray*}
%			O_{n+1}T_k &=& \frac{1}{2} \sum_{-\infty}^{+ \infty}\left(o_n(k,i-1) - o_n(k+1,i - 1)\right) T_{k - i} \\
%			&&+ \frac{1}{2} \sum_{-\infty}^{+ \infty}\left(o_n(k,i+1) - o_n(k-1,i + 1)\right) T_{k - i}.
%		\end{eqnarray*}
%		Thus, condition (i) is satisfied with 
%		\[o_{n+1}(k,i) \isdef \frac{\left(o_n(k,i-1) - o_n(k+1,i-1) + o_n(k,i+1) - o_n(k-1,i+1)\right)}{2}.\]
%		If $\abs{i} \geq n+1$ then by triangular inequality $\abs{i-1} \geq n$ and $\abs{i+1} \geq n$ so all terms in the rhs are null by the assumption (iii), which shows that (iii) also holds for $o_{n+1}$. Finally, the assumption (ii) is easily checked for $o_{n+1}$ once we write 
%		\[ o_{n+1}(k,i) = \frac{- \Delta_ko_n(k,i-1) + \Delta_ko_n(k-1,i+1)}{2}.\]
%	\end{proof}
%	
%	
%	\begin{Lem}
%		\label{orderOfOn}
%		The operator $O_n$ is of order $n$. 
%	\end{Lem}
%	\begin{proof}
%		Since the sum in \eqref{sumDefiningOn} is finite, by linearity, it is sufficient to show that the operator $O^i_n$ defined by 
%		\[ \forall k \in \Z, \quad  O^i_n T_k = o_n(k,i) T_{k-i} \]
%		is of order $n$. We treat the case $i > 0$, the opposite case being analogous. Let $u \in T^s$ for some $s$, there holds 
%		\[ O^i_n u = \sum_{k = 0}^{+ \infty} o_n(k + i,i)\hat{u}_{k + i}T_k + \sum_{k = 0}^{i} o_n(i - k,i) \hat{u}_{i - k}T_k.\]
%		We let $Vu$ and $Ru$ respectively the two terms of the rhs. Obviously, $R$ is a smoothing operator with
%		\[ \norm{Ru}_{T^{s + n}} \leq (1 + i)^{n} \norm{u}_{T^s}.\]
%		Now, for all $k \in \N$ let
%		\[\hat{v}_k \isdef o_n(i + k,i) \hat{u}_{i + k}.\]
%		Applying Peetre's inequality, one has
%		\[(1 + k^2)^{n + s}\abs{\hat{v}_k}^2 \leq C \left(1 + i^2\right)^{\abs{n + s}}\left(1 + (i + k)^2\right)^{n + s} \abs{o_n(k + i,i)}^2 \abs{\hat{u}_{k+i}}^2.\]
%		the condition (ii) in \autoref{lemPseudoDiffOn} with $\alpha = \beta = 0$ yields
%		\[\abs{o_n(k+i,i)}^2 \leq C\left(1 + (k+i)\right)^{-2n} \leq 2C \left(1 + (k+i)^2\right)^{-n}.\]
%		Therefore, $\norm{V u}_{T^{s + n}} \leq C(1 + i)^{\abs{n + s}} \norm{u}_{T^s}$ which concludes the proof. 
%	\end{proof}

	
	
	
	
	
	
	
	
	
	\bibliographystyle{plain}
	\IfFileExists{../../Biblio/biblio.bib}{\bibliography{../../Biblio/biblio}}{\bibliography{/home/martin/Thesis/Biblio/biblio}}
	
	
\end{document}


%
%\section{Laplace equation on a flat segment}
%
%In this section, we restrict our attention to the case where $\Gamma$ is the open segment $(-1,1) \times \{0\}$, and $k=0$. We study the properties of the equations 
%\[S\lambda = -u_D\]
%and 
%\[N\mu = u_N\]
%and show their invertibility in a range of Sobolev-like spaces. This problem has been considered thoroughly, both
%in terms of analytical and numerical properties in the literature (see for instance \cite{jiang2004second,bruno2012second}), and it turns out that the Chebyshev polynomials of first and second kind play a very important role. However, we go further compared to the literature by 
%by constructing a functional framework close to Sobolev spaces, based on Chebyshev polynomials that
%allows us to give a complete framework for the existence and uniqueness of the solutions to the preceding equations, as well as
%new preconditioners.
%
%
%
%\subsection{Single layer equation}
%
%In this section we focus on the equation $S\lambda = g$, that is we seek $\lambda \in \tilde{H}^{-1/2}$ such that 
%\begin{equation}
%-\frac{1}{2\pi}\int_{-1}^{1} \log|x-y| \lambda(y) = -g(x), \quad \forall x\in (-1,1)\,.\label{Slambda}
%\end{equation} 
%
%This equation is sometimes called ``Symm's integral equation'' and its resolution has received a lot of attention in the 1990's. Numerical methods, using both collocation and Galerkin have been presented and analyzed \cite{atkinson1991numerical,yan1988integral,yan1990cosine,sloan1992collocation,yan1989mesh}. 
%
%%The solution is connected to the exterior Dirichlet problem for the Laplace operator, but attention must be paid when the solution $\lambda$ obtained does not satisfy $\duality{1}{\lambda}_\Gamma = 0$: in this case, $\textup{SL}\lambda$ is not a bounded solution of the Dirichlet problem. See \cite{atkinson1991numerical} for a link with the logarithmic capacity of the line and how we recover the bounded solution from the solution of \eqref{Slambda}.
%
%
%%
%%\paragraph{Autre idée de présentation.}
%%We first start with a commutation result
%%
%%\toDo{Commencer par le truc connu. Et en fait c'est normal. Balancer ensuite la commutation. Dire que ça n'a pas été remarqué. }
%%
%%\begin{Prop}
%%	Commutation de $S_\omega$ et $(\omega \partial_x)^2$. 
%%\end{Prop}
%%Exploitation en terme de vp. Dire qu'on a deux opérateurs avec spectre discret. (L'un est compact dans $L^2_\frac{1}{\omega}$, (sans preuve pour l'instant).
%%
%\begin{Lem}
%	\[ -\frac{1}{2\pi}\int_{-1}^{1} \frac{\ln|x-y|}{\sqrt{1 - y^2}}T_n(y)dy = s_n T_n(x)\]
%	where
%	
%	\label{STn}
%\end{Lem}
%
%Using the decomposition of $g$ and of the logarithmic kernel on the basis $T_n$, we see that the solution $\lambda$ to equation \eqref{Slambda} admits the following expansion 
%\begin{equation}
%\lambda(x) = \frac{1}{\sqrt{1-x^2}}\sum_{n=0}^{+ \infty} \frac{\hat{g}_n}{s_n} T_n(x).
%\label{expansionLambda}
%\end{equation}
%We deduce the following well-known fact:
%\begin{Cor}
%	\label{CorSingularity}
%	If the data $g$ is in $C^{\infty}([-1,1])$, the solution $\lambda$ to the equation 
%	\[S\lambda = g\]
%	is of the form 
%	\[\lambda = \dfrac{\alpha}{\sqrt{1-x^2}}\]
%	with $\alpha \in C^{\infty}([-1,1])$.  
%	\begin{proof}
%		Let $\alpha = \sqrt{1 - x^2}\lambda$ where $\lambda$ is the solution of $S\lambda = g$ where $g$ is assumed to lie in $C^{\infty}([-1,1])$. 
%		\autoref{LemTinfCinf} implies that $g \in T^{\infty}$, and by equation \eqref{expansionLambda}, 
%		\[ \hat{\alpha}_n = \frac{\hat{g}_n}{s_n},\]
%		so $\alpha$ also  belongs to $T^{\infty} = C^{\infty}([-1,1])$. 
%	\end{proof}
%\end{Cor}
%
%
%We follow \cite{bruno2012second} by noticing that the behavior in $\frac{1}{\sqrt{1-x^2}}$ is consistent with the expected singularity near the edges and introduce the weighted single layer operator as the operator that appeared in Proposition \ref{STn}.
%\begin{Def}(See \cite{bruno2012second}) 
%	Let $S_\omega$ be the weighted single layer operator defined by
%	\[\opFromTo{S_\omega}{\alpha \in \Cinf([-1,1])}{-\dfrac{1}{2\pi}}{\int_{-1}^1\dfrac{\ln|x-y|}{\omega(y)} \alpha(y)dy}\]
%\end{Def}
%\noindent We also recall that the operator $(\omega\partial_x)^2$ is defined by \[\opFromTo{(\omega\partial_x)^2}{\alpha \in \Cinf([-1,1])}{(1-x^2)\alpha''(x) - x \alpha'(x)}.\]
%
%The action of these operators on $T^{\infty}$ is easy to analyze using \eqref{cheb1} and \autoref{STn}. By density of $T^{\infty}$ in $T^s$ for all $s$, we get:
%\begin{Prop}
%	The operator $S_\omega$ is a self-adjoint, positive definite operator, and defines a continuous bijection from $T^{s}$ to $T^{s+1}$ for all real $s$. In particular, $S_\omega$ is of order $1$ and is compact in $T^s$. 
%	Similarly, for any $s \in \R$, the operator $-(\omega \partial_x)^2$ is positive, self-adjoint, and of order $-2$. 
%\end{Prop}
%\begin{proof}
%	It suffices to remark that if $u=\sum_{n=0}^\infty \hat{u}_n T_n \in T^s$, then
%	\[S_\omega u = \frac{\ln(2)}{2} \hat{u}_0 T_0 +  \sum_{n=1}^\infty \frac{\hat{u}_n}{2n} T_n\]
%	while
%	\[-(\omega \partial_x)^2 u = \sum_{n=0}^\infty n^2\hat{u}_n T_n \,.\]
%\end{proof}
%\begin{Rem}
%	Of course, $S_\omega$ is in the class $S^1$ defined in \autoref{subsec:classesOfOp}
%\end{Rem}
%\noindent To obtain the solution of \eqref{Slambda}, we can thus solve 
%\begin{equation}
%S_\omega \alpha = -u_D,
%\label{Somegaalpha}
%\end{equation}
%and let $\lambda = \frac{\alpha}{\omega}$.  
%The next lemmas make clear the connection between the spaces $T^s$ with $s = \pm \frac{1}{2}$ and the usual Sobolev spaces. Equivalent results are proved in \cite{jerez2010boundary}. 
%
%
%\begin{Lem} Similarly,
%	\[H^{1/2}(-1,1) = T^{1/2}\]
%	and for $u \in H^{1/2}(-1,1)$ we have
%	\[\norm{u}_{H^{1/2}} \sim \norm{u}_{T^{1/2}}\,.\]
%	\label{LemmaT1/2}
%\end{Lem}	
%\begin{proof}
%	 
%\end{proof}
%
%We are now in a position to find an expression for the inverse of $S_\omega$. An explicit inverse has already appeared in the literature. In 
%particular, in \cite{jerez2012explicit,urzua2014optimal}, explicit variational forms for this inverse operator are derived rigorously. (A similar method is also employed in the recent paper \cite{hiptmair2017closed} in $\R^3$ for the case of the unit disk.) We just state here the following formal decomposition:
%\[\dfrac{d^2}{dxdy}\log\frac{M(x,y)}{|x-y|^2} = \frac{-1+xy}{2|x-y|^2} = \sum_{n=1}^{+ \infty} n T_n(x)T_n(y)\]
%with 
%$M(x,y) = \frac{1}{2}\left((y-x)^2 + (\omega(x) + \omega(y))^2\right) $.
%
%However, using the preceding analysis, we have an alternative way of defining this exact inverse, which leads to an expression in the form of the square root of a local operator. To state the next result, we define the operator $\pi_{0}$ as the $L^2_{1/\omega}$ 
%orthogonal projector on $T_0$. Namely 
%\[\pi_0 \alpha(x)  = \frac{1}{\pi} \int_{-1}^{1}\frac{\alpha(y)}{\omega(y)}dy\,.\]
%The preceding definition can be extended to $u \in T^s$ for any $s \in \R$ by setting $\pi_0 u$ as the solution of
%\[\left\{
%\begin{array}{l}\duality{\alpha-\pi_0 \alpha}{T_0}_{\frac{1}{\omega}} = 0\,,\\
%\pi_0\alpha\in \mbox{Span}(T_0)\,,
%\end{array}
%\right.\]
%since $T_0\in T^\infty$. Of course, $\pi_0$ is continuous from $T^s$ to $T^{\infty}$ for any $s$. 
%
%\begin{The}
%	\label{TheSdx2S}
%	There holds
%	\begin{equation}
%		\label{Sdx2S}
%		S_{\omega}^2 = \frac{1}{4}\left(-(\omega\partial_x)^2 + \frac{1}{\ln(2)^2} \pi_0 \right)^{-1}\,.
%	\end{equation}
%\end{The}
%\begin{proof}
%	The Chebyshev polynomials $(T_n)$ are a common Hilbert basis of eigenvectors for the three operators $S_\omega$, $-(\omega \partial_x)^2$ and $\pi_0$, so it is sufficient to compute $4 S_\omega^2 \left(-(\omega\partial_x)^2 + \frac{1}{\ln(2)^2} \pi_0 \right) T_n$ and check that this is indeed equal to $T_n$. 
%	One has using the explicit eigenvalues for $S_\omega$. This is easily verified using the following expressions
%	\[ S_\omega T_n =\frac{1}{2n}T_n\,,\,\, \pi_0 T_n = 0 \mbox{ and } -(\omega\partial_x)^2T_n = n^2 T_n \mbox{ if } n\ne 0\,,\]
%	while
%	\[ S_\omega T_0 = \frac{\ln(2)}{2} T_0\,,\,\, \pi_0 T_0 = T_0 \mbox{ and } -(\omega\partial_x)^2T_0 = 0 \mbox{ otherwise.}\]
%\end{proof}
%
%From the preceding formula, we can extract the explicit inverse of $S_\omega$ in terms of the square root of the inner operator. 
%
%\begin{Cor}
%	The inverse of $S_\omega$ can be equivalently expressed as 
%	\begin{equation}
%	S_{\omega}^{-1} = 2\sqrt{-(\omega \partial_x)^2 + \frac{1}{\ln(2)^2}\pi_0}\,.
%	\end{equation}
%\end{Cor}
%
%
%	
%\begin{table}[H]
%	\begin{center}
%		\begin{tabular}{|| m{4em} | m{4em} | m{4em} | m{4em} | m{4em}||} 
%			\hline
%			\multicolumn{1}{||c|}{ }&
%			\multicolumn{2}{c|}{with Prec.}&\multicolumn{2}{c||}{without Prec.}\\
%			\hline
%			$N$ & $n_{it}$& t(s) & $n_{it}$ & t(s)\\
%			\hline\hline
%			50 & 7 & 0.11 & 35 & 0.21\\
%			\hline
%			200 & 7 & 0.14 & 53 & 0.55\\
%			\hline
%			800 & 7 & 0.29 & 76 & 2.0 \\
%			\hline
%			3200 & 7 & 0.95 & 107 & 9.5\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\caption{Number of iteration and time needed for the numerical resolution of \eqref{Somegaalpha} using Galerkin finite elements with and without preconditioner.}
%	\label{TableNitTimeLaplaceDirichlet}
%\end{table}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=0.7]{../figs/PrecondDirichletLaplaceSeg.png}
%	\caption{Number of iteration in the resolution of the single layer integral equation with a mesh of size $N = 1600$.}
%	\label{FigureNitLaplaceDirichlet}
%\end{figure}
%
%\subsection{Hypersingular equation} 
%
%We now turn our attention to the equation 
%
%\begin{equation}
%N\mu = g
%\label{Nmu}
%\end{equation} 
%
%Similarly to the previous section and following again the idea of \cite{bruno2012second}, we consider a rescaled version of the hypersingular operator $N_\omega \isdef N \omega$ defined by
%
%\[N_\omega \mu = \lim_{\varepsilon\to 0}\int_{-1}^{1} n(y)\cdot\nabla G(x + \varepsilon n(x) - y) \sqrt{1-y^2} dy\]
%We can get the solution to equation \eqref{Nmu} by solving 
%\begin{equation}
%N_\omega \beta = u_N,
%\label{Nomegabeta}
%\end{equation}
%and letting $\mu = \omega \beta$. 
%We now show that $N_\omega$ can also be analyzed in our functional framework, using this time the spaces $U^s$. 
%\begin{Lem}
%	\label{lemIPP}
%	For any $\beta$, $\beta'$, one has 
%	\[\duality{N_\omega \beta}{ \beta'}_\omega = \duality{S_\omega \omega \partial_x \omega \beta}{\omega \partial_x \omega \beta'}_\frac{1}{\omega}.\]
%	\begin{proof}
%		It is sufficient to show this formula for $\beta$ and $\beta'$ in $U^{\infty}$ by density. Indeed, for such $\beta, \beta'$, both sides of the identity define continuous bilinear forms on $T^{\infty}$. We use the well-known integration by part formula
%		\[\duality{N u}{v} = \duality{S\partial_x u}{\partial_x v},\]
%		valid when $u$ and $v$ vanish at the extremities of the segment (see for example \cite{bruno2012second}). 
%		For a smooth $\beta$, we thus have
%		\[ \duality{N (\omega \beta)}{ (\omega \beta')} = \duality{S \partial_x(\omega \beta)}{\partial_x (\omega \beta')}\] 
%		which obviously implies the announced identity. 
%	\end{proof}
%\end{Lem}
%\begin{Prop}
%	$N_\omega$ is a positive definite, self-adjoint operator continuous from $U^s$ to $U^{s-1}$ for all real $s$. For all $n \in \N$, we have 
%	\[N_\omega U_n = \frac{n+1}{2}U_n.\]
%	Moreover, $-(\partial_x\omega)^2$ is also positive definite of order $2$.
%	\label{NUn}
%\end{Prop}
%\begin{proof}
%	From identity $T_{n+1}' = (n+1)U_n$ and Equation $\eqref{cheb1}$ we obtain
%	\begin{equation*}
%	\omega \partial_x \omega U_n = -(n+1) T_{n+1}.
%	\end{equation*}
%	Therefore, by \autoref{lemIPP}
%	\begin{eqnarray*}
%		\duality{N_\omega U_m}{U_n}_\omega & = & (n+1)(m+1)\duality{S_\omega T_{m+1}}{T_{n+1}}_\frac{1}{\omega}\\
%		&=& \delta_{m=n} \frac{n+1}{2}.	
%	\end{eqnarray*}
%	The fact that $-(\partial_x \omega)^2$ is self-adjoint positive definite of order $2$ is a consequence of Equation \eqref{cheb2}.
%\end{proof}
%	Like before, we have the following link between $U^{-1/2}$, $U^{1/2}$ and the usual Sobolev spaces. 
%
%As an application of this result, one can also derive the formal expansions as in \cite{jerez2012explicit}
%\[\frac{1}{(x-y)^2} = \sum_{n=0}^{+\infty} 2(n+1)U_n(x)U_n(y)\,,\]
%that lead, by applying for $(\partial_x\omega)^{-2}$ on both sides, to the following explicit kernel for the inverse of $N_\omega$:
%\[\ln\left(\dfrac{(y-x)^2 + (\omega(x) + \omega(y))^2}{2|x-y|}\right) = \sum_{n=0}^{+\infty} \dfrac{2 U_n(x) U_n(y)}{n+1}.\]
%Here instead, we give a simple expression of the inverse of $N_\omega$ as the inverse square root of a local operator:
%\begin{The} 
%	\label{the:NeumannInverseLaplace}
%	There holds 
%	\[N_\omega^2 = -\frac{1}{4}(\partial_x \omega)^2 \,.\]
%	The inverse of $N_\omega$ is therefore 
%	\begin{equation}
%	N_\omega^{-1} = 2\sqrt{-(\partial_x \omega)^{-2}}\,.
%	\end{equation}
%\end{The}
%In \autoref{TableNitTimeLaplaceNeumann}, we compare the number of iterations for the numerical resolution of Equation \eqref{Nomegabeta} by the method detailed in \autoref{sec:numerMeth} without preconditioner, and with a preconditioner given by $M^{-1} \left[B \right] M^{-1}$ where $M$ is the mass matrix and $\left[ B \right]$ is the Galerkin matrix of the operator $\sqrt{ -( \partial_x \omega)^{-2}}$. The right hand side in \eqref{Nomegabeta} is chosen as $u_N(x) = (x^2 + 0.001)^{1/2}, x \in (-1,1)$.
%
%\begin{table}[H]
%	\begin{center}
%		\begin{tabular}{|| m{4em} | m{4em} | m{4em} | m{4em} | m{4em}||} 
%			\hline
%			\multicolumn{1}{||c|}{ }&
%			\multicolumn{2}{c|}{with Prec.}&\multicolumn{2}{c||}{without Prec.}\\
%			\hline
%			$N$ & $n_{it}$& t(s) & $n_{it}$ & t(s)\\
%			\hline\hline
%			50 & 4 & 0.05 & 50 & 0.05\\
%			\hline
%			200 & 3 & 0.05 & 200 & 0.25\\
%			\hline
%			800 & 3 & 0.06 & 799 & 3.7 \\
%			\hline
%			3200 & 3 & 0.6 & 3007 & 630\\
%			\hline
%		\end{tabular}
%	\end{center}
%	\caption{Number of iteration and time needed for the numerical resolution of \eqref{Somegaalpha} using Galerkin finite elements with and without preconditioner.}
%	\label{TableNitTimeLaplaceNeumann}
%\end{table}
%\begin{figure}[H]
%	\centering
%	\includegraphics[scale=0.7]{../figs/PrecondNeumannLaplaceSeg.png}
%	\caption{Number of iteration in the resolution of the hypersingular  integral equation with a mesh of size $N = 1600$. The importance of preconditioning in this case is more obvious than in the case of the single-layer equation.}
%	\label{FigureNitLaplaceNeumann}
%\end{figure}
%
%\begin{Rem}
%	In \cite{bruno2012second}, the main theorem is equivalent to stating that $N_\omega S_\omega$ and $S_\omega N_\omega$ are bicontinuous operators in $T^s$, with a spectrum concentrated around $\frac{1}{4}$, which can be exploited for preconditioning purposes. It is shown that $N_\omega$ is continuous from $T^s$ to $T^{s-1}$ for all $s >1$ (in fact, this remains true for $s > \frac{1}{2}$). The two main arguments involved in the proof are the explicit expression of $N_\omega T_n$ and the continuity of the adjoint of the Cesaro operator in $l^2(\N)$. The same arguments can be used to prove that $S_\omega$ is also a bicontinuous operator from $U^s$ to $U^{s+1}$ for all $s > 1/2$. 
%\end{Rem}



%\section{Helmholtz equation}

%	In this section, we introduce preconditioners for the integral equations on $\Gamma = (-1,1)$ for the Helmholtz equation. Recall the definition of the single layer and hypersingular operators, $S_k$ and $N_k$, given in \eqref{defSk} and \eqref{defNk}, and the integral equations for the Dirichlet and Neumann problems, \eqref{Sklambda} and \eqref{Nkmu}. As before, let $S_{k,\omega} \isdef S_k \frac{1}{\omega}$ and $N_{k,\omega} \isdef N_k \omega$. We begin by establishing the following result:
%	
%	\begin{The}
%		\label{Commutations}
%		The following commutations hold:
%		\[S_{k,\omega} \left[-(\omega \partial_x)^2 - k^2\omega^2\right] =  \left[-(\omega \partial_x)^2 - k^2\omega^2\right]S_{k,\omega},\]
%		\[N_{k,\omega} \left[-(\partial_x \omega)^2 - k^2\omega^2\right] =  \left[-(\partial_x \omega)^2 - k^2\omega^2\right]N_{k,\omega}.\]
%		\begin{proof}
%			We start with the first commutation. Since $(\omega \partial_x)^2$ is self adjoint and symmetric, we have 
%			\[S_{k,\omega} (\omega \partial_x)^2 = \int_{-1}^{1} \frac{(\omega_y \partial_y)^2 \left[G_k(x-y)\right] u(y)}{\omega(y)},\]
%			where we use the notation $\omega_y$ and $\partial_y$ to emphasize the dependence in the variable $y$. 
%			Thus, 
%			\[S_{k,\omega} (\omega \partial_x)^2 - (\omega \partial_x)^2 S_{k,\omega} = \int_{-1}^{1} \frac{D_k(x,y)u(y)}{\omega(y)},\]
%			where $D_k(x,y) \isdef \left[(\omega_y \partial_y)^2 - (\omega_x \partial_x)^2\right] \left[G_k(x-y)\right]$. 
%			One has 
%			\[D_k(x,y) = G_k''(x-y) (\omega^2_y - \omega^2_x) + G_k'(x-y)(y + x).\]
%			Since $G_k$ is a solution of the Helmholtz equation, we have for all $(x \neq y) \in \R^2$ 
%			\[G_k'(x-y) = (y-x)(G_k''(x-y) + k^2G(x-y)),\]
%			thus
%			\[D_k(x,y) = G_k''(x-y)\left(\omega^2_y - \omega_x^2 + y^2 - x^2\right) + k^2(y^2 - x^2)G_k(x-y) . \]
%			A careful analysis shows that no Dirac mass appears in the previous formula, that is, the previous formula is an equality of two functions in $T^{-\infty}$. 
%			Note that $y^2 - x^2 = \omega_x^2 - \omega_y^2$ so the first term vanishes and we find
%			\[S_{k,\omega} (\omega \partial_x)^2 - (\omega \partial_x)^2 S_{k,\omega} =  k^2\left(\omega^2 S_{k,\omega} -S_{k,\omega} \omega^2 \right). \]
%			The proof of the second commutation is postponed to \autoref{ann:commut}. 
%		\end{proof}
%	\end{The}
%	
%	This theorem implies that the operators $S_{k,\omega}$ and $N_{k,\omega}$ share the same eigenvectors as, respectively, $\left[-(\omega \partial_x)^2 - k^2\omega^2\right]$ and $ \left[-(\partial_x \omega)^2 - k^2\omega^2\right]$. We can look for eigenfunctions of the operator $\left[ -(\omega \partial_x)^2 - k^2\omega^2\right]$, to find a diagonal basis for $S_{k,\omega}$. They are the solutions to the differential equation 
%	\[ (1-x^2) y'' - x y' - k^2 \omega^2 y = \lambda y.\]
%	Once we set $x = \cos \theta$, $\tilde{y}(\theta) = y(x)$,  $q = \frac{k^2}{4}$, $a = \lambda + 2q$, $\tilde{y}$ is a solution of the standard Mathieu equation 
%	\begin{equation}
%	\label{MatthieuEq}
%		\tilde{y}'' + (a - 2q \cos(2\theta)) \tilde{y} = 0.
%	\end{equation}
%	There are a discrete set of values $a_{2n}(q)$ for which this equation possesses an even and $2\pi$ periodic function. The corresponding solution is known as the Mathieu cosine, and usually denoted by $\textup{ce}_n$. Here, we use the notation $\textup{ce}^k_n$ to emphasize the dependency in the parameter $k = \sqrt{2q}$ of those functions. The normalization is taken as
%	\[ \int_{0}^{2\pi} \textup{ce}^k_n(\theta)^2 d\theta = \pi.\]
% 	They satisfy
%	\[ \int_{-\pi}^{\pi}\textup{ce}^k_n(\theta) \textup{ce}^k_m(\theta) = \pi \delta_{m,n}.\]
%	Any even $2\pi$ periodic function in $L^2(-\pi,\pi)$ can be expanded along the functions $\textup{ce}_n$, with the coefficients obtained by orthonormal projection. Letting 
%	\[T_{n}^k \isdef \textup{ce}^k_n(\arccos(x)),\]
%	in analogy to the zero-frequency case, we have
%	\[\left[-(\omega \partial_x)^2 - k^2\omega^2\right] T_{n}^k = \lambda_{n,k}^2 T_{n}^k.\]
%	For large $n$, using the general results from the theory of Hill's equations (see \cite[eq. 28.29.21]{NIST:DLMF}) we have the following asymptotic formula for $\lambda_{n,k}$:
%	\[ \lambda_{n,k}^2 = n^2 - \frac{k^4}{16n^2} +o \left(n^{-2}\right). \]
%	The first commutation established in \autoref{Commutations} implies that the Matthieu cosines are also the eigenfunctions of the single-layer operator. An equivalent statement is given in \cite[Thm 4.2]{betcke2014spectral}, if we allow the degenerate case $\mu = 0$. 
%	A similar analysis can be applied to the hypersingular operator. The eigenfunctions of $\left[(\partial_x \omega)^2 - k^2 \omega^2\right]$ are given by 
%	\[U_n^k \isdef \frac{\textup{se}_n^k(\arccos(x))}{\omega(x)}\]
%	where $\textup{se}_n^k$ are the so-called Matthieu sines, which also satisfy the Matthieu differential equation \eqref{MatthieuEq}, but with the condition that they must be odd $2\pi$ periodic functions. 
%	Unfortunately, the lack of knowledge about the eigenvalues of $S_{k,\omega}$ and $N_{k,\omega}$ prevents us from applying a similar analysis as that performed in the first part of this work. Instead, we will perform a perturbation analysis, much like \cite{bruno2012second}.
